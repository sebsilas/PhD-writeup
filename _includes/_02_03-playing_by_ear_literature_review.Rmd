

## Playing by Ear Research: A Literature Review {#playing_by_ear_literature_review}

In this section, I provide an overview of the literature on playing by ear and related skills. Research specifically on the topic of "playing by ear" mainly comes from the music education and music performance literatures. I will review this literature first - which is mainly *descriptive* in that it does not *explain* the mechanisms underlying performance on playing by ear tasks. To build on this literature, I will turn to the cognitive psychology literature to help develop an *explanatary* account of playing by ear. In the cognitive/music psychology literature, "playing by ear" has not been established as a clear topic, though there is much related research, particularly in the domain of singing. I will therefore synthesise these literatures and contextualise playing by ear within a deeper cognitive psychological foundation: that is, I will review the internal mechanisms that might underlie performance. Then, add the end of the chapter, I will propose a theoretical cognitive model of playing by ear skills, integrating the findings I have reviewed. This theoretical cognitive model will serve as a basis for computational models developed later in the manuscript.

### Historical Overview

#### Foundation or Frill? [@woody2012]


In music education research, in at least as early as the 1950's did researchers such as @mainwaring1951teaching begin advancing the importance of playing by ear skills in formal music education. By the late eighties, the music education literature began further lamenting that playing by ear skills were largely overlooked in music education, with the tyranny of visual notation being a main focus of teaching [@inbook; @priestPlayingEarIts1989]. A key emphasis and conclusion of this emerging literature in music education was that playing by ear skills were grossly overlooked, as they actually appear to be important contributors to musicianship as a whole - even helping sight reading skills [@mcphersonChildMusicianSkill2005].

#### From Sign to Sound => From Sound to Sign

As such, @inbook convey how musical meaning arises through a dynamic interplay between performer intention, listener interpretation, and cultural context, rather than being fixed in notation. They argued that music should be taught from *sound to sign* — that is, beginning with auditory and expressive engagement before introducing formal notation. This approach, they contend, better reflects how meaning is constructed in music and supports deeper, more intuitive musical learning. Their contribution is significant within music education and cognition, challenging notation-first traditions and advocating for a more experiential, communication-oriented model of instruction. Such an approach was later refined by @haston_playing_2022, who gave specific directives as to when learning visual notation should be (e.g., 6-7 years old, after many years of ear-only training), which is also similar to the Suzuki method [@hermannShinichiSuzukiMan1999].

#### The Contemporary Situation

Whilst visual notation may ostensibly reign supreme in Western teaching conventions, perhaps in part due to the somewhat polemical music education literature reviewed [e.g., @inbook; @muscoPlayingEarExpert2010; @priestPlayingEarIts1989] do attitudes and practices appeared to have changed. At the present time of writing, in 2025, playing by ear seems to now be more widely recognised as a valuable pedagogical tool, at least in the UK, with aural skill tests including singing and playing by ear exercises being a feature of exam boards. The development of playing by ear skills varies significantly across music examination boards. The *ABRSM* exam system includes aural tests in which candidates sing back short melodies (Grades 1–3), but it does not assess instrumental playback by ear [@abrsm2024]. In contrast, the *Trinity College London* syllabus features a "musical recall" component that directly tests the ability to play by ear on an instrument [@trinity2024]. Similarly, Trinity's relatively new *Rockschool* exam board places strong emphasis on contemporary aural skills, including instrumental playback and improvisation as part of its exams from early grades [@rsl2024]. Differences between exam boards reflect broader pedagogical focuses, with *ABRSM* favoring traditional classical training and *Trinity* and *Rockschool* supporting a more holistic or contemporary approach. However, *ABRSM*,  has offered jazz grades since the 1990's, reflecting an acknowledgement of the importance of jazz education. They explictly state the importance of playing by ear skills on their webpage describing aural tests for jazz grades: *"The aural tests are designed to help you to listen to music in this way and to foster working by ear. The aural tests can be extended into exercises for developing improvisation and other jazz skills"* [@Jazz2025]. Perhaps due to these contemporary picture, there has been a relative dearth of new research on playing by ear compared to the 1990's and 2000's. But to conclude, at least in the UK, it seems that playing by ear has become more widely recognised even in formal music education, with exam boards now even offering exams to vernacular musicians. In the next section, I will describe findings from the music education and performance literature that help us understand the development of playing by ear skills and its relationship to other factors.


### Developmental and Pedagogical Aspects of Playing By Ear Skill Acquisition


How do musicians acquire the ability to play by ear? @muscoPlayingEarExpert2010's review reports that playing by ear skills may develop naturally over time [@gerberInvestigationRelationshipPerformance1993; @mcphersonChildMusicianSkill2005], through unsupervised practice [@mcphersonAssessmentMusicalPerformance1995] and through practice with instruction [@bernhardEffectsTonalTraining2004; @brown1990investigation; @dickey1991comparison. In general, evidence suggests that the practice of recalling melodies on an instrument can improve playing by ear skills [@bernhard2005playing; @dickey1991comparison; @wilder1988investigation]: plainly put, *"ear playing is learned by playing by ear"* [@Johansson2004]. I will now review different developmental aspects of playing by ear skill acquisition and the relationship of playing by ear to other skills.


#### Early Development and Informal Learning 

Developmental studies indicate that playing by ear can emerge at surprisingly early stages given the right exposure. Many children first experience music informally – singing songs, copying melodies by ear on piano or guitar, improvising little tunes – often well before they read notation. Longitudinal research  [e.g., @mcphersonChildMusicianSkill2005; @mcphersonPathAnalysisTheoretical1997] followed young instrumental students over time and found that those who engaged in activities like singing or picking out tunes by ear showed enhanced musical understanding in the long run [@Varvarigou2014]. @inbook suggested that having beginners sing before playing an instrument helps them internalise pitch and rhythm, which later aids in connecting sound to symbols (notation). In essence, early ear-playing experiences allow children to embody music – linking what they hear to what their fingers do – which lays a cognitive foundation for all subsequent musical learning. Another study by @gerberInvestigationRelationshipPerformance1993 suggested that skill in playing by ear often develops naturally through unguided exploration: children who spend time noodling on their instrument, figuring out favorite tunes by ear, tend to improve in that ability through self-discovery. Such findings align with anecdotal observations that many talented ear-players are self-taught or began learning informally (e.g. picking up guitar chords from recordings or learning folk tunes by ear). In popular music contexts, it is common for beginners to start with imitation of recordings, gradually building a repertoire of songs by ear [@Green2002]. Overall, developmental evidence supports the idea that given exposure and opportunity, learners will cultivate ear-playing competencies even without formal instruction – though formal training can further refine and expand these skills. 

#### Formal Pedagogy and Ear-Training

Despite its evident benefits, playing by ear has not always been systematically incorporated into formal music education. Traditional Western pedagogy, especially in classical music, has heavily focused on notation literacy and technical exercises, with ear-playing sometimes regarded as a lesser skill or even a distraction. Nonetheless, a growing body of pedagogical research advocates for integrating playing by ear into teaching curricula for its positive impact on musicianship. @BakerGreen2013 conducted a landmark *Ear Playing Project* experiment with 10–14 year-old students in the UK, providing one group of students with regular opportunities to learn melodies by ear from recordings (instead of from notation) while a control group received only traditional instruction. After a period of instruction, all students were given standardised aural tests that required them to play back melodies and rhythms by ear. The results were striking: the ear-playing group surpassed the control group in every criterion (pitch accuracy, rhythmic accuracy, melodic contour, tempo, etc.) on the post-tests. In other words, those who practiced learning music by ear showed significantly greater improvement in aural skills than those who only learned through notation. This evidence strongly suggests that incorporating ear-playing in lessons formally can enhance students’ aural development. Notably, these gains did not come at the expense of other skills; instead, ear-playing experience appeared to reinforce musical memory and understanding that also benefit reading and performing. Parallel research by @muscoPlayingEarExpert2010 and @woody2012 addressed a common concern among music teachers that spending time on by-ear learning might impede music reading progress [@Varvarigou2014]. Their findings counter this worry: students can learn to play by ear and to read music in tandem, with each skill informing the other. In fact, @woody2012 argued that playing by ear skills make students more sensitive and "musical" when reading notation, since they are not just decoding notes on the page but internally hearing and understanding them [@WoodysResearchAppear2018]. Recognising these advantages, educational approaches like Suzuki method (for violin and other instruments) have long emphasised early ear training—students learn tunes by ear first, delaying notation, which purportedly develops strong listening and memory skills [@hermannShinichiSuzukiMan1999]. Similarly, contemporary methods in popular music education (e.g., Lucy Green’s informal learning approach, @greenMusicInformalLearning2008) deliberately use playing by ear in group teaching: students might be tasked with figuring out a pop song by listening to a recording together, fostering collaborative ear-learning. Teachers who have tried these approaches often report increased student engagement. For example, @Varvarigou2014 examined instrumental teachers’ experiences when they introduced "copying by ear" tasks in one-to-one lessons as part of the *Ear Playing Project*. Teachers adopted various strategies, such as singing or humming phrases to prompt students, asking guiding questions, and giving positive feedback while students learned songs by ear. By the end of the project, the teachers noted that incorporating ear-playing provided "a new and enjoyable way" to work on aural skills and even boosted their own confidence in teaching by ear. They observed that students seemed to enjoy lessons more, showed improved improvisation abilities, and grew more confident on their instruments through these activities. These qualitative outcomes echo formal test results: playing by ear can increase musical enjoyment and creativity, likely because it is a more naturally immersive way to learn music than reading alone.

#### Jazz Education and Professional Development

To summarise what was discussed in Chapter 3, in jazz music, learning by ear has always been fundamental, and research on jazz pedagogy provides insights into advanced playing by ear skill development. For instance, jazz educators encourage students to transcribe solos by ear (i.e. learn them by listening and reproducing, sometimes writing them down afterward) and to learn tunes from recordings rather than fakebooks. This practice not only ingrains repertoire, but also develops the aural vocabulary needed for improvisation. Ethnographic work, such as Paul Berliner’s *Thinking in Jazz* -@berliner1994thinking, documents how jazz legends acquired their craft: virtually all spent countless hours listening to records, imitating phrasing and solos, and jamming informally – all ear-driven learning. Systematic studies reinforce this: for example, a study of collegiate jazz improvisers by @Norgaard2011 found that expert improvisers rely heavily on musical memory during performance. In interviews, professional jazz musicians described their improvisational thinking as a mix of pre-learned phrases (licks) retrieved from memory, and spontaneous creation guided by ear. They report that while improvising, they often recall well-learned ideas from memory and insert them, or choose notes based on an internal auditory priority (what they hear as the next phrase) rather than a purely theoretical formula [@Norgaard2011]. This again highlights the "primacy of the ear" (also the name given to a popular resource of the same name; @blakePrimacyEar2010).


#### Learning Strategies for Playing by Ear

There is limited research on the practice of learning by ear, especially among popular musicians [@Lilliestam1996], with previous studies of learning by ear usually focusing on students or novices, often limited to short melodies [@Lahav2005:1; @Varvarigou2015]. Despite this, there have been a few studies on experienced musicians, who use music theory and advanced strategies to help facilitate recall [@Johansson2004:1; @WoodyLehmann2010:1]. Musicians often learn by ear from recordings, using informal methods [@Bennett1980; @Groce1989] and recordings have been central to learning, even before digital tools [@Bennett1983; @Campbell1995]. It has been suggested that recordings serve as "notation" for popular musicians. Learning is typically a private, self-taught process [@Bennett1983; @Campbell1995]. Contemporarily, tools like *Transcribe!* [@TranscribeSoftwareHelp2021] and *Amazing Slow Downer* [@ronimusic2025] help slow and loop recordings, but their usage remains under-researched [@Driedger2016; @Johansson2004]. It has also been suggested that teacher-student modelling i.e., call and response is an effective method to teach playing by ear skills [@dickey1988comparison; @haston_playing_2022; @hastonBeginningWindInstrument2010]. Additionally, providing "opportunities for self-initiated learning and non-evaluated practice" – where students explore without immediate external correction – has been suggested as crucial for developing confidence in ear-playing [@Varvarigou2014]. Such unguided exploration allows individuals to discover what strategies work best for them, whether it’s trial-and-error, visualising the music, or relying on muscle memory.

An important theme in playing by ear research is the contrast between formally trained musicians and those from informal backgrounds (such as self-taught popular musicians). Studies consistently show differences in how these groups learn and approach ear-playing. @WoodyLehmann2010 found that college music students with vernacular (informal) experiences needed significantly fewer trials to learn melodies by ear than their strictly classically trained peers. The formally trained musicians often struggled initially because their habits were tied to written cues and deliberate practice of technique; they tended to focus on "physically producing the melodies" (e.g. thinking about finger positions) instead of listening to the melody as a whole. In contrast, the informal-trained students had automated much of the motor execution, allowing them to focus attention on the sound itself. This finding echoes many anecdotal observations in music teaching: students coming from church bands, garage bands, or other informal environments often have a natural ease with picking up songs by ear and playing with others, whereas conservatory-trained students might excel at reading and technique but initially feel "lost" without sheet music. Of course, these differences are not immutable – formal training can incorporate ear skills, and informal musicians can learn theory and reading. The point is that early experiences shape one's musical orientation. Individual differences in auditory memory, motivation, and even personality (e.g. willingness to take risks) can also affect playing by ear ability. Some individuals seem to have a proclivity for learning by ear; researchers like @mishraRhythmicMelodicSight2016 have speculated about auditory working memory capacity or auditory imagery vividness as factors that might make one person a stronger ear-learner than another. However, the overarching message from the literature is that playing by ear is trainable. Even those who do not consider themselves naturally good at it can improve with practice and the right strategies. For instance, a case study by @Creech2008 showed that adult classical musicians, when encouraged to learn simple tunes by ear as part of a workshop, made substantial progress and reported it positively impacted their listening skills. As one educator summarised, "ear playing is learned by playing by ear" [@Johansson2004] – meaning the best way to get better is simply to do it, genre by genre, song by song, gradually building the mental library and reflexes that enable ever more fluent playing by ear.

Recent research has noted how YouTube has been used in various fields for observing real-world behaviors, including learning by ear [@Anthony2013; @Mauriello2018]. YouTube offers access to real-world examples of musicians learning in their natural environments. @liscioWatchingPopularMusicians2024 conducted a hypothesis-generating study to explore how experienced popular musicians learn music by ear, using 18 YouTube videos as data. Their goal was to identify patterns of human-recording interaction that could inform the design of future music learning technologies. From their observations, they derived six key hypotheses grounded in empirical evidence. First, they found that the scope of learning influences musicians' interaction with recordings. While some musicians attempted to learn entire songs, most focused on fragments such as riffs or solos, which may reflect both genre conventions (e.g., repetition in popular music) and the limited affordances of their tools. Second, notation and transcription played a surprisingly limited role. While a few musicians created sheet music or tablature during their learning process, these artifacts seemed to function more as memory aids than as tools directly supporting ear-based learning. Notably, most musicians did not consult notation while playing, suggesting that transcription and ear learning may operate as parallel, rather than integrated, activities. Third, purpose-built technologies—such as software designed to slow or loop audio (e.g., *Transcribe!*, *Amazing Slow Downer*) — were seldom used. Most musicians relied on general-purpose media players like YouTube or Spotify and demonstrated little use of features like tempo or pitch adjustment. This underutilisation raises questions about the accessibility, awareness, or necessity of such tools among skilled learners. Fourth, the authors highlighted the importance of working memory in by-ear learning. Musicians frequently sang or hummed notes after pausing playback, indicating that vocal rehearsal may serve as a bridge between perception and performance. The ability to mentally retain short musical phrases and reproduce them on an instrument was a common strategy among participants. Fifth, familiarity with recordings prior to learning appeared to enhance the effectiveness of ear-based learning. Some musicians listened to tracks repeatedly before attempting to play them, or demonstrated genre-specific knowledge that allowed them to anticipate musical patterns. This suggests that pre-exposure and stylistic fluency may scaffold the by-ear learning process. Finally, the study found that theoretical knowledge, particularly regarding harmony and key, aided musicians in identifying chords and notes more efficiently. Those who could name chords or apply scale structures progressed more rapidly than those relying purely on trial-and-error methods. However, the authors caution that this efficiency may stem as much from instrumental fluency as from abstract theoretical understanding. Overall, this study contributes important insights into informal, in-the-wild musical learning practices and calls for future research to refine technological tools that align with the actual strategies musicians use. It also underscores the need for more inclusive datasets and broader participant demographics in future work. In Table xx, I reproduce the hypotheses generated by their study.

```{r, results='asis', echo = FALSE}

# Create the data frame
table_data <- tibble::tibble(
  Hypothesis = c(
    "Desiderata recording interactions change depending on learning scope",
    "Transcription serves no role in the by-ear learning task",
    "Experienced musicians rarely engage with purpose-built tools",
    "A musician’s working memory will dictate their ability to copy notes",
    "Intentional recording familiarization improves by-ear learning",
    "Knowledge of theory helps make note and chord identification more efficient"
  )
  )

# Display the table
knitr::kable(table_data, 
              caption = "Hypotheses about playing by ear strategies generated by Liscio and Brown (2014)")

```

 


#### Playing By Ear Abilities and its Relationship to Other Factors


Playing by ear has been documented as related to sight-reading  [@luceSightreadingEarplayingAbilities1965; @mcphersonAssessmentMusicalPerformance1995; @mcphersonChildMusicianSkill2005], singing, and improvisation/creativity.Playing by ear may help sight-reading because it helps build a mental library for melodies. To be able to sight-read well, one must have a good aural model of how the "sign" translates into "sound". Thus, training aural modelling in general should also help its connection to visual notation.

@haston_playing_2022 argue that singing should be a frequent and integral component of early music instruction. To advance beyond singing alone, a connection between vocalisation and the corresponding instrumental fingerings should be established - in lieu of visual notation. Musicians who both sing and play during the modeling or echo-teaching process strengthen the connection between their ears and fingers, promoting multimodal learning [@haston_playing_2022]. The process of mentally and physically rehearsing a piece "by ear"—through simultaneous singing and fingering - could cultivate a child’s capacity to perceive sound through kinesthetic engagement, thereby promoting the integration of bodily movement with cognitive processes [@galvao1999kinaesthesia; @haston_playing_2022]. @haston_playing_2022 further argue that application of solfège could further facilitate this transition by reinforcing the progression from rote memorisation (e.g., singing on a neutral syllable such as "la") to conceptual understanding (e.g., employing sol-fa syllables and correlating them with instrumental fingerings).

Improvisation is closely intertwined with playing by ear, as both involve real-time generation of music without reading. Many studies of improvisation emphasise the role of the ear: improvisers are essentially composing with their instrument in real time, and to do so, they must listen – to the accompanying music, to their own ideas as they unfold, and to an internal sense of where the music could go next. Psychological models of improvisation [e.g., @JohnsonLaird2002; @Pressing1988] propose that improvisers use a repertoire of memorised licks plus generative rules to create new solos. The selection and execution of those licks is guided by auditory feedback: a player might hear a motif in their head and immediately play it, then listen to what they just played and let that spark the next idea. @Norgaard2011's study of expert jazz improvisers illustrated this iterative process of planning, executing, and monitoring during solos. The musicians described constantly evaluating their output (e.g., thoughts like "was that phrase good? should I repeat it or change it?") and making adjustments on-the-fly. This improvisational thinking requires a well-trained ear to judge one’s musical statements and to hear possibilities before playing them. Because of this, exercises that strengthen playing by ear are often recommended to aspiring improvisers. 


### McPherson's Integrated Model of Musical Skill Development

To situate playing by ear and its development among other skills in an integrative fashion, @mcpherson1993factors proposed and tested a theoretical model that examines the development of key musical performance skills among student instrumentalists. Drawing on both literature and empirical data—student performance outcomes and interviews, McPherson’s model offers a view of how various learning experiences and individual practices contribute to musicianship. The model, later supported by further analysis [@inbook], reveals both direct and indirect pathways between factors such as early musical experiences, quality and length of study, and the development of skills like sight-reading, improvisation, and playing by ear.

One of the central findings of McPherson’s model is the pivotal role of playing by ear. This skill was shown to be the strongest predictor of a student's ability to improvise, suggesting that aural engagement is foundational to more creative aspects of musical performance. Playing by ear was also shown to have a meaningful, though more complex, relationship with sight-reading ability—supporting earlier findings that ear-training may play a more critical role in developing musical fluency than traditionally emphasised [@luceSightreadingEarplayingAbilities1965; @priestPlayingEarIts1989]. If also found that early musical experiences positively influenced students' capacity to play by ear, though they had little impact on sight-reading. Similarly, engaging in enriching activities—such as improvising or playing by ear during practice—had a strong impact on the development of ear-playing skills, but again, less so on sight-reading. Interestingly, the quality of formal study had only a weak influence on both ear-playing and sight-reading, while the length of study had a moderate and consistent effect across multiple performance domains, including rehearsed performance, sight-reading, and playing by ear.

Through qualitative analysis of student interviews, McPherson also identified clear differences in cognitive strategy between less and more skilled performers. Less proficient players often relied on abstract, notation-based thinking, such as trying to identify note names while listening. In contrast, more capable musicians demonstrated a more integrated aural-kinesthetic approach, mentally translating what they heard directly into instrumental actions.

Overall, McPherson's model offers an argument for the centrality of ear-playing in music education, as further iterated in [@haston_playing_2022]. It suggests that developing the ability to play by ear not only supports improvisational skill but also facilitates the integration of aural, visual, and motor domains essential to fluent musicianship. These findings carry significant pedagogical implications, potentially challenging traditional hierarchies in music training and highlighting the potential value of emphasising aural-based learning strategies in instrumental instruction.

```{r, fig.cap="Path analysis of the McPherson (1993) theoretical model. Thicker lines represent stronger relationships and thinner lines weaker relationships from one variable to the next, as shown by the directed arrows. Reproduced with the permission of Gary McPherson.", fig.height=12, fig.width=12, echo = FALSE}

knitr::include_graphics('../img/McPherson_Chapter 8 Figure 3.pdf')

```


#### Interim Summary 

In summary, research in music education converges on the idea that integrating ear-playing experiences – whether through informal learning projects, ear-training exercises, or improvisational activities – significantly enriches musical development. It produces musicians who are more well-rounded, confident, creative, and able to adapt to new musical situations (a crucial trait for professionals). Ear-playing is no longer seen as mere talent or trick; it is increasingly recognised as a pedagogical tool and an objective of instruction in its own right.


### Cognitive Mechanisms Underlying Playing by Ear


In the next section, I move towards describing playing by ear at a more detailed cognitive level. As far as I am aware, no comprehensive cognitive model of playing by ear yet exists. However, several models come very close to describing this phenomenon, and I thus review and later synthesise them here.

In general, music performance relies on three key cognitive skills: goal imaging (imagining the sound), motor production (executing movements), and self-monitoring (hearing and assessing one’s performance) [@lehmann2002acquired; @woody2003explaining]. Similarly, @haston_playing_2022 describe playing by ear as requiring "aural discrimination skills and the alignment of concomitant motor skills: goal imaging, motor production, and self-monitoring. Linking that goal image to motor production is key.". Thus, fluency in playing an instrument and by-ear playing involves creating strong connections between imagined sounds and physical actions—developing ear–hand coordination.


### Auditory Perception

To first play a melody by ear, one must perceive the target melody, as well as the recalled melody as it unfolds. Auditory perception represents a complex cognitive process through which the human brain transforms acoustic vibrations into meaningful sound experiences, involving multiple interconnected neural pathways and processing stages. The process begins with sound wave transduction in the cochlea, where mechanical vibrations are converted into electrical signals that travel through the vestibulocochlear nerve to various brainstem nuclei before reaching the medial geniculate body of the thalamus, which acts as a critical information processing hub that actively shapes auditory representations rather than serving as a simple relay [@bartlettOrganizationPhysiologyAuditory2013]. From the thalamus, processed auditory information reaches the primary auditory cortex in the temporal lobe, where sophisticated computational processes enable the brain to perform what @bregman1990auditory termed "auditory scene analysis" - the fundamental ability to segregate, integrate, and organise complex mixtures of simultaneous sounds into distinct perceptual objects [@sussmanAuditorySceneAnalysis2017]. This cognitive process involves both automatic, stimulus-driven mechanisms that operate without conscious attention, as well as top-down attentional processes that allow selective focus on specific sound sources in noisy environments, such as following a conversation at a cocktail party [@sussmanAuditorySceneAnalysis2017]. The auditory system's remarkable capacity for sound localisation, pitch perception, and timbre recognition emerges from the integration of multiple acoustic cues processed across parallel neural pathways, with attention serving as a limited but flexible resource that can enhance processing of attended sounds while maintaining access to unattended auditory information in neural memory [@carliniAuditoryLocalizationComprehensive2024; @sussmanAuditorySceneAnalysis2017].

### Working Memory and Melodic Perception

With attention applied to an auditory stimulus, tonal information is parsed and generally enters an acoustic store. This acoustic store is encapsulated in a memory system known as *working memory* [@baddeleyWorkingMemory1974; @baddeleyEpisodicBufferNew2000], a form of short term memory system. Cognitive psychology distinguishes between short-term memory and long-term memory in terms of both capacity and duration. Short-term memory (in modern times equated with working memory) is a limited storage system that holds information for mere seconds if not actively rehearsed [@cascellaShortTermMemoryImpairment2025]. In contrast, long-term memory can retain information for days, years, or even a lifetime. These two memory systems differ not only in duration but also in function and mechanism. Working memory acts as a mental "scratchpad" for immediate information processing (such as remembering a phone number long enough to dial it), whereas long-term memory stores more durable knowledge such as facts, personal experiences, and skills. The classic @atkinsonHumanMemoryProposed1968 conceptualised memory as a flow from transient sensory memory, to short-term memory, and eventually to long-term storage. While modern research has refined this modal model, incorporating working memory, the basic distinction remains useful: short-term memory is fleeting unless information is deliberately maintained or encoded into long-term memory.

The construct of working memory is now well-developed in psychology, with the most popular model being @baddeleyWorkingMemory1974’s multi-component model, subsequently updated in @baddeleyEpisodicBufferNew2000. Working memory refers to the ability to transform and manipulate information in short-term memory. In general, it is thought to comprise components for manipulating phonic (in the phonological loop) and visual stimuli (in the visuospatial scratchpad) separately. Music scholars have long recognised the important role of working memory in musical behaviours, particularly those involving aural skills [@chenetteWhatAreTruly2021; @corneliusInteractionRepetitionDifficulty2020; @gatesDevelopingMusicalImagery2021; @karpinskiAuralSkillsAcquisition2000]. Indeed, those with formal music training have widely been documented to have better general working memory capacities [@talaminiMusiciansHaveBetter2017; @talaminiWorkingMemoryMusicians2016], but note, it not seem that musical training causally influences general working memory, as will be discussed shortly [@silasAssociationsMusicTraining2022].


It has been argued that @baddeleyWorkingMemory1983model's standard general working memory model does not sufficiently explain the representation and manipulation of musical stimuli (e.g., see @berzWorkingMemoryMusic1995). Instead, it is proposed that there are other working memory components that represent a different class of working memory called *long-term working memory* [@ericssonLongtermWorkingMemory1995], which particularly rely on experience-driven and domain- specific training in specialised domains, such as formal music training [@lorchChunkingTonalContexts2022] and chess [@chasePerceptionChess1973; @gobetChunkingMechanismsHuman2001; @robbinsWorkingMemoryChess1996; @gobetExpertChessMemory1998]. In music, this enables musical chunks to be formed. @lorchChunkingTonalContexts2022 shows how in melodic processing, musical chunks benefit from a clear tonal context and melodic cells with clear labels (e.g., "C major triad") and the subtleties of the process are additionally influenced by type, size, and number of melodic cells.

In our own research, we have found that a music-specific working memory system can be statistically dissociated from a general working system @silasAssociationsMusicTraining2022. Musical training appears related to musical working memory, which in turn is related to general working memory, but general working memory and musical training and not directly related. One could conceive that general working memory encapsulates musical working memory, which relies more on training and music-specific knowledge. In this way, general working memory probably constrains the development of musical working memory and will always be related to it (potentially bidirectionally), even if musical working memory is somewhat distinct and training-reliant. The implications of this, as discussed in @silasAssociationsMusicTraining2022 are that, musical cognition is subserved by domain-specific faculties (more to do with experience and training) but ultimately both domain-general (more to do more with inherited characteristics).

In @silasLearningRecallingMelodies2023, we further explored the potential reliance on musical vs. non musical faculties in sung recall further. We found that, the handling of relatively stylistically simplistic (i.e, pop) melodies, can almost be thought more of a general working memory task, rather than musical working memory task. This is because, if melodic material is simplistic enough enough that the general population will have had much exposure to their contents, then the importance of musical training will be far less, and sung recall may then become more about general constraints on human memory [@barberWhyTwoHeads2015; @christiansenNoworNeverBottleneckFundamental2016; @cowanMagicalMysteryFour2010; @oberauerWorkingMemoryCapacity2007]. In this way, we found that not all all variance in melodic recall behaviour may be explained in musicological terms, suggesting that domain-general memory mechanisms should not be overlooked in explaining the representation of musical stimuli, at least when they are stylistically simplistic. This suggested the potential application of models and ideas from already well-established theories of produced mental representations in non-musical domains (non-musical serial recall; @andersonFranSimulationModel1972). We concluded that concepts related to general working memory constraints (e.g., non-musical serial recall, item length) are important in explaining melodic recall, potentially more so than any other musicological considerations (e.g., interval representations, tonality) at least when the length of the melodies certainly requires multiple attempts to sing back all the notes (e.g., length 15-48), or with pop melodies which are relatively simple to sing. In other words: the "melodic recall" of relatively simple pop melodies appears to be closely related to "recall" in other memory domains. 


In the non-musical literature on verbal recall exists some relevant non-musical analogues [e.g., from the *Adaptive Control of Thought-Rational*, *ACT-R* literature; @andersonFranSimulationModel1972; @chikhaouiLearningSongACTR2009] to the observations that @slobodaImmediateRecallMelodies1985 made, that over multiple attempts at singing the same melody, participants attempt to sing more notes on each subsequent attempt. The so-called list length effect is the finding that recognition performance is superior for items that are part of a short list than for items that were part of a long list [@kinnellRoleStimulusType2012]. Usually, the literature on verbal memory has used lists of unrelated words as stimuli and asks the participant to recall as many items as they can from memory. Over multiple attempts, @murdockjr.ImmediateRetentionUnrelated1960 specifically found that the shape of the learning curve across attempts can be described as an exponential curve with an asymptote equal to the number of items in a target list. However, word lists have different properties to melodies, which presuppose serial recall (i.e., a note order) and embody important structural features within interval and rhythmic patterns. It is not clear if the unique properties of musical stimuli mean that melodic recall processes are underpinned by fundamentally different processes to their non-musical analogues. In general, the amount of melodic information that a listener can hold in their melodic working memory thus depends on someone's general working memory capacity and their ability to retrieve melodic-chunks from the experience of listening (or practising an instrument). 

Therefore, the handling of musical stimuli in working memory depends ultimately on general working memory, but the more stylistically advanced the features become, the more musical training is required in developing domain-specific expertise (in Western music listeners, familiarity with simplistic pop music does not constitute expertise, but a norm). Thus, someone with a very good general working memory might be able to demonstrate a similar level of musical (e.g., sung recall) performance to someone who has had more musical training. The former’s general faculties may help them monitor their performance as well as someone who has carved out music-specific templates to aid the same task. The underlying reliance on music-specific vs. general working memory may be slightly different, but the observable phenotype similar.

In playing by ear tasks, long term working memory for melodic stimuli underlies the central cognitive component of playing by ear of *auditory imagery*: the ability to internally hear or imagine music without external sound [@geldingEfficientAdaptiveTest2021]. Skilled by-ear players exhibit strong auditory imagery capacities, which enable them to anticipate and mentally "hear" pitches and phrases before playing them as well as the ability to identify and reproduce notes and intervals. Many ear players develop acute relative pitch skills, allowing them to recognise scale degrees or chord tones by ear and map them to their instrument. Some research has examined the role of absolute pitch in ear-playing as well. While absolute pitch (the ability to identify pitches without a reference) can aid certain tasks, it appears to be somewhat rare, even in musician populations (< 30% with absolute pitch; @gregersenAbsolutePitchPrevalence1999; @leiteMusicProficiencyQuantification2016). Instead, most musicians seem to rely on well-honed relative pitch and tonal schema to play by ear in real musical contexts. For instance, learning a song by ear often involves detecting its tonal center and scale, recognizing common chord progressions (e.g. the 12-bar blues or II–V–I progression in jazz), and using those frameworks to guide note choices. @Johansson2004, in a study of rock musicians, observed that ear players often identify familiar "clichés, harmonic formulas and other stylistic traits" of the genre to decode songs on the fly. In other words, they listen for characteristic chord patterns or melodic motifs, which helps them predict upcoming pitches. This genre-dependent pattern recognition underscores that ear-playing proficiency is partly a product of genre-specific listening experience. Musicians essentially build a library of musical phrases and progressions in memory by extensive listening; when a new piece is heard, they match it to known patterns. Over time, this process can become quite automatic. Therefore, melodic cognition in playing by ear involves both fine-grained perception (discriminating pitches and intervals) and higher-order schema (tonal and stylistic expectations), all coordinated through the musician’s auditory imagery and memory systems. 

In general, playing by ear, sight-reading, and interacting musically help build an internal "aural database," expanding musicians' capacity to memorize more music [@fine2006music; @haston_playing_2022; @odam1995sound]. Memorising music relies on integrating aural, visual, and kinesthetic codes, making learning more robust and multidimensional [@hallam1998predictors]. Playing by ear seems to strengthen aural and kinesthetic memory - and possibly visual memory - as musicians often mentally visualise notation or musical structure [@woody2010; @woody2019psychology]. Aural imagery allows musicians to develop and store mental representations of melodic and harmonic patterns, which supports more efficient future learning [@freymuth1999mental]. Playing by ear promotes "inner hearing" [@haston_playing_2022; @woody2012] - allows musicians to form a mental model of the sound they are going to play. Developing inner hearing allows performers to "listen with expectation" [@haston_playing_2022]



#### Sensorimotor Integration and Neural Basis


Behavioural evidence suggests that the auditory imagery generated (in working memory) can guide performance by activating sensorimotor representations  [@novembreConceptualReviewActionperception2014a; @kellerAuditoryImageryShapes2010; @kellerPlanningExecutionShort2006; @pfordresherAuditoryFeedbackMusic2005; @pfordresherEffectsHearingPresent2006]. Imagining sounds that correspond to specific instrumental actions can trigger the motor programs for those actions. In other words, when an experienced musician internally hears a melody, that imagery is closely coupled with the fingerings or movements needed to produce it, aligning with the concept of *audiation* in music education [@gordon2001; @gordonLearningSequencesMusic2007], whereby musicians "hear" music in their mind as a precursor to performing it. Neuroimaging evidence further supports this auditory–motor linkage. For example, studies show that simply imagining musical sequences engages regions of the brain’s motor planning network in trained musicians [@bangertSharedNetworksAuditory2006; @dausilioCrossmodalPlasticityMotor2006; @haueisenInvoluntaryMotorActivity2001; @novembreConceptualReviewActionperception2014a]. @kellerMentalImageryMusic2012 noted that mental imagery in music performance serves important functions such as planning upcoming notes and monitoring intonation. Similar brain activity occurs when music is heard and when it is imagined, suggesting that musicians can internally "hear" accurate pitches and "feel" the appropriate muscular movements during mental practice [@alluri2017musicalimagery; @gordon2018recruitment; @haston_playing_2022]. This integration of auditory imagery with the sensation of performance highlights the constant cross-modal processing involved in instrumental playing [@ross1985mentalpractice; @woody2012]. In skilled musicians, auditory and motor regions of the brain form strong bidirectional connections due to training. @novembreConceptualReviewActionperception2014a review evidence that musical training "couples" perception and action systems, such that perceiving a musical phrase can automatically activate the motor program to play it. This reflects the brain’s general action–perception coupling mechanism, where anticipated effects (like a heard note) can trigger the motor command associated with producing that effect. In the context of ear-playing, this means a violinist might hear a phrase in their mind and feel the impulse to execute the fingerings and bowings, or a pianist hearing a chord might internally rehearse the hand shape required. 

A particularly vivid demonstration of advanced audiomotor integration is seen in jazz improvisers. @Harris2016 compared improvising pianists with classical score-dependent pianists in their ability to reproduce unfamiliar melodies by ear. They found that the improvising (ear-trained) musicians had a "superior ability [...] to replicate both the pitch and rhythm of aurally perceived music at the keyboard, not only in the original key, but also in other tonalities". In other words, those accustomed to playing by ear could accurately pick up a tune and immediately play it and even transpose it, far outperforming the note-bound players. The same study linked this behavioral skill to neural differences: an *fMRI* comparison revealed that improvising musicians showed enhanced activation in a right dorsal fronto-parietal network during audiation tasks, suggesting more efficient neural pathways for audiomotor transformations. These brain regions (including posterior parietal and premotor cortices) are thought to support mapping auditory inputs to motor responses. Likewise, @limbNeuralSubstratesSpontaneous2008's *fMRI* study of jazz improvisation found that spontaneous musical creation involves distinct neural dynamics (including heightened activity in motor-planning areas and the suppression of self-monitoring regions), illustrating the brain's adaptation to real-time ear-to-hand performance. Collectively, research suggests that improvisation - and probably playing by ear - is a whole-brain activity: it recruits auditory perception circuits, memory and planning areas, and motor execution networks in a tightly coordinated loop. With training, this loop becomes highly optimised – as seen in professionals who can hear a melody once and immediately play it. Sensorimotor integration is thus at the core of playing by ear, enabling the immediate translation of heard musical ideas into played music.

## Relation to Playing By Ear Research in the Music Education Literature

To summarise the cognitive psychological literature reviewed and relate it back to the music education literature: playing by ear engages working memory and long-term memory in unique ways. Musicians must temporarily hold incoming auditory information (i.e., the sounds just heard) while simultaneously planning and executing motor responses on their instrument. This places demands on the phonological loop as well as domain-specific long term working memory for melodies, as well as the integration of auditory and motor memory. Studies have explored how working memory for musical material might differ between those who rely on ear-playing and those who rely on notation. @Nichols2018 compared jazz and classically trained musicians on auditory working memory tasks and found notable differences. Jazz players – who typically emphasise learning by ear – outperformed classical players in remembering and reproducing heard melodies, especially when they had to play back the melodies on an instrument. In this study, musicians were asked to recall the final notes of sequences after a distraction, either by writing/singing or by playing them on a piano. Jazz musicians showed superior recall for aurally presented melodies when responding instrumentally (playing by ear), and their scores positively correlated with years of jazz experience. The authors concluded that jazz training (i.e., involving extensive ear-playing and improvisation experience) might enhance domain-specific working memory capacity which allows the better handling of musical information in real time, especially relevant to improvised music contexts. Furthermore, ear-trained musicians often develop efficient cognitive chunking strategies. Instead of processing every note in isolation, they rely on familiar patterns and harmonic sequences stored in long-term memory. When reproducing a melody by ear, skilled musicians may anticipate likely chord progressions or melodic resolutions based on their internalised "musical grammar". This predictive listening reduces memory load by allowing the musician to generate expectations. In this way, @woody2010 found that musicians with extensive vernacular (informal) music experience could learn melodies by ear with fewer repetitions than classically trained musicians, thanks in part to better anticipation of melodic/harmonic patterns. @WoodyLehmann2010 studied how well college music majors could learn melodies by ear. They compared students with "vernacular" music backgrounds (e.g., jazz, rock) to those trained mainly through formal instruction. The vernacular musicians outperformed the formal ones, needing fewer attempts to accurately sing or play back melodies. On average, vernacular students required 3 attempts to sing and 3.8 to play melodies, compared to 6.4 and 10.6 for formal students, suggesting that vernacular training places emphasis on both melodic memory (goal imaging) and the ability to reproduce melodies on instruments (motor production). The ear-trained players applied a "more sophisticated knowledge base to generate accurate expectations" about how a melody would unfold. In contrast, formally trained players without strong ear-playing backgrounds used less efficient, more surface-level strategies for encoding melodies. This implies that cognitive schemas and pattern knowledge (acquired largely through listening and imitating) free up working memory resources during playing by ear by providing ready-made chunks and expectations. Expert playing by ear musicians form rich mental representations of pieces, often encoding not just the melodic contour but also harmonic and structural features. Musicians highly skilled in ear-playing use "harmonically oriented integrated cognitive strategies," whereas less experienced ear-players rely on more fragmentary, note-by-note approaches [@woody2020]. In Woody’s study, university music students who were guided to focus on a melody’s underlying chord progression developed a more substantive "goal image" of the tune, which in turn improved their ability to learn it by ear. This indicates that adding harmonic context to one’s auditory imagery (for instance, knowing the chord changes) leads to more robust mental representations and facilitates ear-playing. Thus, proficient playing by ear involves vivid auditory imagery and schema-like memory for musical patterns, especially harmonic frameworks.


## Pfordresher's Cognitive Model of Singing Accuracy and H-PAC Models


@pfordresherTheoreticalPerspectivesSinging2015 provided a foundational overview of theoretical approaches to singing accuracy, emphasising the complexity of the cognitive and sensorimotor processes involved in vocal production. They highlight that accurate singing depends on more than just pitch perception or motor ability—it arises from the interaction between perceptual and motor systems, including how auditory targets are represented and transformed into vocal output.

```{r, echo = FALSE, fig.cap = "Pfordresher et al.'s (2015) cognitive model of singing accuracy. Reproduced with the permission of Peter Pfordresher."}

knitr::include_graphics('../img/pfordresher_singing_model.jpg')


```


This perspective sets the stage for the *H-PAC* (Hierarchical Perception-Action Coupling) model later proposed by @pfordresherSoundActionMusic2019, which formalises these ideas into a mechanistic account of how singing behaviour emerges from hierarchical layers of processing. According to the *H-PAC* model, musical performance involves the dynamic coupling of auditory perception with motor planning and execution, structured across multiple levels—from abstract representations such as melodic contour, down to specific articulatory commands that activate the vocal apparatus. These commands refer to the fine-grained motor instructions sent to the muscles involved in vocal production (e.g., the larynx, tongue, lips), translating high-level musical goals into physical sound.


```{r, fig.cap = "Pfordresher et al.'s (2019) H-PAC model. Reproduced with the permission of Peter Pfordresher."}

knitr::include_graphics('../img/pfordresher_hpac_model.png')


```


A central feature of both the -@pfordresherTheoreticalPerspectivesSinging2015 and -@pfordresherSoundActionMusic2019 accounts is the notion that poor-pitch singing often reflects a disruption in the mapping between auditory targets and motor output, rather than a deficit in either domain alone. This helps explain why some individuals with intact pitch perception still struggle to produce accurate vocal pitches. Within the *H-PAC framework*, such difficulties are attributed to failures in either feedforward mechanisms - which plan motor actions based on internally generated auditory representations - or feedback mechanisms, which compare ongoing output with auditory goals and make real-time corrections.

At the low level, this cognitive system includes an auditory feedback loop, wherein external sound is encoded as perceptual representations of pitch, timbre, duration, and loudness. These low-level representations are used to guide sensorimotor planning through a translation mechanism, which maps perceptual information onto physical actions. In singing, this mapping guides processes like respiration, phonation, and articulation. In instrumental performance, however, these actions would be instrument-specific: finger coordination for piano, violin, or clarinet; embouchure control for brass and woodwinds; or arm and wrist movements for percussion.

Beyond low-level mapping, higher-level cognitive processes support the categorisation and structuring of auditory input. Drawing on long-term memory [@baddeleyMemory2009; @ericssonLongtermWorkingMemory1995], listeners use mental templates to extract musical features such as tonality, melodic contour, and phrasing. These abstract representations provide top-down input to inform sensorimotor planning, while also being shaped by real-time auditory feedback. The result is a bidirectional architecture, in which perception and action are constantly influencing one another.

Crucially, this same system can be extended to playing by ear—the reproduction of music on an instrument without notation. In such contexts, an auditory stimulus is perceived, mentally represented, and mapped onto the motor system of a particular instrument. The perceptual and cognitive processes involved in encoding, segmenting, and categorising the input remain largely the same as in singing; it is primarily the motor modality that differs. Whether reproducing a melody vocally or on a violin, successful performance depends on the strength of the mapping between internal sound representations and the corresponding motor output. One difference between singing and instrumental playing is the different kinds of kinaesthetic perceptual traces and memories that may reinforce learning [@galvao1999kinaesthesia].

Thus, both @pfordresherTheoreticalPerspectivesSinging2015 and the @pfordresherSoundActionMusic2019 *H-PAC* model offer a unified theoretical framework for understanding musical reproduction across domains. By situating performance within a hierarchically organised, interactive system that links perception, cognition, and motor control, this approach provides a compelling account of how individuals produce music—either through singing or playing by ear. It also offers explanatory power for understanding individual differences in performance ability, the nature of imitation deficits, and potential strategies for remediation or training.


## Baker's Computational Model of Melodic Dictation


@bakerModelingMelodicDictation2019's computational model of melodic dictation presents a stage-based framework that simulates how listeners perceive, process, retain, and ultimately transcribe melodies into symbolic notation. Whilst melodic dictation - the reproductive act of transcribing a melody into visual notation on paper - is different to melodic recall/playing by ear, this model has some useful features to add depth to the other frameworks discussed above.


The model begins with a perception stage, during which the dictation object — typically a short monophonic melody — is encoded into a set of low-level melodic features. For simplicity, @bakerModelingMelodicDictation2019 follows @pearceConstructionEvaluationStatistical2005's representation of both pitch (note and scale degree) and timing (rhythm and interonset interval). Whilst @bakerModelingMelodicDictation2019 only uses these features for convenience, it is likely that other higher order melodic features are relevant to this task as well as playing by ear. An important part of this model is the notion that as a melody unfolds serially (note-by-note), each new note added to the working memory buffer for the target melody adds a new degree of *information content*, which reflects a potential load on working memory. The information content is computed based on a users stylistic knowledge of Western tonal music that has in turn been created through enculturation (i.e., many years of listening; @pearceConstructionEvaluationStatistical2005). The more training a musician has undertaken, the larger their library of "learned" musical chunks that they can rely on. Each transcriber has their own working memory capacity for such information, which when reached should lead to a deterioration in memory and subsequent transcription performance. After hearing and representing the melody, a search for representations of that melody in ones "prior knowledge". If a match is found for a representation that has been explicitly learned, then the melody or segment can enter the transcription module and be transcribed. If there is a gap between prior knowledge and the target melody, on patches will be transcribed, based on any matches that could be found for melodic subsets (i.e., N-grams).


@bakerModelingMelodicDictation2019's conception of *cumulatative information content* and the search from melodic N-Gram chunks across a lifetime of expertise acquisition is useful and highly relevant to playing by ear. In playing by ear, both ideas would be implicated in representing the heard melody and the recalled melody.


## Models of Sung Recall

Lastly, related to playing by ear is singing by ear, or "sung recall". My @silasSingingAbilityAssessment2023 study investigated sung recall by examining its relationship ,first, with other related skills and participant attributes. Demographically, better sung recall ability ability was associated with more musical training and a younger age (although the latter effect was small). Our modelling suggested that a sizeable proportion performance in sung recall can be attributed to individual differences, which makes sense for a task in which one can develop high levels of domain-specific expertise via musical training. We found that melodic discrimination, pitch imagery abilities, and mistuning perception appear to be fundamental skills contributing to melodic sung recall. The sung recall score we devised moderately correlated with self-reported singing ability and musical training. However, it showed no significant correlation with visuospatial working memory or pitch discrimination, aligning with previous research and suggesting that singing ability is not closely linked to low-level perceptual processes [@pfordresherPoorpitchSingingAbsence2007], even though such working memory processes might be ultimately partially responsible for performance. An important aspect of the study was to suggest which computational melodic features could predict sung recall performance. Features which indicate melodic complexity turned out to be relevant predictors of sung recall performance: features indicating melody length, contour, tonality, statistical occurrence of N-grams in the melody, and durational complexity were important. As previously mentioned, melodic features do not be important predictors of sung recall when melodies are relatively simplistic; here, only melody length turns out to be an important predictor  [@silasLearningRecallingMelodies2023].


Another significant finding from @silasLearningRecallingMelodies2023 (presented there in Figure 8), regards how similarity between target and recall changes as a function of attempt and the specific section of the melody (beginning, middle, end). The results show that similarity performance increases more rapidly for the beginning of the melody compared to the middle and end across successive attempts. This indicates that participants tend to stabilise their recall of the initial melodic segments earlier than the middle or end sections. The end sections, in particular, show a slower rate of improvement, suggesting that the latter parts of a melody are more challenging to accurately recall perhaps due to the higher working memory load as a result of having to remember more notes, the later you are in a position, or that generally people engaging in sung recall *prioritise* getting the earlier parts melody correct first.  This finding supports the theory that memory encoding is stronger for the beginning of sequences, a phenomenon consistent with the primacy effect observed in other types of serial recall tasks. It also highlights that recall accuracy is not uniformly distributed across a melody, with the initial segments being more robustly learned compared to later ones.

Moreover, the results highlighted that similarity scores increase with each successive attempt, but the rate of improvement diminishes after the third or fourth attempt. This pattern suggests that the most substantial gains in melodic recall occur early in the learning process, followed by incremental refinements in pitch and rhythm accuracy. Additionally, melodies presented as vocal audio excerpts resulted in higher recall accuracy compared to piano sound presentations, indicating that the human voice might provide additional mnemonic cues that aid in memory encoding. Overall, the study's use of similarity-based metrics, particularly the *opti3* metric which integrates pitch intervals, harmonic progression, and rhythmic similarity, offers a more nuanced and accurate assessment of how melodies are learned and recalled and the present manuscript extends this approach.

 
### Playing by Ear Research: Conclusion

The phenomenon of playing by ear sits at the intersection of cognitive skill, pedagogical practice, and musical creativity. From a cognitive standpoint, playing by ear engages complex mental processes: vivid auditory imagery, specialised working memory, pattern recognition, and a tight coupling of perception and action. Extensive ear-playing experience appears to shape the brain, leading to more efficient audiomotor networks. Developmentally, learning to play by ear can begin early and flourish in environments that encourage informal exploration. Incorporating ear-playing into formal instruction – as research in music education has shown – yields benefits for aural skills, musical understanding, and student motivation. In jazz and other professional domains, playing by ear is not only a skill to acquire but a mode of musical existence: it underpins the ability to improvise and to connect with music on a deeply intuitive level. Individual differences certainly influence how people approach playing by ear, yet studies underline that with the right strategies and experiences, virtually any musician can improve their ear-playing ability. This rich body of literature refutes the old notion that playing by ear is a mysterious gift; instead, it is a multifaceted skill set that can be analysed, taught, and learned. As @WoodysResearchAppear2018 observed, developing ear-based musicianship imbues music making with a certain "humanness" – it reconnects performers with the fundamentally aural nature of music. In practical terms, musicians who play by ear often learn new material faster, memorise more effectively, and perform with greater expressivity and flexibility. For educators, the implication is clear: fostering playing by ear alongside other skills produces more well-rounded and versatile musicians. For researchers, playing by ear remains a fertile topic, raising questions about auditory cognition and expert memory. The literature so far, grounded in cognitive psychology, music psychology, and systematic musicology, provides a compelling case that playing by ear is both an essential subject of study and an invaluable aspect of musical practie – from the novice learner picking out a tune, to the jazz virtuoso crafting a solo, guided all the while by the inner ear.
 


## A Comprehensive Theoretical Model of Playing By Ear

Consequently, synthesising the results above, we can characterise playing by ear as involving the following processes. Where I mark the text grey, I highlight an additional suggestion beyond the reviewed literature, as a contribution from my own theory development. I will refer to the person playing by ear as the "player" in the following description.


Playing by ear first requires a target melody to be perceived. Due to the nature of serial presentation, a presented auditory melody unfolds note-by-note. From the acoustic signal, the player decodes the fundamental frequencies into a melodic object based on their structural knowledge, in term based on a lifetime of listening (enculturation). The ability to do this also depends on the acoustic features themselves, especially its timbre. The closer the timbre to the player's on instrument, the easier it is to decode (and later recall) because the player can draw not only on melodic memory, memory for absolute pitch, including multimodal representations that might activate kinaesthetic/tactile traces (CITE). This overall ability to image the correct melodic object is "audiation". More experienced listeners and more musical training are better able to audiate, segmenting/chunking the target melody into relevant chunks. Each time a new note is heard from the melody, its strain on working memory increases based on the information content in each new note and the emergent tonal, rhythmic, metric and other structural features. In long term working memory for melodies, N-Gram chunks are stored distinct entities, each with their own properties - in particular, the amount that the player has experienced them in their listening experiences (including practising an instrument). This statistical sensibility should approximate the real frequency of occurrence in music. If there are visual cues (e.g., visual notation or a model - like a teacher to immitate) accompanying the audiated melody, these will be decoded in their respective working memory slave systems and potentially integrated in the episodic buffer, to form a multimodal representaiton that could inform overall recall.


Once the target melody has completed being played, it will be stored in a short term melodic memory buffer and flagged as a point of reference. The longer this representation remains in this buffer without mental or physical rehearsal, the more it will decay in memory in a non-linear fashion. The extent of the target melody's burden on working memory load dictates if how the player will attempt to recall the melody, if at all. If working memory capacity is greatly surpassed, with the player able to retrieve no reliable representations, they may not attempt to recall the melody at all. If they have some vague representations, they might attempt to improve a sketch of what they heard. In a performance/high pressure situations (e.g., an aural exam), maybe they will have some fallback approach to attempt to respond musically or "style it out". Depending on the context, maybe the player (e.g., in the practising/learning) will take a strategy to help reinforce the melodic image because attempting to reproduce it, for example, by singing it.

Eventually, if at least some - if not all - of the melody of the is represented reliably in melodic long term working memory, the player will attempt to produce it in the recall and an action plan will be setup to reproduce the melody. Potentially, clear motor action plans will have already been activated in respond to the stimulus in the form of imagined actions to reproduce the sequence. The player will direct their attention to the instrument and the tactile sensations and motoric actions required to reproduce the sound. As they produce each note, the recalled melody will be perceived by the ear and parsed again, note-by-note into first basic auditory representations in the phonological loop, but then higher order melodic structural ones in melodic working memory. Because the recalled melody is being physically produced by the player, it will have richer cues: e.g., visual ones, for a pianist directing their fingers to different keys, tactile ones for all instruments, motoric cues (i.e., the pattern tactile sensations). Again, they will be parsed eventually into an unfolding multimodal melodic representation.

Every time a new note is recalled, a melodic similarity algorithm will compute on the latest version of the recalled melody in relation to the target melody. Generally, as each new note is recalled, the similarity should go up. If the similarity goes down, this will be flagged as a prediction error, feeding back to motor plans and potentially causing the player to make adjustments to their motor plans. The player will presumably attempt to make the rest of the recall maximise the similarity, even if certain notes or rhythms have clearly violated the possibility of perfect similarity. Typically, target melodies that were not held strongly enough in working memory or where there were errors in the recall will lead to shorter recalls, whereby the player may stop, perhaps to re-imagine the melodic object, or, if possible, to take another attempt at hearing it and trying again. If there are multiple attempts, which is usually the case in learning a melody, each attempt will increase in length and similarity, until the length of target and recall match and there is perfect similarity, or, if this is not possible in a given (learning) session, working on that melody will eventually be terminated once fatigue or motivation is sufficiently low. Returning to replay that melody at a later time, especially after a night's sleep, due to consolidation effect, should typically make the process easier next time, so long as the melody in question was too difficult - and therefore, the feasibility of this is a function of a melody's difficulty, which is also a function of a player's ability (which is in turn a function of their musical training and general working memory capacity). I represent this description in Figure xx.

```{r fig.cap = "A Theoretical Cognitive Explanatory Model of Playing By Ear"}


knitr::include_graphics('../img/PBE Computational Model.png')


```

