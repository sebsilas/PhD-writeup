<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>13 Models of sung recall | _main.knit</title>
  <meta name="description" content="" />
  <meta name="generator" content="bookdown 0.42 and GitBook 2.6.7" />

  <meta property="og:title" content="13 Models of sung recall | _main.knit" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="13 Models of sung recall | _main.knit" />
  
  
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="pfordreshers-cognitive-model-of-singing-accuracy.html"/>
<link rel="next" href="non-musical-models-of-serial-recall.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="table-of-contents.html"><a href="table-of-contents.html"><i class="fa fa-check"></i><b>1</b> Table of Contents</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#further-researchto-do"><i class="fa fa-check"></i><b>2.1</b> Further Research/To Do</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="motivations.html"><a href="motivations.html"><i class="fa fa-check"></i><b>3</b> Motivations</a></li>
<li class="chapter" data-level="4" data-path="generalising-beyond-jazz.html"><a href="generalising-beyond-jazz.html"><i class="fa fa-check"></i><b>4</b> Generalising beyond jazz</a></li>
<li class="chapter" data-level="5" data-path="computational-modelling.html"><a href="computational-modelling.html"><i class="fa fa-check"></i><b>5</b> Computational modelling</a></li>
<li class="chapter" data-level="6" data-path="what-is-playing-by-ear.html"><a href="what-is-playing-by-ear.html"><i class="fa fa-check"></i><b>6</b> What is playing by ear?</a>
<ul>
<li class="chapter" data-level="6.1" data-path="what-is-playing-by-ear.html"><a href="what-is-playing-by-ear.html#learning-to-play-by-ear"><i class="fa fa-check"></i><b>6.1</b> Learning to play by ear</a></li>
<li class="chapter" data-level="6.2" data-path="what-is-playing-by-ear.html"><a href="what-is-playing-by-ear.html#research-questions"><i class="fa fa-check"></i><b>6.2</b> Research questions</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="music-and-combinatorics.html"><a href="music-and-combinatorics.html"><i class="fa fa-check"></i><b>7</b> Music and combinatorics</a></li>
<li class="chapter" data-level="8" data-path="background.html"><a href="background.html"><i class="fa fa-check"></i><b>8</b> Background</a>
<ul>
<li class="chapter" data-level="8.1" data-path="background.html"><a href="background.html#historical-approaches-to-improving-playing-by-ear"><i class="fa fa-check"></i><b>8.1</b> Historical approaches to improving playing by ear</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="melody-as-cognitive-psychology.html"><a href="melody-as-cognitive-psychology.html"><i class="fa fa-check"></i><b>9</b> Melody as Cognitive Psychology</a></li>
<li class="chapter" data-level="10" data-path="theoretical-model.html"><a href="theoretical-model.html"><i class="fa fa-check"></i><b>10</b> Playing By Ear: A Theoretical Model</a></li>
<li class="chapter" data-level="11" data-path="pfordreshers-h-pac-model.html"><a href="pfordreshers-h-pac-model.html"><i class="fa fa-check"></i><b>11</b> Pfordresher‚Äôs H-PAC model</a></li>
<li class="chapter" data-level="12" data-path="pfordreshers-cognitive-model-of-singing-accuracy.html"><a href="pfordreshers-cognitive-model-of-singing-accuracy.html"><i class="fa fa-check"></i><b>12</b> Pfordresher‚Äôs cognitive model of singing accuracy</a>
<ul>
<li class="chapter" data-level="12.1" data-path="pfordreshers-cognitive-model-of-singing-accuracy.html"><a href="pfordreshers-cognitive-model-of-singing-accuracy.html#bakers-computational-model-of-melodic-dictation"><i class="fa fa-check"></i><b>12.1</b> Baker‚Äôs computational model of melodic dictation</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="models-of-sung-recall.html"><a href="models-of-sung-recall.html"><i class="fa fa-check"></i><b>13</b> Models of sung recall</a></li>
<li class="chapter" data-level="14" data-path="non-musical-models-of-serial-recall.html"><a href="non-musical-models-of-serial-recall.html"><i class="fa fa-check"></i><b>14</b> Non-musical models of serial recall</a></li>
<li class="chapter" data-level="15" data-path="wm-bits.html"><a href="wm-bits.html"><i class="fa fa-check"></i><b>15</b> WM bits</a></li>
<li class="chapter" data-level="16" data-path="bringing-it-together.html"><a href="bringing-it-together.html"><i class="fa fa-check"></i><b>16</b> Bringing it together</a>
<ul>
<li class="chapter" data-level="16.1" data-path="bringing-it-together.html"><a href="bringing-it-together.html#moving-from-theoretical-to-computational"><i class="fa fa-check"></i><b>16.1</b> Moving from Theoretical to Computational</a></li>
<li class="chapter" data-level="16.2" data-path="bringing-it-together.html"><a href="bringing-it-together.html#mathematical-representation"><i class="fa fa-check"></i><b>16.2</b> Mathematical Representation</a></li>
<li class="chapter" data-level="16.3" data-path="bringing-it-together.html"><a href="bringing-it-together.html#algorithm-flow"><i class="fa fa-check"></i><b>16.3</b> Algorithm Flow</a></li>
<li class="chapter" data-level="16.4" data-path="bringing-it-together.html"><a href="bringing-it-together.html#final-equation"><i class="fa fa-check"></i><b>16.4</b> Final Equation</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="strategies.html"><a href="strategies.html"><i class="fa fa-check"></i><b>17</b> Strategies</a></li>
<li class="chapter" data-level="18" data-path="learning-forgetting.html"><a href="learning-forgetting.html"><i class="fa fa-check"></i><b>18</b> Learning, forgetting</a></li>
<li class="chapter" data-level="19" data-path="the-melodic-mind-as-item-bank.html"><a href="the-melodic-mind-as-item-bank.html"><i class="fa fa-check"></i><b>19</b> The Melodic Mind As Item Bank</a></li>
<li class="chapter" data-level="20" data-path="predictions.html"><a href="predictions.html"><i class="fa fa-check"></i><b>20</b> Predictions:</a></li>
<li class="chapter" data-level="21" data-path="melodic_networks.html"><a href="melodic_networks.html"><i class="fa fa-check"></i><b>21</b> Melodic corpora as networks</a></li>
<li class="chapter" data-level="22" data-path="similarity-simulation-model.html"><a href="similarity-simulation-model.html"><i class="fa fa-check"></i><b>22</b> Similarity Simulation Model</a></li>
<li class="chapter" data-level="23" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html"><i class="fa fa-check"></i><b>23</b> A computational ecosystem</a>
<ul>
<li class="chapter" data-level="23.1" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#pyin"><i class="fa fa-check"></i><b>23.1</b> pyin:</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="psychologically-meaningful-musical-item-banks-itembankr.html"><a href="psychologically-meaningful-musical-item-banks-itembankr.html"><i class="fa fa-check"></i><b>24</b> Psychologically meaningful musical item banks: itembankr</a>
<ul>
<li class="chapter" data-level="24.1" data-path="psychologically-meaningful-musical-item-banks-itembankr.html"><a href="psychologically-meaningful-musical-item-banks-itembankr.html#datasets"><i class="fa fa-check"></i><b>24.1</b> Datasets</a></li>
<li class="chapter" data-level="24.2" data-path="psychologically-meaningful-musical-item-banks-itembankr.html"><a href="psychologically-meaningful-musical-item-banks-itembankr.html#other-useful-functions"><i class="fa fa-check"></i><b>24.2</b> Other useful functions</a></li>
<li class="chapter" data-level="24.3" data-path="psychologically-meaningful-musical-item-banks-itembankr.html"><a href="psychologically-meaningful-musical-item-banks-itembankr.html#conclusion"><i class="fa fa-check"></i><b>24.3</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="ability_tests.html"><a href="ability_tests.html"><i class="fa fa-check"></i><b>25</b> Ability Tests</a></li>
<li class="chapter" data-level="26" data-path="calibration_studies.html"><a href="calibration_studies.html"><i class="fa fa-check"></i><b>26</b> Calibration studies</a></li>
<li class="chapter" data-level="27" data-path="melsim_development.html"><a href="melsim_development.html"><i class="fa fa-check"></i><b>27</b> Development of a melodic similarity algorithm for short recalled melodies</a></li>
<li class="chapter" data-level="28" data-path="pbet_online_study.html"><a href="pbet_online_study.html"><i class="fa fa-check"></i><b>28</b> Model of melodic difficulty</a></li>
<li class="chapter" data-level="29" data-path="item_curation.html"><a href="item_curation.html"><i class="fa fa-check"></i><b>29</b> Item curation</a></li>
<li class="chapter" data-level="30" data-path="heterogeneity_and_item_bank_sampling.html"><a href="heterogeneity_and_item_bank_sampling.html"><i class="fa fa-check"></i><b>30</b> Heterogenity and item bank sampling</a>
<ul>
<li class="chapter" data-level="30.1" data-path="heterogeneity_and_item_bank_sampling.html"><a href="heterogeneity_and_item_bank_sampling.html#via-item-response-theory-irt-difficulty"><i class="fa fa-check"></i><b>30.1</b> via item response theory (IRT) (difficulty)</a></li>
<li class="chapter" data-level="30.2" data-path="heterogeneity_and_item_bank_sampling.html"><a href="heterogeneity_and_item_bank_sampling.html#via-similarity"><i class="fa fa-check"></i><b>30.2</b> via similarity</a></li>
<li class="chapter" data-level="30.3" data-path="heterogeneity_and_item_bank_sampling.html"><a href="heterogeneity_and_item_bank_sampling.html#via-difficultysimilarity-hybrid"><i class="fa fa-check"></i><b>30.3</b> via difficulty/similarity hybrid</a></li>
</ul></li>
<li class="chapter" data-level="31" data-path="item_banks_and_similarity.html"><a href="item_banks_and_similarity.html"><i class="fa fa-check"></i><b>31</b> Approaches to similarity for large scale corpora</a>
<ul>
<li class="chapter" data-level="31.1" data-path="item_banks_and_similarity.html"><a href="item_banks_and_similarity.html#problem"><i class="fa fa-check"></i><b>31.1</b> Problem:</a></li>
<li class="chapter" data-level="31.2" data-path="item_banks_and_similarity.html"><a href="item_banks_and_similarity.html#approach-1-similarity-of-features-as-proxy-for-melodic-similarity"><i class="fa fa-check"></i><b>31.2</b> Approach #1: similarity of features as proxy for melodic similarity</a></li>
<li class="chapter" data-level="31.3" data-path="item_banks_and_similarity.html"><a href="item_banks_and_similarity.html#approach-2-generative-similarity"><i class="fa fa-check"></i><b>31.3</b> Approach #2: Generative similarity</a></li>
<li class="chapter" data-level="31.4" data-path="item_banks_and_similarity.html"><a href="item_banks_and_similarity.html#approach-3-on-breaking-up-items-into-ngrams-store-representationssimilarity."><i class="fa fa-check"></i><b>31.4</b> Approach #3: on breaking up items into ngrams, store representations/similarity.</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="reviewing_and_spaced_repetition.html"><a href="reviewing_and_spaced_repetition.html"><i class="fa fa-check"></i><b>32</b> Reviewing and spaced repetition</a></li>
<li class="chapter" data-level="33" data-path="identify-correct-vs-incorrect-ngrams-in-a-recall-add-incorrect-ngrams-to-beginning-of-session-buffer.html"><a href="identify-correct-vs-incorrect-ngrams-in-a-recall-add-incorrect-ngrams-to-beginning-of-session-buffer.html"><i class="fa fa-check"></i><b>33</b> identify correct vs incorrect ngrams in a recall: add incorrect ngrams to beginning of session buffer</a></li>
<li class="chapter" data-level="34" data-path="visual_vs_auditory_learning_pbe.html"><a href="visual_vs_auditory_learning_pbe.html"><i class="fa fa-check"></i><b>34</b> Reviewing and spaced repetition</a></li>
<li class="chapter" data-level="35" data-path="identify-correct-vs-incorrect-ngrams.html"><a href="identify-correct-vs-incorrect-ngrams.html"><i class="fa fa-check"></i><b>35</b> identify correct vs incorrect ngrams</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./"></a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="models-of-sung-recall" class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number">13</span> Models of sung recall<a href="models-of-sung-recall.html#models-of-sung-recall" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Lastly, I synthesise models from my own research regarding sung melodic recall. My <span class="citation">@silasSingingAbilityAssessment2023</span> study investigated sung recall by examining its relationship with other related skills and participant attributes. Demographically, better sung recall ability ability was associated with more musical training (ùõΩ = 0.07), a younger age (ùõΩ = -0.05), and being female (ùõΩ = -0.03), though the latter two effects were small. The findings suggest that while musical training can enhance singing ability, inherent skills might also predispose individuals to seek musical training. Moreover, there was a relatively large difference between the marginal and conditional R^2 values, which suggests that there is a sizeable proportion of individual differences in the sample of participants tested which explains SAA performance which shows that individual differences should explain performance on a task in which one can develop high levels of domain-specific expertise.</p>
<p>We found there that melodic discrimination, pitch imagery abilities, and mistuning perception appear to be fundamental skills contributing to melodic sung recall. The sung recall score we devised moderately correlated with self-reported singing ability (r = .46) and musical training (r = ?). However, it shows no significant correlation with visuospatial working memory or pitch discrimination, aligning with previous research and suggesting that singing ability is not closely linked to low-level perceptual processes. This suggests that, whilst</p>
<p>The study also shows that melodic features which indicate melodic complexity (including melody length) are relevant predictors of sung recall performance. These predictors represented melody length, as well as features related to contour, tonality, statistical occurrence of N-grams in the melody, and durational complexity. Rhythmic trials were generally found to be more difficult (B = -0.15, p &lt; .001) and we found that it was appropriate to create separate models for arhythmic and rhythmic.</p>
<p>In another of my papers, <span class="citation">[@silasLearningRecallingMelodies2023]</span>, we investigated how individuals learn and recall melodies using a computational approach that emphasizes similarity metrics rather than traditional accuracy-based methods. The research involved 31 participants who sang back 28 melodies presented either as piano sounds or vocal audio excerpts from pop songs, with each melody repeated up to six times. The similarity between the target melody and the participants‚Äô sung recalls was measured using advanced algorithmic techniques. The primary goal was to understand how melodic recall improves over successive attempts and what factors most significantly influence recall accuracy.</p>
<p>One of the key findings of the study is that the length of sung recall attempts consistently increases across multiple attempts, and this increase significantly correlates with the overall similarity to the target melody. This observation challenges the traditional view that musical features such as interval patterns or tonality are the primary factors influencing melodic recall. Instead, the study suggests that the sheer length of the melody plays a more critical role, indicating that general memory constraints may be more influential than music-specific features. This insight aligns with theories of working memory, suggesting that melodic recall shares characteristics with other types of serial recall rather than being purely domain-specific to music.</p>
<p>A significant finding (presented there in Figure 8), examines how similarity changes as a function of attempt and the specific section of the melody (beginning, middle, end). The results show that similarity performance increases more rapidly for the beginning of the melody compared to the middle and end across successive attempts. This indicates that participants tend to stabilise their recall of the initial melodic segments earlier than the middle or end sections. The end sections, in particular, show a slower rate of improvement, suggesting that the latter parts of a melody are more challenging to accurately recall perhaps due to the higher working memory load as a result of having to remember more notes, the later you are in a position, or that generally people engaging in sung recall prioritise getting the earlier parts melody correct first. This finding supports the theory that memory encoding is stronger for the beginning of sequences, a phenomenon consistent with the primacy effect observed in other types of serial recall tasks. It also highlights that recall accuracy is not uniformly distributed across a melody, with the initial segments being more robustly learned compared to later ones.</p>
<p>The study also found that musical training did not significantly enhance recall performance when similarity metrics were used as the primary assessment method, as shown in another key result. This challenges the conventional belief that formal musical training substantially improves melodic recall ability. Instead, the data suggests that domain-general memory skills may be just as important, pointing to a more integrative understanding of how musical and non-musical cognitive processes interact.</p>
<p>Moreover, the results highlight that similarity scores increase with each successive attempt, but the rate of improvement diminishes after the third or fourth attempt. This pattern suggests that the most substantial gains in melodic recall occur early in the learning process, followed by incremental refinements in pitch and rhythm accuracy. Additionally, melodies presented as vocal audio excerpts resulted in higher recall accuracy compared to piano sound presentations, indicating that the human voice might provide additional mnemonic cues that aid in memory encoding.</p>
<p>Overall, the study‚Äôs use of similarity-based metrics, particularly the ‚Äúopti3‚Äù metric that integrates pitch intervals, harmonic progression, and rhythmic similarity, offers a more nuanced and accurate assessment of how melodies are learned and recalled. By focusing on the gradual increase in recall length and the differential improvement across melodic segments, the study sheds light on the underlying cognitive processes involved in melodic memory, emphasizing the role of general memory mechanisms and the relatively limited impact of formal musical training.</p>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="pfordreshers-cognitive-model-of-singing-accuracy.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="non-musical-models-of-serial-recall.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
