<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>5 Modern Technological Approaches to Ear Training | Playing By Ear: A Computational Approach</title>
  <meta name="description" content="5 Modern Technological Approaches to Ear Training | Playing By Ear: A Computational Approach" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="5 Modern Technological Approaches to Ear Training | Playing By Ear: A Computational Approach" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="5 Modern Technological Approaches to Ear Training | Playing By Ear: A Computational Approach" />
  
  
  

<meta name="author" content="Seb Silas" />


<meta name="date" content="2025-06-03" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="historical_background.html"/>
<link rel="next" href="playing_by_ear_literature_review.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Front Matter</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#foreword"><i class="fa fa-check"></i><b>1.1</b> Foreword</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.2</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#toc"><i class="fa fa-check"></i><b>1.3</b> Table of Contents</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#what-is-playing-by-ear"><i class="fa fa-check"></i><b>2.1</b> What Is Playing By Ear?</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#learning-to-play-by-ear"><i class="fa fa-check"></i><b>2.2</b> Learning to Play By Ear</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#the-problem-domain-and-approach"><i class="fa fa-check"></i><b>2.3</b> The Problem Domain and Approach</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#motivations"><i class="fa fa-check"></i><b>2.4</b> Motivations</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#generalising-beyond-jazz-and-playing-by-ear"><i class="fa fa-check"></i><b>2.4.1</b> Generalising Beyond Jazz and Playing By Ear</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#thesis-statement"><i class="fa fa-check"></i><b>2.5</b> Thesis Statement</a></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#original-contributions"><i class="fa fa-check"></i><b>2.6</b> Original Contributions</a></li>
<li class="chapter" data-level="2.7" data-path="introduction.html"><a href="introduction.html#research-questions"><i class="fa fa-check"></i><b>2.7</b> Research Questions</a></li>
<li class="chapter" data-level="2.8" data-path="introduction.html"><a href="introduction.html#objectives-and-scope"><i class="fa fa-check"></i><b>2.8</b> Objectives and Scope</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="introduction.html"><a href="introduction.html#scope"><i class="fa fa-check"></i><b>2.8.1</b> Scope</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="introduction.html"><a href="introduction.html#front-facing-tools"><i class="fa fa-check"></i><b>2.9</b> Front-Facing Tools</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="introduction.html"><a href="introduction.html#slonimsky.app"><i class="fa fa-check"></i><b>2.9.1</b> Slonimsky.app</a></li>
<li class="chapter" data-level="2.9.2" data-path="introduction.html"><a href="introduction.html#songbird"><i class="fa fa-check"></i><b>2.9.2</b> Songbird</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="introduction.html"><a href="introduction.html#dissertation-outline"><i class="fa fa-check"></i><b>2.10</b> Dissertation Outline</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="backgrounds.html"><a href="backgrounds.html"><i class="fa fa-check"></i><b>3</b> Background</a></li>
<li class="chapter" data-level="4" data-path="historical_background.html"><a href="historical_background.html"><i class="fa fa-check"></i><b>4</b> Historical Background: Approaches to Improving Playing by Ear in Jazz Music</a>
<ul>
<li class="chapter" data-level="4.0.1" data-path="historical_background.html"><a href="historical_background.html#the-aural-origins-of-jazz-education"><i class="fa fa-check"></i><b>4.0.1</b> The Aural Origins of Jazz Education</a></li>
<li class="chapter" data-level="4.0.2" data-path="historical_background.html"><a href="historical_background.html#record-players-as-pedagogical-tools"><i class="fa fa-check"></i><b>4.0.2</b> Record Players as Pedagogical Tools</a></li>
<li class="chapter" data-level="4.0.3" data-path="historical_background.html"><a href="historical_background.html#codification-of-jazz-education"><i class="fa fa-check"></i><b>4.0.3</b> Codification of Jazz Education</a></li>
<li class="chapter" data-level="4.0.4" data-path="historical_background.html"><a href="historical_background.html#the-chord-scale-approach-pattern-books-and-melodic-vocabulary-acquisition"><i class="fa fa-check"></i><b>4.0.4</b> The Chord-Scale Approach, Pattern Books, and Melodic Vocabulary Acquisition</a></li>
<li class="chapter" data-level="4.0.5" data-path="historical_background.html"><a href="historical_background.html#john-coltrane-and-slonimskys-thesaurus-aspirational-melodic-vocabulary-acquisition"><i class="fa fa-check"></i><b>4.0.5</b> John Coltrane and Slonimsky’s Thesaurus: Aspirational Melodic Vocabulary Acquisition</a></li>
<li class="chapter" data-level="4.0.6" data-path="historical_background.html"><a href="historical_background.html#conclusion"><i class="fa fa-check"></i><b>4.0.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="modern_technological_approaches.html"><a href="modern_technological_approaches.html"><i class="fa fa-check"></i><b>5</b> Modern Technological Approaches to Ear Training</a>
<ul>
<li class="chapter" data-level="5.1" data-path="modern_technological_approaches.html"><a href="modern_technological_approaches.html#historical-development-of-ear-training-technology"><i class="fa fa-check"></i><b>5.1</b> Historical Development of Ear-Training Technology</a>
<ul>
<li class="chapter" data-level="5.1.1" data-path="modern_technological_approaches.html"><a href="modern_technological_approaches.html#transcription-software"><i class="fa fa-check"></i><b>5.1.1</b> Transcription software</a></li>
<li class="chapter" data-level="5.1.2" data-path="modern_technological_approaches.html"><a href="modern_technological_approaches.html#chordharmonic-recognition-tools."><i class="fa fa-check"></i><b>5.1.2</b> Chord/Harmonic Recognition Tools.</a></li>
<li class="chapter" data-level="5.1.3" data-path="modern_technological_approaches.html"><a href="modern_technological_approaches.html#rhythm-training-tools."><i class="fa fa-check"></i><b>5.1.3</b> Rhythm Training Tools.</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="modern_technological_approaches.html"><a href="modern_technological_approaches.html#non-commercial-and-research-initiatives"><i class="fa fa-check"></i><b>5.2</b> Non-Commercial and Research Initiatives</a></li>
<li class="chapter" data-level="5.3" data-path="modern_technological_approaches.html"><a href="modern_technological_approaches.html#pedagogical-strategies-and-practical-use"><i class="fa fa-check"></i><b>5.3</b> Pedagogical Strategies and Practical Use</a></li>
<li class="chapter" data-level="5.4" data-path="modern_technological_approaches.html"><a href="modern_technological_approaches.html#benefits-and-limitations"><i class="fa fa-check"></i><b>5.4</b> Benefits and Limitations</a></li>
<li class="chapter" data-level="5.5" data-path="modern_technological_approaches.html"><a href="modern_technological_approaches.html#conclusion-1"><i class="fa fa-check"></i><b>5.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="playing_by_ear_literature_review.html"><a href="playing_by_ear_literature_review.html"><i class="fa fa-check"></i><b>6</b> Playing by Ear Research: A Literature Review</a>
<ul>
<li class="chapter" data-level="6.1" data-path="playing_by_ear_literature_review.html"><a href="playing_by_ear_literature_review.html#cognitive-and-neural-mechanisms-underlying-playing-by-ear"><i class="fa fa-check"></i><b>6.1</b> Cognitive and Neural Mechanisms Underlying Playing by Ear</a></li>
<li class="chapter" data-level="6.2" data-path="playing_by_ear_literature_review.html"><a href="playing_by_ear_literature_review.html#developmental-and-pedagogical-aspects-of-playing-by-ear-skill-acquisition"><i class="fa fa-check"></i><b>6.2</b> Developmental and Pedagogical Aspects of Playing By Ear Skill Acquisition</a></li>
<li class="chapter" data-level="6.3" data-path="playing_by_ear_literature_review.html"><a href="playing_by_ear_literature_review.html#practical-strategies-and-individual-differences-in-playing-by-ear"><i class="fa fa-check"></i><b>6.3</b> Practical Strategies and Individual Differences in Playing By Ear</a></li>
<li class="chapter" data-level="6.4" data-path="playing_by_ear_literature_review.html"><a href="playing_by_ear_literature_review.html#conclusion-2"><i class="fa fa-check"></i><b>6.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="musicological_background.html"><a href="musicological_background.html"><i class="fa fa-check"></i><b>7</b> Computational Musicological Perspectives</a>
<ul>
<li class="chapter" data-level="7.0.1" data-path="musicological_background.html"><a href="musicological_background.html#music-and-combinatorics"><i class="fa fa-check"></i><b>7.0.1</b> Music and Combinatorics</a></li>
<li class="chapter" data-level="7.0.2" data-path="musicological_background.html"><a href="musicological_background.html#melodic-represention-and-computational-melodic-features"><i class="fa fa-check"></i><b>7.0.2</b> Melodic Represention and Computational Melodic Features</a></li>
<li class="chapter" data-level="7.0.3" data-path="musicological_background.html"><a href="musicological_background.html#melody-as-cognitive-psychology"><i class="fa fa-check"></i><b>7.0.3</b> Melody as Cognitive Psychology</a></li>
<li class="chapter" data-level="7.0.4" data-path="musicological_background.html"><a href="musicological_background.html#fuzzification"><i class="fa fa-check"></i><b>7.0.4</b> Fuzzification</a></li>
<li class="chapter" data-level="7.0.5" data-path="musicological_background.html"><a href="musicological_background.html#computed-melodic-features-as-a-musicological-basis-for-selecting-items"><i class="fa fa-check"></i><b>7.0.5</b> Computed Melodic Features as a musicological basis for selecting items</a></li>
<li class="chapter" data-level="7.0.6" data-path="musicological_background.html"><a href="musicological_background.html#pattern-books-as-item-banks"><i class="fa fa-check"></i><b>7.0.6</b> Pattern Books as Item Banks</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html"><i class="fa fa-check"></i><b>8</b> Cognitive Psychology: General Principles of Learning and Memory</a>
<ul>
<li class="chapter" data-level="8.1" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html#theoretical-background"><i class="fa fa-check"></i><b>8.1</b> Theoretical Background</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html#memory-systems-and-retention"><i class="fa fa-check"></i><b>8.1.1</b> Memory Systems and Retention</a></li>
<li class="chapter" data-level="8.1.2" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html#learning-and-forgetting-curves"><i class="fa fa-check"></i><b>8.1.2</b> Learning and Forgetting Curves</a></li>
<li class="chapter" data-level="8.1.3" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html#short-term-vs.-long-term-forgetting"><i class="fa fa-check"></i><b>8.1.3</b> Short-Term vs. Long-Term Forgetting</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html#key-findings-from-cognitive-psychology"><i class="fa fa-check"></i><b>8.2</b> Key Findings from Cognitive Psychology</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html#ebbinghauss-forgetting-curve"><i class="fa fa-check"></i><b>8.2.1</b> Ebbinghaus’s Forgetting Curve</a></li>
<li class="chapter" data-level="8.2.2" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html#interference-and-consolidation"><i class="fa fa-check"></i><b>8.2.2</b> Interference and Consolidation</a></li>
<li class="chapter" data-level="8.2.3" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html#spacing-effect-and-distributed-practice"><i class="fa fa-check"></i><b>8.2.3</b> Spacing Effect and Distributed Practice</a></li>
<li class="chapter" data-level="8.2.4" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html#retrieval-practice"><i class="fa fa-check"></i><b>8.2.4</b> Retrieval Practice</a></li>
<li class="chapter" data-level="8.2.5" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html#cognitive-models-of-memory-and-optimal-scheduling"><i class="fa fa-check"></i><b>8.2.5</b> Cognitive Models of Memory and Optimal Scheduling</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html#applications-in-language-learning"><i class="fa fa-check"></i><b>8.3</b> Applications in Language Learning</a></li>
<li class="chapter" data-level="8.4" data-path="cognitive_psychological_background.html"><a href="cognitive_psychological_background.html#conclusion-3"><i class="fa fa-check"></i><b>8.4</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="statistical_modelling_frameworks.html"><a href="statistical_modelling_frameworks.html"><i class="fa fa-check"></i><b>9</b> Statistical Modelling Frameworks</a>
<ul>
<li class="chapter" data-level="9.1" data-path="statistical_modelling_frameworks.html"><a href="statistical_modelling_frameworks.html#item-response-theory"><i class="fa fa-check"></i><b>9.1</b> Item Response Theory</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="theoretical-model.html"><a href="theoretical-model.html"><i class="fa fa-check"></i><b>10</b> Playing By Ear: A Theoretical Model</a>
<ul>
<li class="chapter" data-level="10.1" data-path="theoretical-model.html"><a href="theoretical-model.html#pfordreshers-h-pac-model"><i class="fa fa-check"></i><b>10.1</b> Pfordresher’s H-PAC model</a></li>
<li class="chapter" data-level="10.2" data-path="theoretical-model.html"><a href="theoretical-model.html#pfordreshers-cognitive-model-of-singing-accuracy"><i class="fa fa-check"></i><b>10.2</b> Pfordresher’s cognitive model of singing accuracy</a></li>
<li class="chapter" data-level="10.3" data-path="theoretical-model.html"><a href="theoretical-model.html#bakers-computational-model-of-melodic-dictation"><i class="fa fa-check"></i><b>10.3</b> Baker’s computational model of melodic dictation</a></li>
<li class="chapter" data-level="10.4" data-path="theoretical-model.html"><a href="theoretical-model.html#models-of-sung-recall"><i class="fa fa-check"></i><b>10.4</b> Models of sung recall</a></li>
<li class="chapter" data-level="10.5" data-path="theoretical-model.html"><a href="theoretical-model.html#non-musical-models-of-serial-recall"><i class="fa fa-check"></i><b>10.5</b> Non-musical models of serial recall</a></li>
<li class="chapter" data-level="10.6" data-path="theoretical-model.html"><a href="theoretical-model.html#wm-bits"><i class="fa fa-check"></i><b>10.6</b> WM bits</a></li>
<li class="chapter" data-level="10.7" data-path="theoretical-model.html"><a href="theoretical-model.html#bringing-it-together"><i class="fa fa-check"></i><b>10.7</b> Bringing it together</a></li>
<li class="chapter" data-level="10.8" data-path="theoretical-model.html"><a href="theoretical-model.html#moving-from-theoretical-to-computational"><i class="fa fa-check"></i><b>10.8</b> Moving from Theoretical to Computational</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="theoretical-model.html"><a href="theoretical-model.html#inputs"><i class="fa fa-check"></i><b>10.8.1</b> Inputs</a></li>
<li class="chapter" data-level="10.8.2" data-path="theoretical-model.html"><a href="theoretical-model.html#sequential-construction"><i class="fa fa-check"></i><b>10.8.2</b> Sequential Construction</a></li>
<li class="chapter" data-level="10.8.3" data-path="theoretical-model.html"><a href="theoretical-model.html#function-application"><i class="fa fa-check"></i><b>10.8.3</b> Function Application</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="theoretical-model.html"><a href="theoretical-model.html#mathematical-representation"><i class="fa fa-check"></i><b>10.9</b> Mathematical Representation</a></li>
<li class="chapter" data-level="10.10" data-path="theoretical-model.html"><a href="theoretical-model.html#algorithm-flow"><i class="fa fa-check"></i><b>10.10</b> Algorithm Flow</a></li>
<li class="chapter" data-level="10.11" data-path="theoretical-model.html"><a href="theoretical-model.html#final-equation"><i class="fa fa-check"></i><b>10.11</b> Final Equation</a></li>
<li class="chapter" data-level="10.12" data-path="theoretical-model.html"><a href="theoretical-model.html#strategies"><i class="fa fa-check"></i><b>10.12</b> Strategies</a></li>
<li class="chapter" data-level="10.13" data-path="theoretical-model.html"><a href="theoretical-model.html#learning-forgetting"><i class="fa fa-check"></i><b>10.13</b> Learning, forgetting</a></li>
<li class="chapter" data-level="10.14" data-path="theoretical-model.html"><a href="theoretical-model.html#the-melodic-mind-as-item-bank"><i class="fa fa-check"></i><b>10.14</b> The Melodic Mind As Item Bank</a></li>
<li class="chapter" data-level="10.15" data-path="theoretical-model.html"><a href="theoretical-model.html#predictions"><i class="fa fa-check"></i><b>10.15</b> Predictions:</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html"><i class="fa fa-check"></i><b>11</b> A computational ecosystem</a>
<ul>
<li class="chapter" data-level="11.1" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#transcription-of-melodic-production-data-pyin"><i class="fa fa-check"></i><b>11.1</b> Transcription of melodic production data: pyin</a></li>
<li class="chapter" data-level="11.2" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#assessment-of-melodic-similarity-melsim"><i class="fa fa-check"></i><b>11.2</b> Assessment of melodic similarity: melsim</a></li>
<li class="chapter" data-level="11.3" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#psychologically-meaningful-musical-item-banks-itembankr"><i class="fa fa-check"></i><b>11.3</b> Psychologically meaningful musical item banks: itembankr</a></li>
<li class="chapter" data-level="11.4" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#datasets"><i class="fa fa-check"></i><b>11.4</b> Datasets</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#wjd"><i class="fa fa-check"></i><b>11.4.1</b> WJD</a></li>
<li class="chapter" data-level="11.4.2" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#berkowitz"><i class="fa fa-check"></i><b>11.4.2</b> Berkowitz</a></li>
<li class="chapter" data-level="11.4.3" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#slonimsky"><i class="fa fa-check"></i><b>11.4.3</b> Slonimsky</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#other-useful-functions"><i class="fa fa-check"></i><b>11.5</b> Other useful functions</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#assessing-musical-behaviours-musicassessr"><i class="fa fa-check"></i><b>11.5.1</b> Assessing musical behaviours: musicassessr</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#ability-tests"><i class="fa fa-check"></i><b>11.6</b> Ability tests</a></li>
<li class="chapter" data-level="11.7" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#conclusion-4"><i class="fa fa-check"></i><b>11.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="melsim_development.html"><a href="melsim_development.html"><i class="fa fa-check"></i><b>12</b> Experiment 1: Development of a melodic similarity algorithm for short recalled melodies</a></li>
<li class="chapter" data-level="13" data-path="pbet_lab_study.html"><a href="pbet_lab_study.html"><i class="fa fa-check"></i><b>13</b> Experiment 2: An Explanatory Model Of Playing By Ear</a>
<ul>
<li class="chapter" data-level="13.1" data-path="pbet_lab_study.html"><a href="pbet_lab_study.html#methods"><i class="fa fa-check"></i><b>13.1</b> Methods</a>
<ul>
<li class="chapter" data-level="13.1.1" data-path="pbet_lab_study.html"><a href="pbet_lab_study.html#participants-and-preliminary-questionnaire"><i class="fa fa-check"></i><b>13.1.1</b> Participants and Preliminary Questionnaire</a></li>
<li class="chapter" data-level="13.1.2" data-path="pbet_lab_study.html"><a href="pbet_lab_study.html#apparatus-and-general-procedure"><i class="fa fa-check"></i><b>13.1.2</b> Apparatus and General Procedure</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="pbet_online_study.html"><a href="pbet_online_study.html"><i class="fa fa-check"></i><b>14</b> Experiment 3: Modelling Melodic Difficulty in Playing by Ear: An Item Response Analysis of Online Performance Data</a></li>
<li class="chapter" data-level="15" data-path="study_history_study.html"><a href="study_history_study.html"><i class="fa fa-check"></i><b>15</b> Experiment 4: A Longitudinal Study of Playing By Ear Skills</a>
<ul>
<li class="chapter" data-level="15.1" data-path="study_history_study.html"><a href="study_history_study.html#production-perception-paradigm"><i class="fa fa-check"></i><b>15.1</b> Production perception paradigm</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="similarity_study.html"><a href="similarity_study.html"><i class="fa fa-check"></i><b>16</b> Experiment 5: A similarity-based approach to item selection</a>
<ul>
<li class="chapter" data-level="16.1" data-path="similarity_study.html"><a href="similarity_study.html#collaborative-filtering"><i class="fa fa-check"></i><b>16.1</b> Collaborative filtering</a></li>
<li class="chapter" data-level="16.2" data-path="similarity_study.html"><a href="similarity_study.html#approaches-to-similarity-for-large-scale-corpora"><i class="fa fa-check"></i><b>16.2</b> Approaches to similarity for large scale corpora</a></li>
<li class="chapter" data-level="16.3" data-path="similarity_study.html"><a href="similarity_study.html#melodic-corpora-as-networks"><i class="fa fa-check"></i><b>16.3</b> Melodic corpora as networks</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="similarity_study.html"><a href="similarity_study.html#approach-1-similarity-of-features-as-proxy-for-melodic-similarity"><i class="fa fa-check"></i><b>16.3.1</b> Approach #1: similarity of features as proxy for melodic similarity</a></li>
<li class="chapter" data-level="16.3.2" data-path="similarity_study.html"><a href="similarity_study.html#approach-2-generative-similarity"><i class="fa fa-check"></i><b>16.3.2</b> Approach #2: Generative similarity</a></li>
<li class="chapter" data-level="16.3.3" data-path="similarity_study.html"><a href="similarity_study.html#approach-3-on-breaking-up-items-into-ngrams-store-representationssimilarity."><i class="fa fa-check"></i><b>16.3.3</b> Approach #3: on breaking up items into ngrams, store representations/similarity.</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="additional-learning-paradigms.html"><a href="additional-learning-paradigms.html"><i class="fa fa-check"></i><b>17</b> Additional Learning Paradigms</a>
<ul>
<li class="chapter" data-level="17.1" data-path="additional-learning-paradigms.html"><a href="additional-learning-paradigms.html#generative-similarity"><i class="fa fa-check"></i><b>17.1</b> Generative similarity</a></li>
<li class="chapter" data-level="17.2" data-path="additional-learning-paradigms.html"><a href="additional-learning-paradigms.html#identify-correct-vs-incorrect-ngrams-in-a-recall-add-incorrect-ngrams-to-beginning-of-session-buffer"><i class="fa fa-check"></i><b>17.2</b> identify correct vs incorrect ngrams in a recall: add incorrect ngrams to beginning of session buffer</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="experiment-6-model-synthesis-development-of-a-musical-dashsim-model.html"><a href="experiment-6-model-synthesis-development-of-a-musical-dashsim-model.html"><i class="fa fa-check"></i><b>18</b> Experiment 6: Model synthesis: Development of a musical DASH+SIM model</a></li>
<li class="chapter" data-level="19" data-path="interventional_Study.html"><a href="interventional_Study.html"><i class="fa fa-check"></i><b>19</b> Experiment 7: An Interventional Study</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Playing By Ear: A Computational Approach</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="modern_technological_approaches" class="section level1 hasAnchor" number="5">
<h1><span class="header-section-number">5</span> Modern Technological Approaches to Ear Training<a href="modern_technological_approaches.html#modern_technological_approaches" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<!-- https://chatgpt.com/c/683ad51a-434c-800d-afa4-1b11dac1635f -->
<p>Somewhat narratively separate from the specific jazz pedagogical issues discussed in the previous chapter, but which is nonetheless relevant to any learner in the 21st - including those enlisting in jazz studies - is a discussion of the development of computerised ear training technology, which be discussed below.</p>
<div id="historical-development-of-ear-training-technology" class="section level2 hasAnchor" number="5.1">
<h2><span class="header-section-number">5.1</span> Historical Development of Ear-Training Technology<a href="modern_technological_approaches.html#historical-development-of-ear-training-technology" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In formal music education, “dictation” (listening to music and writing it down) has been a staple of ear training <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023; Baker 2019)</span>. The first computer-assisted ear training tools appeared in the late 1960s and by the 1970s many university music departments had begun using software for interval, melody, chord and rhythm training <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023; Peters 1992; Stevens 1991)</span>. These early systems predated mainstream personal computers and were often limited in interface and scope, but they signaled that technology could supplement one-on-one tutoring. During the 1980s–90s, as home computers became common, commercial ear-training packages emerged. For instance, desktop programs offered exercises in interval recognition or chord dictation with synthetic examples. Software like <em>EarMaster</em> (first released in the 1990s; <span class="citation"><span>“<span>EarMaster</span> - <span>The App</span> for <span>Ear Training</span>, <span>Sight-Singing</span>, and <span>Rhythm Training</span>”</span> (2025)</span>) began to compile thousands of drills in scales, chords and rhythms. Meanwhile, audio-editing tools introduced the ability to manipulate real recordings: by the 1990s and early 2000’s, software like <em>Transcribe</em><span class="citation">(<span>“Transcribe! - Software to Help Transcribe Recorded Music”</span> 2021)</span> and <em>Amazing Slow Downer</em> <span class="citation">(Roni Music 2025)</span>allowed users to slow down a recording or loop segments without altering pitch, greatly aiding transcription practice. In the 2000s, internet and mobile devices further expanded possibilities with web-based quizzes (e.g. at musictheory.net), smartphone apps (many interval- and chord-drill apps), and online communities for sharing transcriptions all appeared. A recent survey notes that ear-training apps and digital media are now recognized as important in music education, especially after the <em>COVID-19</em> pandemic accelerated remote learning <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023; Biasutti, Antonini Philippe, and Schiavio 2022)</span>.</p>
<p>More recently platforms, particularly YouTube, have become critical resources for jazz ear training. Thousands of free and paid video lessons offer guided transcription walkthroughs, call-and-response singing drills, harmonic analysis, and interval recognition in context. Creators like Adam Neely, Rick Beato, Aimee Nolte, and Jens Larsen provide high-quality instructional content often supplemented by downloadable PDFs containing annotated solos, theoretical explanations, and practice routines. These materials function as hybrid tools: students watch demonstrations, listen to examples repeatedly, and then practice using guided notation. While not interactive like apps, the structured nature of these lessons makes them accessible and effective for visual and auditory learners. Additionally, PDF packages often include backing tracks or isolated stems, making them compatible with tools like <em>Transcribe!</em> or <em>iReal Pro</em> for further ear training integration.</p>
<p>A notable recent example is <em>JazzLessonVideos.com</em>, co-founded by saxophonist Chad Lefkowitz-Brown (Chad LB) and educator Nathan Graybeal. Their platform offers a comprehensive suite of ear training resources tailored for jazz musicians. Their offerings include the Jazz Ear Training Video Course by Dr. Joe Gilman, comprising 23 videos with over 90 minutes of instruction. This course provides step-by-step guidance on identifying chord extensions, comparing chord types, and recognizing individual tones within chords, supplemented by interactive listening challenges. Additionally, their <em>Ear Training Method Book</em> focuses on essential skills such as interval and pitch identification, melodic dictation, chord identification, and chord progression recognition, complete with audio exercises and fill-in worksheets. These resources are designed to enhance aural skills through structured, self-paced learning, making them valuable tools for jazz students seeking to improve their improvisational abilities.</p>
<p>The platform’s approach emphasises the integration of video instruction with downloadable PDF materials, allowing students to engage with content visually, aurally, and kinesthetically. For instance, their “Melodic Cells” PDF package features 64 exercises focusing on non-diatonic, diatonic, and compound melodic cells, providing a structured method for developing improvisational vocabulary. Such resources are designed to be used in conjunction with backing tracks and other practice tools, facilitating a comprehensive ear training experience that bridges theoretical knowledge and practical application.
.
## Commercial Ear-Training and Transcription Tools</p>
<p>There are several main areas of computer assisted tools for helping improve playing by ear and related skills: transcription software, interval and melody training apps, chord/harmony recognition tools and rhythm training tools, which will be summarised below.</p>
<div id="transcription-software" class="section level3 hasAnchor" number="5.1.1">
<h3><span class="header-section-number">5.1.1</span> Transcription software<a href="modern_technological_approaches.html#transcription-software" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Jazz students often begin by transcribing solos and rhythms by ear. In contemporary times, specialised programs can help facilitate this process. <em>Transcribe!</em> <span class="citation">(<span>“Transcribe! - Software to Help Transcribe Recorded Music”</span> 2021)</span> and <em>Amazing Slow Downer</em> <span class="citation">(Roni Music 2025)</span> are two leading commercial tools that let a user loop passages, change tempo, and even shift pitch in real time. This lets learners gradually discern fast or complex lines at a slower pace without distortion. These tools also typically display a spectrogram or note analysis, which can guide accurate pitch identification. Other options include <em>Audacity</em> <span class="citation">(2025a)</span> (free audio editor with tempo/pitch controls) and <em>Sonic Visualiser</em> <span class="citation">(Centre for Digital Music 2025)</span> (research-oriented spectrogram display). Recently, AI-driven transcription has emerged: for example, plugins like <em>Melodyne</em> <span class="citation">(2025b)</span> can extract melody lines into MIDI, and open-source tools like Spotify’s <em>Basic Pitch</em> <span class="citation">(Spotify 2025)</span> (using machine learning) can convert a recording to notes. Such tools can automatically detect pitches and even chords in monophonic lines, though they struggle with dense jazz ensembles. Nonetheless, they offer an assistive first draft for transcribing complex solos or harmonic progressions. Interval and Melody Training Apps. Many apps and websites are designed as drill-and-practice tools for intervals and melodies. Well-known examples include <em>EarMaster</em> <span class="citation">(<span>“<span>EarMaster</span> - <span>The App</span> for <span>Ear Training</span>, <span>Sight-Singing</span>, and <span>Rhythm Training</span>”</span> 2025)</span>, <em>Tenuto</em> (by musictheory.net), <em>Perfect Ear</em> <span class="citation">(Crazy Ootka Software AB 2025)</span>, and <em>TonedEar</em> <span class="citation">(TonedEar 2025)</span>. These let a student train on identifying intervals, scales, and short melodies by ear. For instance, <em>EarMaster</em> <span class="citation">(<span>“<span>EarMaster</span> - <span>The App</span> for <span>Ear Training</span>, <span>Sight-Singing</span>, and <span>Rhythm Training</span>”</span> 2025)</span>offers thousands of exercises in intervals, chord types, cadences, and melodic dictation, while Tenuto’s exercises let one tap out or sing back intervals or scales on a keyboard interface. <em>Functional Ear Trainer</em> (iOS/Android) uses the concept of solfège by establishing a tonal center and having the student name scale-degrees or harmonic functions of incoming notes. Such apps typically provide immediate feedback and can adjust difficulty, which is a strength over traditional one-on-one drills (whose pace is fixed by the teacher). A Chinese study found that structured use of <em>EarMaster</em> significantly improved university students’ pitch, rhythm and timbre recognition compared to traditional instruction <span class="citation">(Lingjie 2025)</span>.</p>
</div>
<div id="chordharmonic-recognition-tools." class="section level3 hasAnchor" number="5.1.2">
<h3><span class="header-section-number">5.1.2</span> Chord/Harmonic Recognition Tools.<a href="modern_technological_approaches.html#chordharmonic-recognition-tools." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Identifying chords and progressions by ear is crucial in jazz. Some ear-training apps include chord identification modules: for example, <em>EarMaster</em> <span class="citation">(<span>“<span>EarMaster</span> - <span>The App</span> for <span>Ear Training</span>, <span>Sight-Singing</span>, and <span>Rhythm Training</span>”</span> 2025)</span> can play triads or seventh-chords of different qualities (major, minor, dominant, etc.) for recognition practice. <em>Tenuto</em> <span class="citation">(musictheory.net 2025)</span> and <em>Perfect Ear</em> <span class="citation">(Crazy Ootka Software AB 2025)</span> also have chord quizzes. Meanwhile, digital accompaniments like <em>iReal Pro</em> <span class="citation">(<strong>irealProApp?</strong>)</span> indirectly train harmonic ear skills. <em>iReal Pro</em> is a jazz “fake book” app that plays back chord charts in realistic backing-band styles. Students use it to loop ii–V–I progressions, turnarounds, or full standards at varying tempos, and practice improvising over them. Although <em>iReal Pro</em> doesn’t explicitly quiz the ear, it immerses students in hearing chord changes in context. (Notably, <em>iReal Pro</em> is also used pedagogically by many teachers – e.g. forums note that educators share custom chord exercises on its forum irealpro.com.) Other software like <em>Band-in-a-Box</em> <span class="citation">(2025c)</span> or <em>Chordbot</em> <span class="citation">(AB 2025)</span> generates full-band or looped chord sequences. Chord-detection services (e.g. <em>Chordify</em> <span class="citation">(B. V. 2025)</span>) even attempt to automatically transcribe chords from recordings, though their accuracy can falter on jazz’s complex voicings. In summary, these tools help jazz students internalise harmonic progressions, but most pedagogical testing still relies on human evaluation or structured quizzes.</p>
</div>
<div id="rhythm-training-tools." class="section level3 hasAnchor" number="5.1.3">
<h3><span class="header-section-number">5.1.3</span> Rhythm Training Tools.<a href="modern_technological_approaches.html#rhythm-training-tools." class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Jazz rhythm (swing feel, syncopation) can be elusive. Apps such as <em>Rhythm Trainer</em>, <em>Rhythm Trainer Complete</em>, or online rhythm dictation games allow practice identifying and tapping back rhythmic patterns. <em>EarMaster</em> <span class="citation">(<span>“<span>EarMaster</span> - <span>The App</span> for <span>Ear Training</span>, <span>Sight-Singing</span>, and <span>Rhythm Training</span>”</span> 2025)</span> includes clap-back and error-detection rhythm exercises. Some drum-focused VR games (e.g. the <em>Drumhead</em> <span class="citation">(VR 2025)</span> VR app) present rhythms visually. These tools support the move toward an “aural skills” approach even for rhythm. However, authentic jazz swing feel and poly-rhythms are hard to simulate outside an ensemble. Educators often still use live or recorded jazz drum examples (e.g. using <em>GrooveScribe</em> <span class="citation">(TheDrumNinja and Firth 2025)</span> to slow or isolate drum grooves) and encourage students to mimic them by ear. Nonetheless, any metronome with accent settings or rhythm game adds value for fundamental training.</p>
</div>
</div>
<div id="non-commercial-and-research-initiatives" class="section level2 hasAnchor" number="5.2">
<h2><span class="header-section-number">5.2</span> Non-Commercial and Research Initiatives<a href="modern_technological_approaches.html#non-commercial-and-research-initiatives" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Beyond commercial products, there are academic and open initiatives for ear training. Music education researchers have explored computer-based ear training since the 1970s, and some projects still surface: e.g. Sibelius Ear Training Exercises (built-in to notation software) or <em>ToneGym</em> <span class="citation">(ToneGym 2025)</span> (a freemium web app with interactive ear games) have some educational followings. A particularly novel project is Virtual Reality ear training. For example, <em>Berklee College of Music</em> has developed a free VR <em>Ear Trainer</em> game: players enter a virtual room and tap notes or rhythms to match aural prompts, using immersive spatial audio <span class="citation">(Smith-Muller 2024)</span>. In research, Bournemouth University created a VR interval-recognition system and found users enjoyed it <span class="citation">(Fletcher, Hulusic, and Amelidis 2019)</span>. These VR approaches align with modern pedagogical emphases on engagement and multisensory learning. Additionally, open-source AI tools like Spotify’s <em>Basic Pitch</em> (audio-to-MIDI conversion) <span class="citation">(Spotify 2025)</span> represent an emerging trend: while not classroom tools per se, they hint at future “smart” apps that can listen to a student’s improvisation and provide instant feedback on pitch and harmony. In terms of research on effectiveness, studies confirm that technology can boost ear-training. The Chinese <em>Earmaster</em> study <span class="citation">(Lingjie 2025)</span> is one example (not jazz-specific but broadly applicable), showing structured software practice outperformed traditional drills in improving aural skills. On the other hand, some surveys report that teachers are cautious: French music educators noted a wealth of apps exists but found few that fit their curricula and quality standards <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023)</span>. In practice, most instructors integrate tech pragmatically (e.g. assigning app exercises for homework, using iReal Pro in lab hours) rather than abandoning traditional exercises outright.</p>
</div>
<div id="pedagogical-strategies-and-practical-use" class="section level2 hasAnchor" number="5.3">
<h2><span class="header-section-number">5.3</span> Pedagogical Strategies and Practical Use<a href="modern_technological_approaches.html#pedagogical-strategies-and-practical-use" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Modern tools offer flexible practice but must be aligned with pedagogical goals. For transcription work, a typical strategy is: (1) listen to a short phrase repeatedly; (2) use software to slow it (e.g. to 60–80% speed) without changing pitch; (3) loop and isolate segments; (4) gradually raise speed as confidence grows. Teachers might recommend <em>Transcribe!</em> <span class="citation">(<span>“Transcribe! - Software to Help Transcribe Recorded Music”</span> 2021)</span> or <em>Amazing Slow Downer</em> <span class="citation">(Roni Music 2025)</span> for this, noting they allow marking sections and adjusting playback easily. Students also often use generic audio editors or <em>DAWs</em> (<em>Logic</em>, <em>Ableton</em>, <em>Audacity</em>) to visually align waveforms or annotate phrases. For interval recognition, instructors may mix app drills with in-class ear tests: e.g. <em>EarMaster</em> sessions can reinforce what students practiced privately on <em>Tenuto</em> <span class="citation">(musictheory.net 2025)</span>. Some educators advocate functional ear training (using scale degrees) especially for jazz, since jazz harmony is often thought of functionally; apps like <em>Functional Ear Trainer</em> <span class="citation">(Benbassat 2025)</span> implement this method. Others prefer interval drills, training students to name or match intervals regardless of key, arguing it transfers to any style. In practice, many adopt a hybrid: using apps for technical skill-building, then embedding those skills in jazz context via transcription and improvisation. Chord and harmonic dictation can be taught by first drilling triad types (through apps or teacher-led quizzing) and gradually moving to seventh chords and modes. Here technology’s pros/cons are clear: an <em>EarMaster</em> chord drill gives clear examples of an isolated chord tone, but hearing chords in real music often involves piano voicings or comping instruments. Some software (e.g. <em>Band-in-a-Box</em>) can generate controlled chord voicings for drill, but a teacher must ensure the student generalizes to actual recordings. Tools like iReal Pro support this by letting students choose different “rhythmic feels” (swing, bossa, etc.) for a given progression, so they hear the chords in musical context. In classes, teachers might assign each student to program a progression into iReal Pro (e.g. a standard tune’s changes) and then transpose and improvise over it. This contrasts with traditional jazz pedagogy, where playing “head a tunes and backings” was often live or from fake books; iReal Pro effectively democratizes a live band rehearsal. Rhythm and groove training via apps must be complemented by ensemble playing. An app can tap or clap back polyrhythms or swing patterns to a click, but internalizing groove usually involves playing with others. Many jazz educators therefore use tech to drill fundamentals (time feel, comping rhythms) but still emphasize jam sessions or drummer-led practice for true syncopation skills. Some programs (e.g. Melodic Perception interactive software) teach reading swing notations, but often jazz theory recommends learning rhythms aurally (listen-and-repeat) above all. Overall, modern ear-training tools align with traditional jazz pedagogy in that they emphasize listening and imitation, but they diverge in method. Traditional methods rely on a teacher or bandleader, whereas apps provide automated feedback and endless repetition. For example, while Lennie Tristano insisted on singing solos note-for-note (which students must check by ear or rely on the teacher’s judgment), an app like EarMaster could instantly verify if a student sang the correct interval. Similarly, instead of a teacher clapping a rhythm for a student to echo, a rhythm app can play random patterns for unsupervised practice. This autonomy can increase practice time and motivation, but some educators warn it may reduce human nuance: a student might become skilled at clicking “correct” on an app but still lack expressive feel.</p>
</div>
<div id="benefits-and-limitations" class="section level2 hasAnchor" number="5.4">
<h2><span class="header-section-number">5.4</span> Benefits and Limitations<a href="modern_technological_approaches.html#benefits-and-limitations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Modern tools allow personalised, flexible practice. Students can drill weak areas at their own pace, track progress quantitatively, and engage in gamified learning. Slowed/audio-transcription tools let learners tackle pieces beyond their current technical level. Mobile apps and cloud platforms enable anywhere-anytime practice, which is especially helpful for busy or distant learners. In higher education, platforms like <em>EarMaster Cloud</em> <span class="citation">(<strong>earmasterCloud?</strong>)</span> or <em>MusicFirst</em> integrate with online curricula, giving instructors assignments and reports. Some researchers note that these tools can bridge gaps in large classes where one-on-one ear training is impractical <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023)</span>.</p>
<p>However, technology cannot fully replicate a skilled teacher or ensemble experience. Commercial apps often focus on Western tonal exercises (major/minor systems), which may not cover jazz’s extended/improvised tonalities (e.g. altered dominants or modal jazz). Additionally, software feedback is often binary (right/wrong) and ignores expression. Some students may “beat the drill” by test-taking tactics (memorizing patterns) without deeper musical understanding. Technical issues also arise: automated chord detectors misinterpret complex voicings; time-stretch algorithms can artefact; VR systems may cause fatigue and currently only train simple tasks (intervals, not swing feel) <span class="citation">(Fletcher, Hulusic, and Amelidis 2019)</span>. Teachers report that finding apps that mesh with a course’s philosophy is challenging <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023)</span>; for example, an app that only tests fixed notes may conflict with an improvisation-first curriculum. Cost is another factor: many apps require purchase (though often at modest prices), and institutional adoption sometimes faces budget constraints. Importantly, some purists worry that reliance on “cheat-like” tools can impede ear development e.g., that slow-down software may constitute “cheating” when transcribing, and hearing at full tempo is the real test. However, educators counter that these are training wheels: speed can be reintroduced gradually to build authentic skill. Pedagogically, best practice seems to be using technology as a supplement: begin with slow, guided work, but also include exercises at normal tempo and many “blind” listening tasks.</p>
</div>
<div id="conclusion-1" class="section level2 hasAnchor" number="5.5">
<h2><span class="header-section-number">5.5</span> Conclusion<a href="modern_technological_approaches.html#conclusion-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Modern technology has substantially broadened the toolkit for jazz ear training. From historically modest <em>CAI</em> programs to today’s interactive apps, VR experiences, and AI transcribers, musicians and educators have more resources than ever for developing listening skills. These tools generally align with traditional jazz pedagogy by reinforcing learning-by-ear, but they allow more self-guided, data-driven practice than the old master-apprentice model. Academic research (from empirical studies to qualitative surveys) suggests that, when used thoughtfully, technology can improve outcomes in pitch, rhythm, and harmonic recognition <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023; Lingjie 2025)</span>.</p>
<p>At the same time, they remind us of the irreplaceable value of human nuance – the swinging rhythm of a live drummer, the phrasing of a soloist, and the inspirational guidance of a mentor. The most effective ear-training approach in jazz likely combines the best of both worlds: students drill fundamentals and tricky passages with software, then validate and refine their skills in real musical contexts (singer circles, jam sessions, or ensemble rehearsals). As technology continues to evolve – with VR, AI, and improved music analysis – jazz education will doubtless adapt, aiming always to train both the intuitive “good ear” and the knowledgeable, expressive improviser.</p>
<!-- https://chatgpt.com/c/682852e1-2c80-800d-bcb5-f7446bb1731a -->
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="historical_background.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="playing_by_ear_literature_review.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
