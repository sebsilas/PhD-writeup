[["index.html", "Playing By Ear: A Computational Approach 1 Foreword", " Playing By Ear: A Computational Approach Seb Silas 2025-05-10 1 Foreword The topic of this dissertation is “playing by ear” and whilst I generalise the results, I motivate this mainly in terms of jazz education. Jazz is an oral tradition. Cognitive psychological tool If you want to learn the tradition, transcribe the solos, go and play with new solos. Less a means of learning the tradition orally (best go straight to the source, transcribe real solos) - more about developing personal vocabulary based on your current knowledge. Exploring new spaces The computer as the “heavy-lifter” so the musician can focus more on the sounds themselves; unburdening the musician "],["table-of-contents.html", "2 Table of Contents", " 2 Table of Contents Table of Contents Introduction {#introduction} The Problem Domain and Approach Computational modelling Motivations Generalising beyond jazz What is playing by ear? Learning to play by ear Thesis Statement Research Objectives and Scope The Coltrane-Slonimsky Problem Background {#background} Historical Approaches to Improving Playing by Ear in Jazz Pedagogy The Aural Origins of Jazz Education Record Players as Pedagogical Tools Codification of Jazz Education The Chord-Scale Approach, Pattern Books and Vocabulary Acquisition The Influence of John Coltrane Slonimsky’s Thesaurus and Jazz Improvisation Modern Technological Approaches to Ear Training Integration of Technology in Educational Settings Conclusion Empirical Backgrounds: Systematic Musicological and Cognitive Psychological Music and combinatorics library(musiccombinatoricsr) Melody as Cognitive Psychology / Melodic represention Computed melodic features as a solution to selecting items Pattern books as item banks Playing By Ear: A Theoretical Model {#theoretical-model} Pfordresher’s H-PAC model Pfordresher’s cognitive model of singing accuracy Baker’s computational model of melodic dictation Models of sung recall Non-musical models of serial recall WM bits Bringing it together Moving from Theoretical to Computational Inputs Sequential Construction Function Application Mathematical Representation Algorithm Flow Final Equation Strategies Learning, forgetting The Melodic Mind As Item Bank Predictions: Melodic corpora as networks {#melodic_networks} musicassessr Similarity Simulation Model A computational ecosystem {#computational-ecosystem} pyin: Psychologically meaningful musical item banks: itembankr itembankr Datasets WJD Berkowitz Slonimsky Other useful functions Assessing musical behaviours: musicassessr Conclusion Generative Similarity {#generative_similarity} Calibration studies {#calibration_studies} Development of a melodic similarity algorithm for short recalled melodies {#melsim_development} Model of melodic difficulty {#pbet_online_study} Item curation {#item_curation} Heterogenity and item bank sampling {#heterogeneity_and_item_bank_sampling} TODO demo PBET etc. sampling functions via item response theory (IRT) (difficulty) via similarity via difficulty/similarity hybrid Approaches to similarity for large scale corpora {#item_banks_and_similarity} Problem: WJD_no_items &lt;- nrow(WJD::WJD(‘phrases’)) factorial(WJD_no_items) Approach #1: similarity of features as proxy for melodic similarity Approach #2: Generative similarity Approach #3: on breaking up items into ngrams, store representations/similarity. Reviewing and spaced repetition {#reviewing_and_spaced_repetition} identify correct vs incorrect ngrams in a recall: add incorrect ngrams to beginning of session buffer Reviewing and spaced repetition {#visual_vs_auditory_learning_pbe} identify correct vs incorrect ngrams Generative similarity {#generative similarity} identify correct vs incorrect ngrams Production perception paradigm {#production_perception} Foreword For Soraya. Sylvia, Daniel Müllensiefen, Reinhard Kopiez. Klaus Frieler, Mohamed Etteyeb Peter Harrison, Kilian Sander, Antoine Sachet, James Petticrew, Annabel Cohen "],["introduction.html", "3 Introduction 3.1 The Problem Domain and Approach 3.2 Motivations", " 3 Introduction 3.1 The Problem Domain and Approach Computational modelling 3.1.1 Computational modelling 3.2 Motivations The main problems this thesis attempts to solve is: A Computational Model of Playing By Ear Abilities: Given an aurally presented melody as input and a reproduction of that melody by a performer as output, what are the cognitive processes underlying performance? This problem is one of developing a cognitive model of playing by ear skills. I will specifically seek to develop a computational model of playing by ear skills. A Computational Model of Playing By Ear Learning and Skill Acquisition: Extending such a model, how do people learn to play by ear? How can people learn to play by ear effectively? item generation curation item selection: that of selecting new melodic material to learn to improve playing by ear skills. 3.2.1 Generalising beyond jazz Whilst I motivate this problem historically and pedagogically in terms of those learning jazz materials, I note, that I expect many of the outcomes to be relevant to playing by ear to very similar - if not virtually identical - for other types of music too, and at least very similar for singing by ear too which is far more ubiqutuous. Since virtually everyone can sing (CITE) but far fewer people have access to an instrument beyond the voice (CITE), I will often discuss singing by ear too and borrow from this literature. In general, much of the cognitive processes behind singing and playing by ear should be very similar. I thus suggest that, the outcomes of this dissertation are not only relevant to jazz musicians, but have a much larger impact, for musicians and musics of all kinds - at least in principle. In practice, model specifics may need adapting for utmost relevance to other domains. There are two (related) principal problems that this thesis aims to tackle. First, since, as of yet, there exists no comprehensive computational model of playing by ear skills (in terms of both acquisition and utilisation), I intend to first propose a theoretical model based on a synthesis of related literature. Once described, I seek to investigate and validate parts of this proposed model in light of empirical data. The second principal problem is to, given such a computational model, design a computer application which helps playing by ear learners more efficiently improve their skills. This part of the thesis has a practical deliverable component that is intended to be used in real-life learning situations, whilst being situated in a scientific framework - both theoretical and statistical. Such an application would be proposed in an open source framework that can be extended by future developers to add new features and improve existing components of the application. The main problem the application intends to solve is one of item selection i.e., finding “optimum” playing by ear items to learn for a given learner, at a given timepoint. "],["what-is-playing-by-ear.html", "4 What is playing by ear? 4.1 Learning to play by ear", " 4 What is playing by ear? In this dissertation, I define playing by ear as the ability to reproduce an aurally presented melody on and instrument (including the voice). To play well by ear means to reproduce the musical properties of the heard melody accurately across relevant domains, such as pitch, interval and rhythmic structures. I note, that, precisely what these important musical structures to assess accuracy by are consist of is non-trivial, and something partly explored on this thesis. I thus leave the definition relatively general at this point. To play badly by ear means to struggle to reproduce the musical structures contained in the melody. Note, that my definition separates playing by ear from “improvisation”, which is about spontaneously generating (new) ideas, not a faithful replication of that heard before. 4.1 Learning to play by ear I separate the general process of “playing by ear” from “learning to play by ear”, even though the two are intrinsically linked. “Playing by ear” presumes that the melody is sufficiently “prelearned” to be recalled almost perfectly. Conversely, learning to play by ear is a separate process, whereby the melody to be recalled is not yet stable enough in memory to be reproduced faithfully. It will take specifically at least more than one attempt to be recalled accurately - potentially “revised” - or may not be recallable in a given session. Thus, learning requires multiple attempts. Learning also requires that improvements are made over attempts, in the relative short term (Silas and Müllensiefen 2023), but also over longer time periods. "],["thesis-statement.html", "5 Thesis Statement 5.1 Research Objectives and Scope", " 5 Thesis Statement 5.1 Research Objectives and Scope PRQ1: How can one effectively learn to play by ear? The thesis aims to answer this question in psychological, musicological, computational, and pedagogical terms. SRQ1: What makes PBE difficult? (psychological, musicological) SRQ2: Can a computer app (with computational item selection) help learn more quickly? (computational) SRQ3: What does such a computational model need to take into account? (DASH?) (computational, psychological) SRQ4: Does presentation mode (visual vs. auditory) make a difference to learning? (pedagogical) SRQ5: Does singing a melody first help? (pedagogical) SRQ6: to what degree is playing by ear based on absolute vs. relative pitch? SRQ7: to what degree is playing by ear based on general working memory vs. acquired training? What is the relationship between sight-reading and PBE skills (we have this data, right?) PRQ2: Intervention: Does a program which implements these effectively work? (psychological, musicological, computational, pedagogical) 5.1.1 The Coltrane-Slonimsky Problem Solve the “Coltrane-Slonimsky Problem” Given a wealth of melodic possibilities to learn from, to select something to learn which is sufficiently challenging and interesting to the ear. Two key deliverables: front-facing apps: Slonimsky.app Songbird.training "],["background.html", "6 Background 6.1 Historical Approaches to Improving Playing by Ear in Jazz Pedagogy 6.2 The Aural Origins of Jazz Education 6.3 Record Players as Pedagogical Tools 6.4 Codification of Jazz Education 6.5 The Chord-Scale Approach, Pattern Books and Vocabulary Acquisition 6.6 The Influence of John Coltrane 6.7 Slonimsky’s Thesaurus and Jazz Improvisation 6.8 Modern Technological Approaches to Ear Training 6.9 Integration of Technology in Educational Settings 6.10 Conclusion 6.11 Empirical Backgrounds: Systematic Musicological and Cognitive Psychological", " 6 Background First, I will motivate my discussion of learning to play by ear with some historical context around the traditional methods that have been used, particularly with in the context of learning to play jazz music. Then, I will largely leave this historical context behind and motivate the question from systematic musicological and cognitive psychological points of view, where the remainder of this manuscript will largely remain. 6.1 Historical Approaches to Improving Playing by Ear in Jazz Pedagogy Jazz music began as an aural tradition where skills were developed through listening and imitation rather than formal instruction. The development of aural skills—often described as “playing by ear”—has been a central feature of jazz learning, especially throughout the 20th and 21st centuries. In this section, I describe the historical evolution of approaches to developing aural skills in jazz education, from early reliance on recordings to modern technological methods. I survey how record players, transcription books, and pattern books have supported the ear training process in jazz education and the evolving interplay between informal, aural traditions and formalised, institutional methods. This suggests a gradual shift from purely aural learning to increasingly systematised approaches, reflecting broader trends in the institutionalization of jazz education. Despite this evolution, the fundamental importance of developing acute listening skills remains central to effective jazz pedagogy. 6.2 The Aural Origins of Jazz Education The early history of jazz was characterised by learning that occurred primarily through aural means. As Herzig (2019) notes, this involved “hours of listening, transcribing, and participating in jam sessions” before formal educational approaches emerged. In this pre-institutional era, the transmission of jazz knowledge occurred organically within communities of practice, with experienced musicians serving as mentors to aspiring players. This master-apprentice relationship formed the foundation of early jazz pedagogy, where direct demonstration and immediate repetition were the primary teaching methods. The absence of formal jazz education in the early period necessitated this aural approach, as musicians needed to develop their skills through direct engagement with the music itself. While some things were written down, such as Downbeat transcriptions in the 1940’s (Koger et al. 1985), the vast majority of what people learned and played was done by ear. This established a precedent that would continue to influence jazz pedagogy even as more formalised approaches developed. The emphasis on learning by ear ensured that early jazz musicians developed strong aural skills as a natural consequence of their training process. 6.3 Record Players as Pedagogical Tools The development of recording technology dramatically transformed jazz education by making the music of master performers accessible to aspiring musicians regardless of geographic location. Acevedo notes in his dissertation that recordings became essential educational resources, allowing students to study the repertoire and improvisations of established artists. This technological advancement democratized access to jazz education, extending learning opportunities beyond those who could physically attend performances or study with established musicians. Re (2004) notes that technologies such as variable-speed turntables and digital audio software enabled closer analysis, allowing students to slow down recordings for detailed ear training. Listening was an active engagement: learners would loop short segments, replicate phrases, and match articulation. The ability to repeatedly listen to recorded performances proved particularly valuable, especially since records could be “endlessly repeated” (Surber 2009). This repetition allowed students to internalize not only melodies and chord progressions but also nuances of style, tone, and expression that were difficult to communicate through written notation. The practice of slowing down recordings or lifting the needle to replay difficult passages became standard pedagogical techniques that allowed for deep analysis of complex musical passages. The phonograph was an indispensable tool for jazz learners. Listening to records enabled musicians to internalize jazz language and style. Berliner (1994) emphasizes that imitation from recordings helped players build a mental library of harmonic and melodic ideas, forming a foundation for improvisation. Even as jazz moved into universities, listening retained primacy. Wilf (2012) describes rituals within jazz education that centered around repeated listening to canonical recordings—practices that continued to uphold the oral-aural traditions at the heart of jazz pedagogy. 6.4 Codification of Jazz Education The transition from purely aural learning to more systematized approaches began in the mid-20th century. Herzig (2019) identifies the 1930s as a pivotal period, with early attempts to codify jazz instruction including Norbert Bleihoof’s “Modern Arranging and Orchestration” (1935) and Lee Bowden’s training program for Afro-American Service Musicians at the Great Lakes Naval Base (1942-45). These initial efforts to systematize jazz education represented the beginning of a shift toward more formalized instructional approaches, though they remained relatively limited in scope. – Transcribing solos has historically been a core method of ear training in jazz. Berliner (1994) and Re (2004) argue that the act of transcribing by ear strengthens aural recognition and improvisational understanding. However, the rise of printed transcription books—like the Charlie Parker Omnibook—introduced shifts in practice. While these books provided accessible models for study, Witmer and Robbins (1988) found that many early transcription collections failed to support active listening. The danger, they argue, lies in students relying on notation rather than using their ears. Academic consensus (Re 2004; Berliner 1994) supports transcription as most effective when used in tandem with active listening—students should first attempt to transcribe by ear and then use notated versions for verification or analysis. – A watershed moment in jazz education came in the late 1960s, with what Herzig terms “the ABCs of jazz” - referring to the influential work of Jamey Aebersold, David Baker, and Jerry Coker. Their development of comprehensive instructional materials, including Baker’s “Jazz Improvisation: a Comprehensive Method for all Players” (1969) and Aebersold’s play-along recordings, established a framework for jazz education that continues to influence pedagogical approaches today. These materials helped standardize jazz instruction and made it more accessible to students without direct access to master performers, contributing to what Prouty describes as the “wholesale growth” of jazz education during the 1960s and 70s. 6.5 The Chord-Scale Approach, Pattern Books and Vocabulary Acquisition The chord-scale approach pioneered by Baker, Aebersold, and Coker became a dominant paradigm in jazz education. As Spice notes in his literature review of jazz improvisation pedagogy, these influential educators “focus on scales and modes to examine improvisation”. This approach provided students with systematic frameworks for navigating harmonic structures, offering concrete tools for developing improvisational facility. The emphasis on scales and patterns created a more accessible entry point for students transitioning from classical training to jazz improvisation. Aebersold’s own description of his pedagogical evolution reveals the gradual systematization of his approach: “I published my first jazz play-a-long in 1967 and the [accompanying] booklet included concert [key] chords for each track. Subsequent printings added transposed chord symbols [for Bb and Eb instruments] and, eventually, I added the needed transposed scales and chords for each track”. This approach represented a compromise between purely aural learning and more visually-oriented instructional methods, coupling “the eye with the ear” in ways that provided students with multiple pathways for internalizing jazz vocabulary. The development of pattern books and play-along recordings created standardized resources that facilitated the institutional teaching of jazz improvisation. Pattern books, such as Coker’s Patterns for Jazz and Baker’s Improvisational Patterns, systematized jazz vocabulary through short, transposable licks and exercises. Witmer and Robbins (1988) recognize their role in helping students internalize chord-scale relationships and idiomatic phrases. However, these tools also sparked criticism. Benward and Wildman (1984) caution that over-reliance can yield formulaic improvisation disconnected from the spontaneous, reactive nature of jazz. Wilf (2012) views pattern books as part of a broader institutional shift from oral tradition to codified curriculum. Educators like Coker (1964) emphasized integrating these resources with listening and improvisation. Used as an ear-training aid, patterns could reinforce melodic shapes and harmonic contexts, provided students also engaged with recordings and creative application. – In more recent times, other repositories of melodies have emerged which are not usually as concerned with twelve-tone possibilities, but are more constrained to a pedagogically focused item banks. Such volumes can be viewed as melodic etudes, which are usually geared towards jazz improvisation and acquiring inner melodic representations. In the music theory and music education literatures, particularly with respect to jazz improvisation, there are many books which contain itemised melodic patterns to stimulate compositional ideas or so that training musicians can practise acquiring cognitive representations of new melodic material (Lateef, 2015; Weiskopf, 2015; Slonimsky, 1947; Ricker, 1999). Such books are essentially corpuses (of which they will from here be referred to) of melodic grammar and possibilities. As well as improving one’s melodic “vocabulary”, such books can be used to develop technical prowess, by challenging the player to acquire new action patterns to perform the items. However, often these volumes are just repositories of melodies and lack a systematic structure, or if they do, the structure is not built upon rigid principles which advance the objective of efficient learning. This is also a technological issue: books are not able to break down items into smaller pieces and consider the relationship between items. Instead, the meaning as to be discovered post hoc by the book’s user. Therefore, by not bring structured in a way that makes them optimised for memorisation such books are limited. Typically, contents will be structured into discrete items where each item represents a particular melodic sequence. However, each of these items can be broken into smaller contiguous subsets known as n-grams (Damashek, 1995), here called “chunks”. Such componentisation makes items more readily memorable since sequence length is a major predictor of how memorable an item is (Cowan, 2010; Miller, 1956). The implication is that, by first learning smaller chunks and then increasing the size of chunks, one can optimise the learning process (Lehmann &amp; Kopiez, 2011). To undertake such a task manually is more or less impossible as it would require an individual to comprehend a combinatorial explosion of relationships between the items in a given corpus (intra-corpus). Moreover, different corpuses will also share identical and similar chunks, so learning one chunk may support learning other chunks inter-corpuses. It would be redundant to treat these as separate chunks (except to count chunks by frequency, another potential indicator of its usefulness) and would instead be more efficient to have a centralised system which can consider information inter-corpus. 6.6 The Influence of John Coltrane John Coltrane’s approach to improvisation, characterized by systematic exploration of harmonic possibilities, had a profound impact on jazz pedagogy. Research examining Coltrane’s melodic vocabulary reveals his methodical approach to developing improvisational frameworks, including his systematic exploration of harmonic structures through patterns and exercises. His disciplined practice methods and innovative harmonic concepts established new paradigms for jazz improvisation that would be incorporated into educational approaches. Coltrane’s influence extended beyond his specific musical innovations to encompass his overall approach to musical development. His systematic exploration of musical possibilities demonstrated the value of structured practice and theoretical understanding alongside intuitive improvisation. Scholars have analyzed Coltrane’s use of pitch-class sets and other patterns, noting the “potential influence of Nicolas Slonimsky’s Thesaurus of Scales and Melodic Patterns (1947)”. This connection between Coltrane’s innovative improvisational approach and Slonimsky’s theoretical work illustrates the emerging synthesis between systematized approaches and creative expression in jazz education. 6.7 Slonimsky’s Thesaurus and Jazz Improvisation Nicolas Slonimsky’s “Thesaurus of Scales and Melodic Patterns” represents a significant intersection between theoretical systems and jazz improvisation. Although originally conceived as a classical resource, the text became influential among jazz musicians seeking to expand their improvisational vocabulary. According to research on Coltrane’s musical development, “the influence of Nicolas Slonimsky’s Thesaurus of Scales and Melodic Patterns on the developing melodic vocabulary of John Coltrane was profound”. This adoption of Slonimsky’s work illustrates how jazz education has drawn from diverse sources beyond the jazz tradition itself. The Thesaurus provided jazz musicians with systematic approaches to exploring melodic possibilities within the twelve-tone chromatic scale. As noted in Joe Hubbard’s educational materials, the book “literally contains millions of permutations based on the equal intervallic divisions of the 12-tone chromatic scale” and was utilized by numerous influential jazz musicians including “John Coltrane, Pat Martino, Herbie Hancock, and Jaco Pastorius”. The application of these patterns to jazz contexts demonstrates how theoretical systems could be adapted to serve improvisational purposes, expanding the vocabulary available to jazz improvisers while maintaining connections to the aural tradition. – In 1947, the Russian-American composer Nicolas Slonimsky who was “obsessed with twelve-tone rows” (https://books.google.de/books?id=r9S--ESUuxEC&amp;pg=PR151&amp;lpg=PR151&amp;dq=schoenberg+feat+of+mental+gymnastics&amp;source=bl&amp;ots=V4wLBZKQPn&amp;sig=ACfU3U2mfVWZ-_DJgE8OEHtNN-SCCS5HJA&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwjooqOFtcTtAhV75-AKHQqaA9EQ6AEwBHoECAYQAg#v=onepage&amp;q&amp;f=false) produced a seminal book in music theory: the Thesaurus of Scales and Melodic Patterns (from here referred to as the Slonimsky’s Thesaurus; Slonimsky, 1947). As suggested by its title, the book is an exhaustive collection of musical melodies which Slonimsky laboriously generated manually and systematically. The purpose of such a volume was to provide a repository of musical melodies which breaks free of traditional tonal harmonic principles. In other words, it was an attempt to systematically open up possibilities in the Western Music system which had not yet been explored. Slonimsky’s undertaking can be viewed as a way of codifying and unlocking the potential of music through systematization; it highlights that by algorithimic thinking, new possibilities can be unleashed. As such, Slonimsky’s volume fascinated.. Coltrane … Zappa. One basic principle behind Slonimsky’s systematization was to divide one or more octaves of the twelve-tone system into symmetrical intervals and, from there, systematically interpolate different numbers of notes between the intervals created by the divisions. Additionally, he used other formulae to generate melodic patterns which had not yet been yield by his basic scheme. Of The Thesaurus, Schoenberg wrote to Slonimsky, “you might [have] in all probability organized every possible succession of tones” and referred to his work as “an admirable feast of mental gymnastics”. Whilst the former is almost certainly not true (unless constrained to a length, the possibilities of melodies are infinite), the latter is undoubtedly. However, such a task would now be solved at ease by a script on a modern computer. =&gt; Coltrane’s use represents a desire to move from simply “learning the oral tradition” to developing new melodic ideas. pedagogical “tried-and-tested” vs. aspirational melodic vocabularies – https://books.google.de/books/about/Perfect_Pitch.html?id=V1cIAQAAMAAJ&amp;redir_esc=y https://wiki.killuglyradio.com/wiki/Nicolas_Slonimsky 6.8 Modern Technological Approaches to Ear Training Contemporary approaches to ear training have leveraged technological advancements to create new pedagogical tools. The development of online ear training platforms has expanded access to structured practice resources, as described by IWasDoingAllRight: “Ear training has been a regular part of my practice routine since the beginning of 2004, when I created the first version of my free online ear training tool”. These digital tools allow students to practice identifying intervals, chords, and progressions with immediate feedback, providing structured approaches to developing aural skills that complement traditional transcription practices. The range of technological resources has continued to expand, with applications designed to address specific aspects of ear training. As documented by JazzAdvice, contemporary jazz ear training must prepare musicians for the complex demands of real-time improvisation, including the ability to “learn tunes from recordings” and “hear chord changes and progressions easily”. Modern digital tools address these needs through targeted exercises focusing on intervals, chord qualities, voicings, and progressions. These technological approaches maintain connections to the aural tradition while providing more systematic pathways for skill development. 6.9 Integration of Technology in Educational Settings Educational institutions have increasingly incorporated technological tools into their ear training curricula. Research from Silpakorn University describes a jazz ear training course that utilized “teaching materials (e.g., exercises, audio files, demonstration clips, and videos)” delivered through Google Classroom during the COVID-19 pandemic. This integration of digital resources allowed for continued instruction despite physical distancing requirements, illustrating the adaptability of contemporary ear training approaches. The adaptation of traditional methods to digital formats represents an evolution rather than a revolution in jazz ear training pedagogy. As described in “Tools For Ear Training Pedagogy,” contemporary approaches continue to emphasize the development of core aural skills while leveraging technology to enhance access and efficiency. The research conducted through interviews with thirteen music educators and professionals confirms that while the tools have evolved, the fundamental goal remains developing the ability to perceive and reproduce musical sounds accurately. This continued emphasis on aural skills maintains connections to jazz’s origins as an aural tradition even as educational approaches become increasingly sophisticated. 6.10 Conclusion Record players, transcription books, and pattern books have each contributed to jazz ear training across the 20th and 21st centuries. Academic literature affirms that while written and technological resources are valuable, they must be embedded in a pedagogy that privileges listening. The most enduring jazz learning strategies integrate tools into a broader aural framework—preserving the tradition of learning music by ear, even in modern academic contexts The historical development of approaches to improving playing by ear in jazz pedagogy reveals a gradual evolution from purely aural learning to increasingly systematized methods. As Liebman argues in his discussion of transcription practices, this process involves “a three part learning process: body, mind and spirit-in that order”. This holistic view recognizes that effective ear training integrates physical, intellectual, and intuitive aspects of musical development, reflecting the multifaceted nature of jazz improvisation itself. Despite the increasing systematization of jazz education, the fundamental importance of aural learning remains. Louise Denson’s work on Third Stream Ear Training at the Queensland Conservatorium acknowledges that “aural training for improvisers is a specialized area of musicianship” requiring both “conventional skills” and “a high level of aural awareness which permits real-time reactions to a variety of musical stimuli and contexts”. This recognition of the unique demands placed on jazz improvisers has led to specialized approaches that maintain connections to the aural tradition while incorporating more structured pedagogical methods. The continued evolution of ear training approaches in jazz education reflects broader trends in the field, balancing respect for traditional aural learning with recognition of the benefits offered by more systematized methods and technological tools. This integration of approaches provides contemporary students with multiple pathways for developing the aural skills essential to effective jazz performance. As jazz education continues to evolve, maintaining this balance between aural tradition and systematized instruction remains a central challenge and opportunity for jazz pedagogy. 6.11 Empirical Backgrounds: Systematic Musicological and Cognitive Psychological The derivation of Slonimsky’s Thesaurus - a new to document and rationalise logical melodic vocabulary - leads to a more general issue around combinatorics and musical (melodic) material. "],["music-and-combinatorics.html", "7 Music and combinatorics", " 7 Music and combinatorics Introduce notion of large melodic learning vocabularies (LMLVs), ? # library(musiccombinatoricsr) "],["melody-as-cognitive-psychology-melodic-represention.html", "8 Melody as Cognitive Psychology / Melodic represention", " 8 Melody as Cognitive Psychology / Melodic represention (herbornFeaturesPerceptionConstruction2022?) "],["computed-melodic-features-as-a-solution-to-selecting-items.html", "9 Computed melodic features as a solution to selecting items", " 9 Computed melodic features as a solution to selecting items "],["pattern-books-as-item-banks.html", "10 Pattern books as item banks", " 10 Pattern books as item banks The book has at least 1,400 discrete items and some of the patterns are terrifically long and complicated. Additionally, nearly all of the melodies are presented from a single note, C, and could be transposed to start on the other 11 chromatic tones. This means there are at least 16,800 (12 * 1400) items to be learned. The author’s saxophone tutor, who was a virtuoso, once said, “Oh, don’t bother trying to learn [Slonimsky’s Thesaurus of Scales and Melodic Patterns] systematically”. This was a wise comment since, as there is so much information, it is almost impossible for a human to comprehend and track their learning of it systematically. However, with advances in computation, this is a relatively easy challenge to solve once the data is in digital form. The author entered the Slonimsky’s Thesaurus corpus into his computer to provide a digital representation. This corpus will remain the test case for description in this document later on. "],["theoretical-model.html", "11 Playing By Ear: A Theoretical Model", " 11 Playing By Ear: A Theoretical Model As far as the author is aware, no computational model of playing by ear has been described in the music psychology, or related, literature(s). Thus, a first step in this thesis is to propose a theoretical model, which can then later be formulated more precisely as a computational model, then tested, partly with data collected throughout this thesis. However, related computational models have been described, for instance in the domain of aural skill acquisition (Baker 2019) and sung melodic recall by the author (Silas and Müllensiefen 2023; Silas, Müllensiefen, and Kopiez 2023). Theoretical cognitive models have also been described in the domain of singing accuracy (Pfordresher et al. 2015). Therefore, in this section, I will attempt to synthesise this literature to propose a corresponding model specifically for playing by ear skills. I distinguish between two basic playing by ear processes: a) playing by ear skill acquisition (learning) and b) playing by ear skill execution (recall). "],["pfordreshers-h-pac-model.html", "12 Pfordresher’s H-PAC model", " 12 Pfordresher’s H-PAC model "],["pfordreshers-cognitive-model-of-singing-accuracy.html", "13 Pfordresher’s cognitive model of singing accuracy 13.1 Baker’s computational model of melodic dictation", " 13 Pfordresher’s cognitive model of singing accuracy I start first by using Pfordresher et al. (2015)’s cognitive (but non-computational) model of singing accuracy, which is the most broad of the models I will review. At the low level, this model comprises an auditory feedback loop. In this loop, first, external auditory input is processed as low-level perceptual representations of sound (pitch, duration, timbre, loudness). Such low-level representations are used as input to a translation model, which relates auditory input to sensorimotor action that is relevant to singing. Hence, this enables the guidance of a singer’s sensorimotor plans to adjust their singing (e.g., to be in tune), in response to auditory feedback. Such changes in sensorimotor actions comprise physical processes like respiration, phonation, and articulation. Abstracting the sensorimotor part to the domain of playing by ear, such physical processes would be somewhat instrument-specific. For many instruments, the physical part will involve finger coordination (e.g., clarinet, violin), but for some, coordination will be more at the level of the arm (e.g., percussion, drums). Many processes will be instrument-specific processes. For example, for brass and woodwind instruments, requiring to coordinate an embouchure to produce a sound. We do not exhaust these instrument-specific processes, but only state that such physical processes are part of the model, with instrument-specific attributes. The lower-level auditory representations are also used as input to higher levels of cognition, which hold mental templates about music (e.g., its features, such as its tonality), stored in long- term memory (Baddeley et al., 2009). These templates allow auditory content to be categorized, forming more sophisticated representations of it, taking on musical domains such as representations of (melodic) features like tonality and contour, as well as segmenting melodies into coherent perceptual chunks. These formed higher-level representations can in turn be used as input back to the lower-level auditory feedback loop and further inform sensorimotor planning. Hence, the overall architecture of Pfordresher et al. (2015)’s cognitive model is bidirectional: both “top down” and “bottom up”. Altogether, this system enables a singer - to fulfill objectives related to sung recall (i.e., hearing stimuli, representing its musical features mentally, responding through singing, and adjusting behavior to fulfill the goal sufficiently). This can readily be abstracted to playing by ear too: the only difference being in the motor plan aspects, which, as mentioned, are instrument-specific. Our focus in the current manuscript is on the higher-level aspects of this model: memory for melodic representations. Caption for the image 13.1 Baker’s computational model of melodic dictation "],["models-of-sung-recall.html", "14 Models of sung recall", " 14 Models of sung recall Lastly, I synthesise models from my own research regarding sung melodic recall. My Silas, Müllensiefen, and Kopiez (2023) study investigated sung recall by examining its relationship with other related skills and participant attributes. Demographically, better sung recall ability ability was associated with more musical training (𝛽 = 0.07), a younger age (𝛽 = -0.05), and being female (𝛽 = -0.03), though the latter two effects were small. The findings suggest that while musical training can enhance singing ability, inherent skills might also predispose individuals to seek musical training. Moreover, there was a relatively large difference between the marginal and conditional R^2 values, which suggests that there is a sizeable proportion of individual differences in the sample of participants tested which explains SAA performance which shows that individual differences should explain performance on a task in which one can develop high levels of domain-specific expertise. We found there that melodic discrimination, pitch imagery abilities, and mistuning perception appear to be fundamental skills contributing to melodic sung recall. The sung recall score we devised moderately correlated with self-reported singing ability (r = .46) and musical training (r = ?). However, it shows no significant correlation with visuospatial working memory or pitch discrimination, aligning with previous research and suggesting that singing ability is not closely linked to low-level perceptual processes. This suggests that, whilst The study also shows that melodic features which indicate melodic complexity (including melody length) are relevant predictors of sung recall performance. These predictors represented melody length, as well as features related to contour, tonality, statistical occurrence of N-grams in the melody, and durational complexity. Rhythmic trials were generally found to be more difficult (B = -0.15, p &lt; .001) and we found that it was appropriate to create separate models for arhythmic and rhythmic. In another of my papers, (Silas and Müllensiefen 2023), we investigated how individuals learn and recall melodies using a computational approach that emphasizes similarity metrics rather than traditional accuracy-based methods. The research involved 31 participants who sang back 28 melodies presented either as piano sounds or vocal audio excerpts from pop songs, with each melody repeated up to six times. The similarity between the target melody and the participants’ sung recalls was measured using advanced algorithmic techniques. The primary goal was to understand how melodic recall improves over successive attempts and what factors most significantly influence recall accuracy. One of the key findings of the study is that the length of sung recall attempts consistently increases across multiple attempts, and this increase significantly correlates with the overall similarity to the target melody. This observation challenges the traditional view that musical features such as interval patterns or tonality are the primary factors influencing melodic recall. Instead, the study suggests that the sheer length of the melody plays a more critical role, indicating that general memory constraints may be more influential than music-specific features. This insight aligns with theories of working memory, suggesting that melodic recall shares characteristics with other types of serial recall rather than being purely domain-specific to music. A significant finding (presented there in Figure 8), examines how similarity changes as a function of attempt and the specific section of the melody (beginning, middle, end). The results show that similarity performance increases more rapidly for the beginning of the melody compared to the middle and end across successive attempts. This indicates that participants tend to stabilise their recall of the initial melodic segments earlier than the middle or end sections. The end sections, in particular, show a slower rate of improvement, suggesting that the latter parts of a melody are more challenging to accurately recall perhaps due to the higher working memory load as a result of having to remember more notes, the later you are in a position, or that generally people engaging in sung recall prioritise getting the earlier parts melody correct first. This finding supports the theory that memory encoding is stronger for the beginning of sequences, a phenomenon consistent with the primacy effect observed in other types of serial recall tasks. It also highlights that recall accuracy is not uniformly distributed across a melody, with the initial segments being more robustly learned compared to later ones. The study also found that musical training did not significantly enhance recall performance when similarity metrics were used as the primary assessment method, as shown in another key result. This challenges the conventional belief that formal musical training substantially improves melodic recall ability. Instead, the data suggests that domain-general memory skills may be just as important, pointing to a more integrative understanding of how musical and non-musical cognitive processes interact. Moreover, the results highlight that similarity scores increase with each successive attempt, but the rate of improvement diminishes after the third or fourth attempt. This pattern suggests that the most substantial gains in melodic recall occur early in the learning process, followed by incremental refinements in pitch and rhythm accuracy. Additionally, melodies presented as vocal audio excerpts resulted in higher recall accuracy compared to piano sound presentations, indicating that the human voice might provide additional mnemonic cues that aid in memory encoding. Overall, the study’s use of similarity-based metrics, particularly the “opti3” metric that integrates pitch intervals, harmonic progression, and rhythmic similarity, offers a more nuanced and accurate assessment of how melodies are learned and recalled. By focusing on the gradual increase in recall length and the differential improvement across melodic segments, the study sheds light on the underlying cognitive processes involved in melodic memory, emphasizing the role of general memory mechanisms and the relatively limited impact of formal musical training. "],["non-musical-models-of-serial-recall.html", "15 Non-musical models of serial recall", " 15 Non-musical models of serial recall (look at Silas &amp; Müllensiefen paper) ACT-R "],["wm-bits.html", "16 WM bits", " 16 WM bits Baddeley and hitch Berz (1995) LTWM (erricsson) Silas et al. (2022) discussion around MWM and GWM "],["bringing-it-together.html", "17 Bringing it together 17.1 Moving from Theoretical to Computational 17.2 Mathematical Representation 17.3 Algorithm Flow 17.4 Final Equation", " 17 Bringing it together In sum, then, 17.1 Moving from Theoretical to Computational “When we develop a psychological theory that is sufficiently precise to be implemented as a computer program, we call it a computational model. The process of developing such theories, and implementing their corresponding computer programs, is then called computational modelling.” (Harrison 2025). At this point, I already suggest a more specific feature to the model: that for playing by ear tasks, there exists a mental melodic “similarity” algorithm, housed in working memory. The input to this module is the target melody and the evolving real-time assessment of the melody being produced in the moment. The performer must hear the target melody, store this in short term memory as a reference, and then continuously update the target melody which each new note that is produced. I speculate that the mind recomputes the similarity between the presently number of recalled notes and the target melody iteratively, each time a new note is added. In other words, a check for the accuracy is made every time a note is recalled, and the presence of an error and its nature, will inform whether or not the performer stops to start again or continues to proceed recalling the melody, at least in the stage of learning. Formally: 17.1.1 Inputs \\(T = [t_1, t_2, \\dots, t_n]\\): TargetMelody of fixed length \\(n\\). \\(R = [r_1, r_2, \\dots, r_k]\\): RecalledMelody of length \\(k\\), unknown a priori. 17.1.2 Sequential Construction \\(T\\) is fixed and built one note at a time. \\(R\\) is sequentially constructed one note at a time. 17.1.3 Function Application At each step \\(i\\) (current length of \\(R\\)), the function MelSim is applied to TargetMelody and the current length of RecalledMelody. 17.2 Mathematical Representation Let: - \\(T_i\\) be the prefix of the TargetMelody up to length \\(i\\), i.e., \\(T_i = [t_1, t_2, \\dots, t_i]\\). - \\(R_i\\) be the current state of the RecalledMelody of length \\(i\\), i.e., \\(R_i = [r_1, r_2, \\dots, r_i]\\). - \\(\\text{MelSim}(T_i, R_i)\\) be the similarity function between the two melodies at length \\(i\\). The MelSim function can be formulated as: \\[ \\text{MelSim}(T_i, R_i) = f(T_i, R_i) \\] Where: - \\(f\\) is a similarity measure (e.g., distance function, alignment score). - \\(i\\) iterates from 1 to \\(n\\), where \\(n\\) is the fixed length of the target melody. 17.3 Algorithm Flow Start with an empty recalled melody \\(R\\). For each new note \\(r_i\\) added to \\(R\\): Compute the similarity: \\(\\text{MelSim}(T_i, R_i)\\) if \\(i = n\\). Repeat until the entire recalled melody is constructed. 17.4 Final Equation The similarity calculation is performed only when the length of the RecalledMelody equals the fixed length of the TargetMelody. Therefore, the final equation is expressed as: \\[ \\text{MelSim}(T, R_n) = f(T, R_n) \\] I note that the MelSim algorithm is itself modular and of discussion in and of itself (cite M&amp;F). For the purpose of this paper, "],["strategies.html", "18 Strategies", " 18 Strategies Beyond scope of this dissertation to investigate in detail. Pop strategies hypotheses: (Liscio and Brown 2024) Also, we have our own text data, for later. "],["learning-forgetting.html", "19 Learning, forgetting", " 19 Learning, forgetting Ebbinghaus, learning curves Unit of sleep "],["the-melodic-mind-as-item-bank.html", "20 The Melodic Mind As Item Bank", " 20 The Melodic Mind As Item Bank Big concept "],["predictions.html", "21 Predictions:", " 21 Predictions: Simpler melodies will rely more on general working memory than musical working memory. In the short term (&lt; 30 mins), melodies learned by sight will be less better retained than those "],["melodic_networks.html", "22 Melodic corpora as networks", " 22 Melodic corpora as networks 22.0.1 musicassessr "],["similarity-simulation-model.html", "23 Similarity Simulation Model", " 23 Similarity Simulation Model "],["computational-ecosystem.html", "24 A computational ecosystem 24.1 pyin:", " 24 A computational ecosystem To investigate computational questions related to playing by ear, an appropriate computational architecture is required. Whilst many musicological and psychological tools exist, as far as I am aware, there is no open source academic framework that provides an end-to-end solution for recording produced musical data, transcribing audio into useful symbolic representations, and assessing these representations within a scientific statistical modelling framework - all in real-time. However, it would be far beyond the scope of any individual to produce all the required components, themselves requiring considerable research. Indeed, we stand on the shoulders of giants. In that respect, my work here has mainly been to find ways to combine the already existing tools into a framework - to get them to interact with one another - and create useful data structures to store relevant information and make it readily usable in web applications. To not detract from the theoretical questions in this manuscript, I will only give a brief tour of this architecture here. However, please see the documentation for a more thorough treatment. I will start with the low-level packages and work my way up to the higher level ones. 24.1 pyin: To be able to assess music production data, it is first necessary to melsim "],["psychologically-meaningful-musical-item-banks-itembankr.html", "25 Psychologically meaningful musical item banks: itembankr 25.1 Datasets 25.2 Other useful functions 25.3 Conclusion", " 25 Psychologically meaningful musical item banks: itembankr 25.0.1 itembankr The purpose of itembankr is to.. The present paper details a new set of scripts which allow a user to process a corpus programmatically to solve some of the problems above. Consequentially, it is able to: a) provide useful insights into that particular corpus b) process the corpus into more readily memorable structures c) facilitate the ability to relate items to one another intra-corpus and inter-corpus . In doing so, the application should be able to improve the amount of time a user requires to learn melodic information from repositories of patterns. library(itembankr) library(WJD) library(Berkowitz) #library(Slonimsky) 25.1 Datasets 25.1.1 WJD The command used to create the item bank was: WJD &lt;- corpus_to_item_bank(corpus_name = &quot;WJD&quot;, corpus_df = phrases_dbs2, output_type = &quot;ngram&quot;, phrases_db = phrases_dbs2, launch_app = FALSE) The properties of the item bank are: WJD::WJD itembankr::hist_item_bank(WJD::WJD) 25.1.2 Berkowitz head(Berkowitz::Berkowitz) itembankr::hist_item_bank(Berkowitz::Berkowitz) 25.1.3 Slonimsky head(Slonimsky::Slonimsky) itembankr::hist_item_bank(Slonimsky::Slonimsky) 25.2 Other useful functions itembankr::subset_item_bank() itembankexplorer::item_bank_explorer(Berkowitz::Berkowitz) Much of the architecture is grouped under the musicassessr package and ecosystem (silasMusicassessrEcosystemRecord2023?). musicassessr is, in essence, a giant wrapper, bringing already developed psychological and musicological into the same software environment, backed by a statistical modelling framework in R (R Core Team 2020). 25.2.1 Assessing musical behaviours: musicassessr library(musicassessr) library(htmltools) htmltools::tagList( lapply(musicassessr::musicassessr_js(visual_notation = TRUE), function(x) { if(base::startsWith(x, &quot;http&quot;)) { htmltools::tags$script(src = x) } else { htmltools::includeScript(x) } }) ) musicassessr::present_stimuli( stimuli = c(60, 62, 64, 65), stimuli_type = &quot;midi_notes&quot;, display_modality = &quot;visual&quot; ) 25.3 Conclusion Thus, a primary outcome of this dissertation was the development of a computational ecosystem to record and assess music production data in real-time. "],["generative_similarity.html", "26 Generative Similarity", " 26 Generative Similarity "],["calibration_studies.html", "27 Calibration studies", " 27 Calibration studies 11 participants.. BDS tasks represent a classic measure of WM (Case &amp; Globerson, 1974). Participants must remember an ordered sequence of digits, mentally reverse it, and enter the reversed sequence by clicking the numbers on a key- pad. We reimplemented the version used by Vock and Holling (2008), which consisted of 12 trials of increas- ing difficulty using sequences of four to seven digits length. Since all stimuli were presented in the visual domain and responding involved clicking digits on a visually displayed keypad that spatially organized the digits, we consider this a visuospatial BDS task. Previous item response theory (IRT) models for this task could not be used as they were constructed based on their inclusion in another battery of tasks (as explained above). We computed IRT scores for each participant by fitting a Rasch psychometric model to the collected data. A Pearson’s product-moment correlation of the sum scores with the IRT scores yielded a very strong correlation (r 1⁄4 .99, p &lt; .01), indicating a high level of consistency between the classical test theory and IRT scoring methods. "],["melsim_development.html", "28 Development of a melodic similarity algorithm for short recalled melodies", " 28 Development of a melodic similarity algorithm for short recalled melodies "],["pbet_online_study.html", "29 Model of melodic difficulty", " 29 Model of melodic difficulty "],["item_curation.html", "30 Item curation", " 30 Item curation "],["heterogeneity_and_item_bank_sampling.html", "31 Heterogenity and item bank sampling", " 31 Heterogenity and item bank sampling "],["todo-demo-pbet-etc.-sampling-functions.html", "32 TODO demo PBET etc. sampling functions 32.1 via item response theory (IRT) (difficulty) 32.2 via similarity 32.3 via difficulty/similarity hybrid", " 32 TODO demo PBET etc. sampling functions PBET::item_characteristics_sampler_pbet() 32.1 via item response theory (IRT) (difficulty) 32.2 via similarity 32.3 via difficulty/similarity hybrid "],["item_banks_and_similarity.html", "33 Approaches to similarity for large scale corpora 33.1 Problem: 33.2 Approach #1: similarity of features as proxy for melodic similarity 33.3 Approach #2: Generative similarity 33.4 Approach #3: on breaking up items into ngrams, store representations/similarity.", " 33 Approaches to similarity for large scale corpora opti3 etc. 33.1 Problem: # WJD_no_items &lt;- nrow(WJD::WJD(&#39;phrases&#39;)) # factorial(WJD_no_items) 33.2 Approach #1: similarity of features as proxy for melodic similarity Conclusion: similarity of features =! melodic (opti3/[perceptual?!]) similarity - this is important, because similar features will produce similar difficulty scores (need to test this formally though).. which shows that similarity as a separate item selector to difficulty is warranted/important (potentially) 33.3 Approach #2: Generative similarity bringing in desimilarize et al. app 33.4 Approach #3: on breaking up items into ngrams, store representations/similarity. by definition ngrams will be similarity to the overall melody they come from "],["reviewing_and_spaced_repetition.html", "34 Reviewing and spaced repetition", " 34 Reviewing and spaced repetition "],["identify-correct-vs-incorrect-ngrams-in-a-recall-add-incorrect-ngrams-to-beginning-of-session-buffer.html", "35 identify correct vs incorrect ngrams in a recall: add incorrect ngrams to beginning of session buffer", " 35 identify correct vs incorrect ngrams in a recall: add incorrect ngrams to beginning of session buffer prioritise those with temporal order prioritise those which are easier or, just incrementally test until each ngram is obtained from the beginning. e.g, if the target is, 60:65, first the participant must at least get 60:61; once this is got, 60:63 etc.. the program adds a note each time (or if the participant adds an additional extra note, the program could skip an n-gram) "],["visual_vs_auditory_learning_pbe.html", "36 Reviewing and spaced repetition", " 36 Reviewing and spaced repetition "],["identify-correct-vs-incorrect-ngrams.html", "37 identify correct vs incorrect ngrams", " 37 identify correct vs incorrect ngrams append incorrect ngrams to top of buffer priorotise earlier ngrams "],["generative-similarity-generative-similarity.html", "38 Generative similarity {#generative similarity}", " 38 Generative similarity {#generative similarity} "],["identify-correct-vs-incorrect-ngrams-1.html", "39 identify correct vs incorrect ngrams", " 39 identify correct vs incorrect ngrams append incorrect ngrams to top of buffer priorotise earlier ngrams "],["production_perception.html", "40 Production perception paradigm", " 40 Production perception paradigm You ask participants to recall a melody, followed by a confidence rating about how well they did it. Then you allow the participant to listen back to their attempt and rate the similarity (like the paradigm I implemented for the Edoardo study). Hence, you get three data points (or more if you have multiple attempts) for each trial/stimulus: i) a production score, ii) an evaluation from memory/confidence score, iii) a perceptual score. The similarity score can also have a condition to it where we either present the participant’s produced recall back as audio or the MIDI transcription produced on-the-fly. Could be a very informative. And just to add, this is closely related to real music learning processes whereby you can imagine musicians undergoing some process like this in the practice room: recall, reflect, revise.. That’s a great idea! Maybe we should call this the production-reflection-perception paradigm. This could work with melodies but also individual tones (long notes) or rhythms, or even sections of rehearsed pieces. It might be useful as an individual differences test (also testing reflective and perceptual self-assessment abilities) and it could be useful as a general learning paradigm. Maybe this is something for the Diaes4all project to try out? Alternatively / additionally, we could suggest this as an MMB student project for the next year. Thanks for sharing and all the best, Daniel Baker, David. 2019. “Modeling Melodic Dictation.” LSU Doctoral Dissertations, June. https://doi.org/10.31390/gradschool_dissertations.4960. Berliner, Paul F. 1994. Thinking in Jazz: The Infinite Art of Improvisation. Chicago: University of Chicago Press. Harrison, P. M. C. 2025. Music and Science. Self-published online. Herzig, Monika. 2019. “The Abcs of Jazz Education. Rethinking Jazz Pedagogy.” In Jazzforschung Heute. https://jazzforschung.hfm-weimar.de/wp-content/uploads/2019/06/JazzforschungHeute2019_Herzig-ABC-Jazz-Education.pdf. Koger, Terry S., Mark Martin, Gary Richardson, Hassan Sabree, Anthony Wade, and Dominique-René de Lerma. 1985. “Fifty Years of \"Down Beat\" Solo Jazz Transcriptions: A Register.” Black Music Research Journal 5: 43–79. https://doi.org/10.2307/779496. Liscio, Christopher, and Daniel G. Brown. 2024. “Watching Popular Musicians Learn by Ear: A Hypothesis-Generating Study of Human-Recording Interactions in YouTube Videos.” arXiv. https://doi.org/10.48550/arXiv.2406.04058. Pfordresher, Peter Q., Steven M. Demorest, Simone Dalla Bella, Sean Hutchins, Psyche Loui, Joanne Rutkowski, and Graham F. Welch. 2015. “Theoretical Perspectives on Singing Accuracy: An Introduction to the Special Issue on Singing Accuracy (Part 1).” Music Perception 32 (3): 227–31. https://doi.org/10.1525/mp.2015.32.3.227. R Core Team. 2020. R: A Language and Environment for Statistical Computing. Vienna, Austria: R Foundation for Statistical Computing. Re, Adrien Marcus. 2004. “The Role of Transcription in Jazz Improvisation: Examining the Aural-Imitative Approach in Jazz Pedagogy.” D.{{A}}. {{Dissertation}}, Ball State University. Silas, Sebastian, and Daniel Müllensiefen. 2023. “Learning and Recalling Melodies: A Computational Investigation Using the Melodic Recall Paradigm.” Music Perception. https://doi.org/10.1525/mp.2023.41.2.77. Silas, Sebastian, Daniel Müllensiefen, Rebecca Gelding, Klaus Frieler, and Peter M. C. Harrison. 2022. “The Associations Between Music Training, Musical Working Memory, and Visuospatial Working Memory: An Opportunity for Causal Modeling.” Music Perception 39 (4): 401–20. https://doi.org/10.1525/mp.2022.39.4.401. Silas, Sebastian, Daniel Müllensiefen, and Reinhard Kopiez. 2023. “Singing Ability Assessment: Development and Validation of a Singing Test Based on Item Response Theory and a General Open-Source Software Environment for Singing Data.” Behavior Research Methods. https://doi.org/10.3758/s13428-023-02188-0. Surber, Greg A. 2009. “Record Progressions: Technology and Its Role in the Development and Dissemination of Jazz.” PhD thesis, Ohio University. Wilf, Eitan Y. 2012. “Rituals of Creativity: Tradition, Modernity, and the ‘Acoustic Unconscious’ in a U.S. Collegiate Jazz Music Program.” American Anthropologist 114 (1): 32–44. https://doi.org/10.1111/j.1548-1433.2011.01396.x. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
