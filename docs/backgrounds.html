<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Backgrounds | Playing By Ear: A Computational Approach</title>
  <meta name="description" content="3 Backgrounds | Playing By Ear: A Computational Approach" />
  <meta name="generator" content="bookdown 0.43 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Backgrounds | Playing By Ear: A Computational Approach" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Backgrounds | Playing By Ear: A Computational Approach" />
  
  
  

<meta name="author" content="Seb Silas" />


<meta name="date" content="2025-06-08" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction.html"/>
<link rel="next" href="a-comprehensive-theorectical-model-of-playing-by-ear.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Front Matter</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#foreword"><i class="fa fa-check"></i><b>1.1</b> Foreword</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.2</b> Acknowledgements</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#toc"><i class="fa fa-check"></i><b>1.3</b> Table of Contents</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#what-is-playing-by-ear"><i class="fa fa-check"></i><b>2.1</b> What Is Playing By Ear?</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#learning-to-play-by-ear"><i class="fa fa-check"></i><b>2.2</b> Learning to Play By Ear</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#the-problem-domain-and-approach"><i class="fa fa-check"></i><b>2.3</b> The Problem Domain and Approach</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#motivations"><i class="fa fa-check"></i><b>2.4</b> Motivations</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#generalising-beyond-jazz-and-playing-by-ear"><i class="fa fa-check"></i><b>2.4.1</b> Generalising Beyond Jazz and Playing By Ear</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#thesis-statement"><i class="fa fa-check"></i><b>2.5</b> Thesis Statement</a></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#original-contributions"><i class="fa fa-check"></i><b>2.6</b> Original Contributions</a></li>
<li class="chapter" data-level="2.7" data-path="introduction.html"><a href="introduction.html#research-questions"><i class="fa fa-check"></i><b>2.7</b> Research Questions</a></li>
<li class="chapter" data-level="2.8" data-path="introduction.html"><a href="introduction.html#objectives-and-scope"><i class="fa fa-check"></i><b>2.8</b> Objectives and Scope</a>
<ul>
<li class="chapter" data-level="2.8.1" data-path="introduction.html"><a href="introduction.html#scope"><i class="fa fa-check"></i><b>2.8.1</b> Scope</a></li>
</ul></li>
<li class="chapter" data-level="2.9" data-path="introduction.html"><a href="introduction.html#front-facing-tools"><i class="fa fa-check"></i><b>2.9</b> Front-Facing Tools</a>
<ul>
<li class="chapter" data-level="2.9.1" data-path="introduction.html"><a href="introduction.html#slonimsky.app"><i class="fa fa-check"></i><b>2.9.1</b> Slonimsky.app</a></li>
<li class="chapter" data-level="2.9.2" data-path="introduction.html"><a href="introduction.html#songbird"><i class="fa fa-check"></i><b>2.9.2</b> Songbird</a></li>
</ul></li>
<li class="chapter" data-level="2.10" data-path="introduction.html"><a href="introduction.html#dissertation-outline"><i class="fa fa-check"></i><b>2.10</b> Dissertation Outline</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="backgrounds.html"><a href="backgrounds.html"><i class="fa fa-check"></i><b>3</b> Backgrounds</a>
<ul>
<li class="chapter" data-level="3.1" data-path="backgrounds.html"><a href="backgrounds.html#historical_background"><i class="fa fa-check"></i><b>3.1</b> Historical Background: Approaches to Improving Playing by Ear in Jazz Music</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="backgrounds.html"><a href="backgrounds.html#the-aural-origins-of-jazz-education"><i class="fa fa-check"></i><b>3.1.1</b> The Aural Origins of Jazz Education</a></li>
<li class="chapter" data-level="3.1.2" data-path="backgrounds.html"><a href="backgrounds.html#record-players-as-pedagogical-tools"><i class="fa fa-check"></i><b>3.1.2</b> Record Players as Pedagogical Tools</a></li>
<li class="chapter" data-level="3.1.3" data-path="backgrounds.html"><a href="backgrounds.html#codification-of-jazz-education"><i class="fa fa-check"></i><b>3.1.3</b> Codification of Jazz Education</a></li>
<li class="chapter" data-level="3.1.4" data-path="backgrounds.html"><a href="backgrounds.html#the-chord-scale-approach-pattern-books-and-melodic-vocabulary-acquisition"><i class="fa fa-check"></i><b>3.1.4</b> The Chord-Scale Approach, Pattern Books, and Melodic Vocabulary Acquisition</a></li>
<li class="chapter" data-level="3.1.5" data-path="backgrounds.html"><a href="backgrounds.html#john-coltrane-and-slonimskys-thesaurus-aspirational-melodic-vocabulary-acquisition"><i class="fa fa-check"></i><b>3.1.5</b> John Coltrane and Slonimsky’s Thesaurus: Aspirational Melodic Vocabulary Acquisition</a></li>
<li class="chapter" data-level="3.1.6" data-path="backgrounds.html"><a href="backgrounds.html#historical-background-conclusion"><i class="fa fa-check"></i><b>3.1.6</b> Historical Background: Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="backgrounds.html"><a href="backgrounds.html#modern_technological_approaches"><i class="fa fa-check"></i><b>3.2</b> Modern Technological Approaches to Ear Training</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="backgrounds.html"><a href="backgrounds.html#historical-development-of-ear-training-technology"><i class="fa fa-check"></i><b>3.2.1</b> Historical Development of Ear-Training Technology</a></li>
<li class="chapter" data-level="3.2.2" data-path="backgrounds.html"><a href="backgrounds.html#non-commercial-and-research-initiatives"><i class="fa fa-check"></i><b>3.2.2</b> Non-Commercial and Research Initiatives</a></li>
<li class="chapter" data-level="3.2.3" data-path="backgrounds.html"><a href="backgrounds.html#pedagogical-strategies-and-practical-use"><i class="fa fa-check"></i><b>3.2.3</b> Pedagogical Strategies and Practical Use</a></li>
<li class="chapter" data-level="3.2.4" data-path="backgrounds.html"><a href="backgrounds.html#benefits-and-limitations"><i class="fa fa-check"></i><b>3.2.4</b> Benefits and Limitations</a></li>
<li class="chapter" data-level="3.2.5" data-path="backgrounds.html"><a href="backgrounds.html#modern-technological-approaches-to-ear-training-conclusion"><i class="fa fa-check"></i><b>3.2.5</b> Modern Technological Approaches to Ear Training: Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="backgrounds.html"><a href="backgrounds.html#playing_by_ear_literature_review"><i class="fa fa-check"></i><b>3.3</b> Playing by Ear Research: A Literature Review</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="backgrounds.html"><a href="backgrounds.html#historical-overview"><i class="fa fa-check"></i><b>3.3.1</b> Historical Overview</a></li>
<li class="chapter" data-level="3.3.2" data-path="backgrounds.html"><a href="backgrounds.html#developmental-and-pedagogical-aspects-of-playing-by-ear-skill-acquisition"><i class="fa fa-check"></i><b>3.3.2</b> Developmental and Pedagogical Aspects of Playing By Ear Skill Acquisition</a></li>
<li class="chapter" data-level="3.3.3" data-path="backgrounds.html"><a href="backgrounds.html#mcphersons-integrated-model-of-musical-skill-development"><i class="fa fa-check"></i><b>3.3.3</b> McPherson’s Integrated Model of Musical Skill Development</a></li>
<li class="chapter" data-level="3.3.4" data-path="backgrounds.html"><a href="backgrounds.html#cognitive-mechanisms-underlying-playing-by-ear"><i class="fa fa-check"></i><b>3.3.4</b> Cognitive Mechanisms Underlying Playing by Ear</a></li>
<li class="chapter" data-level="3.3.5" data-path="backgrounds.html"><a href="backgrounds.html#auditory-perception"><i class="fa fa-check"></i><b>3.3.5</b> Auditory Perception</a></li>
<li class="chapter" data-level="3.3.6" data-path="backgrounds.html"><a href="backgrounds.html#working-memory"><i class="fa fa-check"></i><b>3.3.6</b> Working Memory</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="backgrounds.html"><a href="backgrounds.html#interim-summary-1"><i class="fa fa-check"></i><b>3.4</b> Interim Summary</a></li>
<li class="chapter" data-level="3.5" data-path="backgrounds.html"><a href="backgrounds.html#pfordreshers-cognitive-model-of-singing-accuracy-and-h-pac-models"><i class="fa fa-check"></i><b>3.5</b> Pfordresher’s Cognitive Model of Singing Accuracy and H-PAC Models</a></li>
<li class="chapter" data-level="3.6" data-path="backgrounds.html"><a href="backgrounds.html#bakers-computational-model-of-melodic-dictation"><i class="fa fa-check"></i><b>3.6</b> Baker’s Computational Model of Melodic Dictation</a></li>
<li class="chapter" data-level="3.7" data-path="backgrounds.html"><a href="backgrounds.html#models-of-sung-recall"><i class="fa fa-check"></i><b>3.7</b> Models of Sung Recall</a>
<ul>
<li class="chapter" data-level="3.7.1" data-path="backgrounds.html"><a href="backgrounds.html#playing-by-ear-research-conclusion"><i class="fa fa-check"></i><b>3.7.1</b> Playing by Ear Research: Conclusion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html"><i class="fa fa-check"></i><b>4</b> A Comprehensive Theorectical Model of Playing By Ear</a>
<ul>
<li class="chapter" data-level="4.1" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html#musicological_background"><i class="fa fa-check"></i><b>4.1</b> Computational Musicological Perspectives</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html#music-and-combinatorics"><i class="fa fa-check"></i><b>4.1.1</b> Music and Combinatorics</a></li>
<li class="chapter" data-level="4.1.2" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html#music-corpora-analysis"><i class="fa fa-check"></i><b>4.1.2</b> Music Corpora Analysis</a></li>
<li class="chapter" data-level="4.1.3" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html#melodic-represention-and-computational-melodic-features"><i class="fa fa-check"></i><b>4.1.3</b> Melodic Represention and Computational Melodic Features</a></li>
<li class="chapter" data-level="4.1.4" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html#computed-melodic-features-as-a-musicological-basis-for-selecting-items"><i class="fa fa-check"></i><b>4.1.4</b> Computed Melodic Features as a Musicological Basis for Selecting Items</a></li>
<li class="chapter" data-level="4.1.5" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html#pattern-books-as-item-banks"><i class="fa fa-check"></i><b>4.1.5</b> Pattern Books as Item Banks</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html#melodic-similarity"><i class="fa fa-check"></i><b>4.2</b> Melodic Similarity</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html#methodological-background"><i class="fa fa-check"></i><b>4.2.1</b> Methodological Background</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html#cognitive_psychological_background"><i class="fa fa-check"></i><b>4.3</b> Cognitive Psychology</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html#conclusion-cognitive-psychological-background"><i class="fa fa-check"></i><b>4.3.1</b> Conclusion: Cognitive Psychological Background</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html#statistical_modelling_frameworks"><i class="fa fa-check"></i><b>4.4</b> Statistical Modelling Frameworks</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="a-comprehensive-theorectical-model-of-playing-by-ear.html"><a href="a-comprehensive-theorectical-model-of-playing-by-ear.html#cognitive-modelling-item-feature-modelling-via-item-response-theory"><i class="fa fa-check"></i><b>4.4.1</b> Cognitive Modelling Item Feature Modelling via Item Response Theory</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="theoretical-model.html"><a href="theoretical-model.html"><i class="fa fa-check"></i><b>5</b> Playing By Ear: A Theoretical Model</a>
<ul>
<li class="chapter" data-level="5.1" data-path="theoretical-model.html"><a href="theoretical-model.html#bringing-it-together"><i class="fa fa-check"></i><b>5.1</b> Bringing It Together</a></li>
<li class="chapter" data-level="5.2" data-path="theoretical-model.html"><a href="theoretical-model.html#moving-from-theoretical-to-computational"><i class="fa fa-check"></i><b>5.2</b> Moving from Theoretical to Computational</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="theoretical-model.html"><a href="theoretical-model.html#inputs"><i class="fa fa-check"></i><b>5.2.1</b> Inputs</a></li>
<li class="chapter" data-level="5.2.2" data-path="theoretical-model.html"><a href="theoretical-model.html#sequential-construction"><i class="fa fa-check"></i><b>5.2.2</b> Sequential Construction</a></li>
<li class="chapter" data-level="5.2.3" data-path="theoretical-model.html"><a href="theoretical-model.html#function-application"><i class="fa fa-check"></i><b>5.2.3</b> Function Application</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="theoretical-model.html"><a href="theoretical-model.html#mathematical-representation"><i class="fa fa-check"></i><b>5.3</b> Mathematical Representation</a></li>
<li class="chapter" data-level="5.4" data-path="theoretical-model.html"><a href="theoretical-model.html#algorithm-flow"><i class="fa fa-check"></i><b>5.4</b> Algorithm Flow</a></li>
<li class="chapter" data-level="5.5" data-path="theoretical-model.html"><a href="theoretical-model.html#final-equation"><i class="fa fa-check"></i><b>5.5</b> Final Equation</a></li>
<li class="chapter" data-level="5.6" data-path="theoretical-model.html"><a href="theoretical-model.html#strategies"><i class="fa fa-check"></i><b>5.6</b> Strategies</a></li>
<li class="chapter" data-level="5.7" data-path="theoretical-model.html"><a href="theoretical-model.html#the-melodic-mind-as-item-bank"><i class="fa fa-check"></i><b>5.7</b> The Melodic Mind as Item Bank</a></li>
<li class="chapter" data-level="5.8" data-path="theoretical-model.html"><a href="theoretical-model.html#predictions"><i class="fa fa-check"></i><b>5.8</b> Predictions</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html"><i class="fa fa-check"></i><b>6</b> A Computational Ecosystem</a>
<ul>
<li class="chapter" data-level="6.1" data-path="computational-ecosystem.html"><a href="computational-ecosystem.html#transcription-of-melodic-production-data-pyin"><i class="fa fa-check"></i><b>6.1</b> Transcription of Melodic Production Data: pyin</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="pyin-r-package.html"><a href="pyin-r-package.html"><i class="fa fa-check"></i><b>7</b> pYIN R package</a>
<ul>
<li class="chapter" data-level="7.1" data-path="pyin-r-package.html"><a href="pyin-r-package.html#installation"><i class="fa fa-check"></i><b>7.1</b> Installation</a></li>
<li class="chapter" data-level="7.2" data-path="pyin-r-package.html"><a href="pyin-r-package.html#usage"><i class="fa fa-check"></i><b>7.2</b> Usage</a></li>
<li class="chapter" data-level="7.3" data-path="pyin-r-package.html"><a href="pyin-r-package.html#notes"><i class="fa fa-check"></i><b>7.3</b> Notes</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="pyin-r-package.html"><a href="pyin-r-package.html#compatability"><i class="fa fa-check"></i><b>7.3.1</b> Compatability</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="pyin-r-package.html"><a href="pyin-r-package.html#references"><i class="fa fa-check"></i><b>7.4</b> References</a></li>
<li class="chapter" data-level="7.5" data-path="pyin-r-package.html"><a href="pyin-r-package.html#assessment-of-melodic-similarity-melsim"><i class="fa fa-check"></i><b>7.5</b> Assessment of Melodic Similarity: melsim</a></li>
<li class="chapter" data-level="7.6" data-path="pyin-r-package.html"><a href="pyin-r-package.html#psychologically-meaningful-musical-item-banks-itembankr"><i class="fa fa-check"></i><b>7.6</b> Psychologically Meaningful Musical Item Banks: itembankr</a></li>
<li class="chapter" data-level="7.7" data-path="pyin-r-package.html"><a href="pyin-r-package.html#references-1"><i class="fa fa-check"></i><b>7.7</b> References</a></li>
<li class="chapter" data-level="7.8" data-path="pyin-r-package.html"><a href="pyin-r-package.html#musicassessrdb"><i class="fa fa-check"></i><b>7.8</b> musicassessrdb</a></li>
<li class="chapter" data-level="7.9" data-path="pyin-r-package.html"><a href="pyin-r-package.html#datasets-created-with-itembankr"><i class="fa fa-check"></i><b>7.9</b> Datasets (created with itembankr)</a>
<ul>
<li class="chapter" data-level="7.9.1" data-path="pyin-r-package.html"><a href="pyin-r-package.html#wjd"><i class="fa fa-check"></i><b>7.9.1</b> WJD</a></li>
</ul></li>
<li class="chapter" data-level="7.10" data-path="pyin-r-package.html"><a href="pyin-r-package.html#references-2"><i class="fa fa-check"></i><b>7.10</b> References</a>
<ul>
<li class="chapter" data-level="7.10.1" data-path="pyin-r-package.html"><a href="pyin-r-package.html#berkowitz"><i class="fa fa-check"></i><b>7.10.1</b> Berkowitz</a></li>
</ul></li>
<li class="chapter" data-level="7.11" data-path="pyin-r-package.html"><a href="pyin-r-package.html#references-3"><i class="fa fa-check"></i><b>7.11</b> References</a>
<ul>
<li class="chapter" data-level="7.11.1" data-path="pyin-r-package.html"><a href="pyin-r-package.html#slonimsky"><i class="fa fa-check"></i><b>7.11.1</b> Slonimsky</a></li>
</ul></li>
<li class="chapter" data-level="7.12" data-path="pyin-r-package.html"><a href="pyin-r-package.html#other-useful-functions"><i class="fa fa-check"></i><b>7.12</b> Other useful functions</a>
<ul>
<li class="chapter" data-level="7.12.1" data-path="pyin-r-package.html"><a href="pyin-r-package.html#assessing-musical-behaviours-musicassessr"><i class="fa fa-check"></i><b>7.12.1</b> Assessing musical behaviours: musicassessr</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="musicassessr.html"><a href="musicassessr.html"><i class="fa fa-check"></i><b>8</b> musicassessr</a>
<ul>
<li class="chapter" data-level="8.1" data-path="musicassessr.html"><a href="musicassessr.html#the-musicassessr-ecosystem"><i class="fa fa-check"></i><b>8.1</b> The musicassessr ecosystem</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="musicassessr.html"><a href="musicassessr.html#musical-ability-tests"><i class="fa fa-check"></i><b>8.1.1</b> Musical ability tests</a></li>
<li class="chapter" data-level="8.1.2" data-path="musicassessr.html"><a href="musicassessr.html#cheat-sheet"><i class="fa fa-check"></i><b>8.1.2</b> Cheat Sheet</a></li>
<li class="chapter" data-level="8.1.3" data-path="musicassessr.html"><a href="musicassessr.html#analysis-pipeline"><i class="fa fa-check"></i><b>8.1.3</b> Analysis pipeline</a></li>
<li class="chapter" data-level="8.1.4" data-path="musicassessr.html"><a href="musicassessr.html#research-and-documentation"><i class="fa fa-check"></i><b>8.1.4</b> Research and Documentation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="setup.html"><a href="setup.html"><i class="fa fa-check"></i><b>9</b> Setup</a>
<ul>
<li class="chapter" data-level="9.1" data-path="setup.html"><a href="setup.html#references-4"><i class="fa fa-check"></i><b>9.1</b> References</a></li>
<li class="chapter" data-level="9.2" data-path="setup.html"><a href="setup.html#ability-tests"><i class="fa fa-check"></i><b>9.2</b> Ability tests</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="setup.html"><a href="setup.html#play-by-ear-test-pbet"><i class="fa fa-check"></i><b>9.2.1</b> Play By Ear Test (PBET)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html"><i class="fa fa-check"></i><b>10</b> Play By Ear Test (PBET)</a>
<ul>
<li class="chapter" data-level="10.1" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#author"><i class="fa fa-check"></i><b>10.1</b> Author</a></li>
<li class="chapter" data-level="10.2" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#demos"><i class="fa fa-check"></i><b>10.2</b> Demos</a></li>
<li class="chapter" data-level="10.3" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#installation-1"><i class="fa fa-check"></i><b>10.3</b> Installation</a></li>
<li class="chapter" data-level="10.4" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#usage-1"><i class="fa fa-check"></i><b>10.4</b> Usage</a></li>
<li class="chapter" data-level="10.5" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#usage-notes"><i class="fa fa-check"></i><b>10.5</b> Usage notes</a></li>
<li class="chapter" data-level="10.6" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#citation"><i class="fa fa-check"></i><b>10.6</b> Citation</a></li>
<li class="chapter" data-level="10.7" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#references-5"><i class="fa fa-check"></i><b>10.7</b> References</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#singing-ability-assessment-saa"><i class="fa fa-check"></i><b>10.7.1</b> Singing Ability Assessment (SAA)</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#author-1"><i class="fa fa-check"></i><b>10.8</b> Author</a></li>
<li class="chapter" data-level="10.9" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#demos-1"><i class="fa fa-check"></i><b>10.9</b> Demos</a></li>
<li class="chapter" data-level="10.10" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#installation-2"><i class="fa fa-check"></i><b>10.10</b> Installation</a></li>
<li class="chapter" data-level="10.11" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#usage-2"><i class="fa fa-check"></i><b>10.11</b> Usage</a></li>
<li class="chapter" data-level="10.12" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#usage-notes-1"><i class="fa fa-check"></i><b>10.12</b> Usage notes</a></li>
<li class="chapter" data-level="10.13" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#citation-1"><i class="fa fa-check"></i><b>10.13</b> Citation</a></li>
<li class="chapter" data-level="10.14" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#references-6"><i class="fa fa-check"></i><b>10.14</b> References</a></li>
<li class="chapter" data-level="10.15" data-path="play-by-ear-test-pbet-1.html"><a href="play-by-ear-test-pbet-1.html#conclusion"><i class="fa fa-check"></i><b>10.15</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="melsim_development.html"><a href="melsim_development.html"><i class="fa fa-check"></i><b>11</b> Experiment 1: Development of a Melodic Similarity Algorithm for Short Recalled Melodies</a></li>
<li class="chapter" data-level="12" data-path="pbet_lab_study.html"><a href="pbet_lab_study.html"><i class="fa fa-check"></i><b>12</b> Experiment 2: An Explanatory Model Of Playing By Ear</a>
<ul>
<li class="chapter" data-level="12.1" data-path="pbet_lab_study.html"><a href="pbet_lab_study.html#methods"><i class="fa fa-check"></i><b>12.1</b> Methods</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="pbet_lab_study.html"><a href="pbet_lab_study.html#participants-and-preliminary-questionnaire"><i class="fa fa-check"></i><b>12.1.1</b> Participants and Preliminary Questionnaire</a></li>
<li class="chapter" data-level="12.1.2" data-path="pbet_lab_study.html"><a href="pbet_lab_study.html#apparatus-and-general-procedure"><i class="fa fa-check"></i><b>12.1.2</b> Apparatus and General Procedure</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="pbet_online_study.html"><a href="pbet_online_study.html"><i class="fa fa-check"></i><b>13</b> Experiment 3: Modelling Melodic Difficulty in Playing by Ear: An Item Response Analysis of Online Performance Data</a></li>
<li class="chapter" data-level="14" data-path="study_history_study.html"><a href="study_history_study.html"><i class="fa fa-check"></i><b>14</b> Experiment 4: A Longitudinal Study of Playing By Ear Skills</a></li>
<li class="chapter" data-level="15" data-path="similarity_study.html"><a href="similarity_study.html"><i class="fa fa-check"></i><b>15</b> Experiment 5: A Similarity-Based Approach to Item Selection</a>
<ul>
<li class="chapter" data-level="15.1" data-path="similarity_study.html"><a href="similarity_study.html#collaborative-filtering"><i class="fa fa-check"></i><b>15.1</b> Collaborative Filtering</a></li>
<li class="chapter" data-level="15.2" data-path="similarity_study.html"><a href="similarity_study.html#approaches-to-similarity-for-large-scale-corpora"><i class="fa fa-check"></i><b>15.2</b> Approaches to Similarity for Large-Scale Corpora</a></li>
<li class="chapter" data-level="15.3" data-path="similarity_study.html"><a href="similarity_study.html#melodic-corpora-as-networks"><i class="fa fa-check"></i><b>15.3</b> Melodic corpora as networks</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="similarity_study.html"><a href="similarity_study.html#approach-1-similarity-of-features-as-a-proxy-for-melodic-similarity"><i class="fa fa-check"></i><b>15.3.1</b> Approach #1: Similarity of Features as a Proxy for Melodic Similarity</a></li>
<li class="chapter" data-level="15.3.2" data-path="similarity_study.html"><a href="similarity_study.html#approach-2-generative-similarity"><i class="fa fa-check"></i><b>15.3.2</b> Approach #2: Generative Similarity</a></li>
<li class="chapter" data-level="15.3.3" data-path="similarity_study.html"><a href="similarity_study.html#approach-3-parent-melody-representation"><i class="fa fa-check"></i><b>15.3.3</b> Approach #3: Parent Melody Representation</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="additional-learning-paradigms.html"><a href="additional-learning-paradigms.html"><i class="fa fa-check"></i><b>16</b> Additional Learning Paradigms</a>
<ul>
<li class="chapter" data-level="16.1" data-path="additional-learning-paradigms.html"><a href="additional-learning-paradigms.html#generative-similarity"><i class="fa fa-check"></i><b>16.1</b> Generative Similarity</a></li>
<li class="chapter" data-level="16.2" data-path="additional-learning-paradigms.html"><a href="additional-learning-paradigms.html#learn-chunks"><i class="fa fa-check"></i><b>16.2</b> Learn Chunks</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="experiment-6-model-synthesis-development-of-a-musical-dashsim-model.html"><a href="experiment-6-model-synthesis-development-of-a-musical-dashsim-model.html"><i class="fa fa-check"></i><b>17</b> Experiment 6: Model synthesis: Development of a musical DASH+SIM model</a></li>
<li class="chapter" data-level="18" data-path="interventional_Study.html"><a href="interventional_Study.html"><i class="fa fa-check"></i><b>18</b> Experiment 7: An Interventional Study</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Playing By Ear: A Computational Approach</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="backgrounds" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">3</span> Backgrounds<a href="backgrounds.html#backgrounds" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>TODO: Webster and Greg Surber dissertations should appear here!</p>
<div id="historical_background" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Historical Background: Approaches to Improving Playing by Ear in Jazz Music<a href="backgrounds.html#historical_background" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Jazz music began as an oral tradition where skills were developed through listening and imitation rather than formal instruction. The development of aural skills to support improvisation (i.e., playing by ear”) — has been a central feature of learning jazz music throughout the 20th and 21st centuries. In this section, I describe the historical evolution of approaches to developing aural skills in jazz music. I survey how record players, transcription books, and pattern books have supported the ear training process in jazz music and the evolving interplay between informal, aural traditions and formalised, institutional methods. This suggests a gradual shift from purely aural learning to increasingly systematised approaches, reflecting broader trends in the institutionalisation of jazz education. Despite this evolution, the fundamental importance of developing acute listening skills remains central to effective jazz pedagogy and discourse.</p>
<div id="the-aural-origins-of-jazz-education" class="section level3 hasAnchor" number="3.1.1">
<h3><span class="header-section-number">3.1.1</span> The Aural Origins of Jazz Education<a href="backgrounds.html#the-aural-origins-of-jazz-education" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The early history of jazz was characterised by learning that occurred primarily through aural means involving “hours of listening, transcribing, and participating in jam sessions” <span class="citation">(Herzig 2019)</span> before formal educational approaches emerged. In this pre-institutional era, the transmission of jazz knowledge occurred organically within communities of practice, with experienced musicians serving as mentors to aspiring players. This master-apprentice relationship formed the foundation of early jazz pedagogy, where direct demonstration and immediate repetition were the primary teaching methods. The absence of formal jazz education in the early period necessitated the aural approach, as musicians needed to develop their skills through direct engagement with the music itself. While some things were written down, such as Downbeat magasine transcriptions in the 1940’s <span class="citation">(Koger et al. 1985)</span>, the vast majority of what people learned and played was done solely “by ear”. This established a precedent that would continue to influence jazz pedagogy, even as more formalised approaches developed. The emphasis on learning by ear ensured that early jazz musicians developed strong aural skills as a natural consequence of their training process.</p>
</div>
<div id="record-players-as-pedagogical-tools" class="section level3 hasAnchor" number="3.1.2">
<h3><span class="header-section-number">3.1.2</span> Record Players as Pedagogical Tools<a href="backgrounds.html#record-players-as-pedagogical-tools" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The development of recording technology dramatically transformed jazz education by making the music of master performers accessible to aspiring musicians regardless of geographic location. Recordings became essential educational resources, allowing students to study the repertoire and improvisations of established artists <span class="citation">(Butterfield 2002; Re 2004)</span>. This technological advancement democratised access to jazz education, extending learning opportunities beyond those who could physically attend performances or study with established musicians. Technologies such as variable-speed turntables and digital audio software enabled closer analysis, allowing students to slow down recordings for detailed ear training <span class="citation">(Re 2004)</span>. Listening became active engagement, with learners looping short segments, replicating phrases, and attempting to match phrasing and articulation. The ability to repeatedly listen to recorded performances proved particularly valuable, especially since records could be “endlessly repeated” <span class="citation">(Surber 2009)</span>. This repetition allowed students to internalise not only melodies and chord progressions but also nuances of style, tone, and expression that are difficult to communicate through written notation. The practice of slowing down recordings or lifting the needle to replay difficult passages became standard pedagogical techniques that allowed for deep analysis of complex musical passages. <span class="citation">Berliner (1994)</span> emphasises that imitation from recordings helped players build a mental library of harmonic and melodic ideas, forming a foundation for improvisation.</p>
<p>The phonograph (and later recording techologies e.g., CDs, MP3s etc.) thus become an indispensable tool for jazz learners. Listening to records enabled musicians to internalise jazz language and style. Even as jazz moved into universities, listening retained primacy. As <span class="citation">Wilf (2012)</span> describes, jazz education features “rituals” that centre around repeated listening to and playing along with canonical recordings. These practices continue to uphold the oral traditions at the heart of jazz pedagogy.</p>
</div>
<div id="codification-of-jazz-education" class="section level3 hasAnchor" number="3.1.3">
<h3><span class="header-section-number">3.1.3</span> Codification of Jazz Education<a href="backgrounds.html#codification-of-jazz-education" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The transition from purely aural learning to more systematised approaches began in the mid-20th century. <span class="citation">Herzig (2019)</span> identifies the 1930s as a pivotal period, with early attempts to codify jazz instruction including <span class="citation">Beihoff (1934)</span>’s “Modern Arranging and Orchestration” and Lee Bowden’s training program for Afro-American Service Musicians at the Great Lakes Naval Base (1942-45). These initial efforts to systematise jazz education represented the beginning of a shift toward more formalised and codified instructional approaches, though they remained relatively limited in scope. However, the rise of printed transcription books - like the <em>Charlie Parker Omnibook</em> in the 1970’s <span class="citation">(Parker 2009)</span> - introduced shifts in practice. While these books provided accessible models for study, <span class="citation">Witmer and Robbins (1988)</span> argued that many early transcription collections failed to support active listening, with students relying more on notation rather than using their ears. Generally, transcription is thought most effective when used in tandem with active listening: students should first attempt to transcribe by ear and then use notated versions for verification or analysis <span class="citation">(Berliner 1994; Re 2004)</span></p>
</div>
<div id="the-chord-scale-approach-pattern-books-and-melodic-vocabulary-acquisition" class="section level3 hasAnchor" number="3.1.4">
<h3><span class="header-section-number">3.1.4</span> The Chord-Scale Approach, Pattern Books, and Melodic Vocabulary Acquisition<a href="backgrounds.html#the-chord-scale-approach-pattern-books-and-melodic-vocabulary-acquisition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A watershed moment in jazz education came in the late 1960s, with what <span class="citation">Herzig (2019)</span> terms “the ABCs of jazz” - referring to the influential work of Jamey Aebersold, David Baker, and Jerry Coker. Their development of comprehensive instructional materials, including <span class="citation">Baker (1969)</span>’s “Jazz Improvisation: a Comprehensive Method for all Players” and Aebersold’s play-along recordings, established a framework for jazz education that continues to influence pedagogical approaches today. These materials helped standardise jazz instruction and made it more accessible to students without direct access to master performers, contributing to what <span class="citation">Prouty (2005)</span> describes pejoratively as the “wholesale growth” of jazz education during the 1960s and 70s.</p>
<p>The chord-scale approach pioneered by Baker, Aebersold, and Coker became a dominant paradigm in jazz education. These influential educators “focus on scales and modes to examine improvisation” <span class="citation">(Spice 2010)</span>. This approach provided students with systematic frameworks for navigating harmonic structures, offering concrete tools for developing improvisational facility. The emphasis on scales and patterns created a more accessible entry point for students transitioning from classical training to jazz improvisation.</p>
<p>Aebersold’s own description of his pedagogical evolution reveals the gradual systematisation of his approach: “I published my first jazz play-a-long in 1967 and the [accompanying] booklet included concert [key] chords for each track. Subsequent printings added transposed chord symbols [for Bb and Eb instruments] and, eventually, I added the needed transposed scales and chords for each track” <span class="citation">(Herzig 2019)</span>. This approach represented a compromise between purely aural learning and more visually-oriented instructional methods, coupling “the eye with the ear” in ways that provided students with multiple pathways for internalising jazz vocabulary. The development of pattern books and play-along recordings created standardised resources that facilitated the institutional teaching of jazz improvisation.</p>
<p>Pattern books, such as Coker’s <em>Patterns for Jazz</em> and Baker’s <em>Improvisational Patterns</em>, systematised jazz vocabulary through short, transposable licks and exercises. While <span class="citation">Witmer and Robbins (1988)</span> recognises their role in helping students internalise chord-scale relationships and idiomatic phrases, these tools also sparked criticism. <span class="citation">Benward and Wildman (1984)</span> caution that over-reliance on such methods can yield formulaic improvisation disconnected from the spontaneous, reactive nature of jazz. <span class="citation">Wilf (2012)</span> views pattern books as part of a broader institutional shift from an oral tradition to a codified curriculum. Proponents of such methods like <span class="citation">Coker (1964)</span> emphasised that such resources should be integrated with listening and improvisation, rather than standing in as a replacement. In this way, practising melodic patterns can be used as an ear-training aid by helping to reinforce melodic shapes and harmonic contexts, provided that students also engage with recordings and creative application. It is for this reason that many pattern books are also presented with isorhythmic melodies; as noted in the introduction to <span class="citation">Coker et al. (1999)</span>:</p>
<blockquote>
<p>Most of the patterns contained herein are presented in eighth notes (the rhythmic level of most jazz improvisation), in a continuing fashion, without rhythmic variation, and without rhythmic phrase-endings. This was an arbitrary approach, so as not to dictate what the rhythms should be. nor to restrict them to a single rhythmic approach. When the practiced patterns are applied to an improvisation. it is expected that the rhythms would be loosened, so that the idea takes on a more lyrical, natural, and less mechanical feeling.</p>
</blockquote>
</div>
<div id="john-coltrane-and-slonimskys-thesaurus-aspirational-melodic-vocabulary-acquisition" class="section level3 hasAnchor" number="3.1.5">
<h3><span class="header-section-number">3.1.5</span> John Coltrane and Slonimsky’s Thesaurus: Aspirational Melodic Vocabulary Acquisition<a href="backgrounds.html#john-coltrane-and-slonimskys-thesaurus-aspirational-melodic-vocabulary-acquisition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>John Coltrane’s approach to improvisation, characterised by systematic exploration of harmonic possibilities, had a profound impact on jazz pedagogy. Musicological research examining Coltrane’s melodic vocabulary suggests his methodological approach to developing improvisational frameworks, including his systematic exploration of harmonic structures through patterns and exercises <span class="citation">(e.g., Bertholf 2014; Martin 2012; O’Gallagher 2020)</span>. Coltrane’s disciplined practice methods and innovative harmonic concepts established new paradigms for jazz improvisation that would later be incorporated into educational approaches, showing how his influence extended beyond his specific musical innovations to encompass his overall approach to musical development.</p>
<p>Coltrane’s systematic exploration of musical possibilities demonstrated the value of structured practice and theoretical understanding alongside intuitive improvisation. Scholars have analysed Coltrane’s use of pitch-class sets and other patterns <span class="citation">(O’Gallagher 2020)</span>, noting the probable influence of Slonimsky’s <em>Thesaurus of Scales and Melodic Patterns</em> [referred to as Slonimsky’s <em>Thesaurus</em>, for short; <span class="citation">Slonimsky (1947)</span>] by the Russian-American composer Nicolas Slonimsky who was “obsessed with twelve-tone rows” <span class="citation">(Feisst 2011; Slonimsky 1988)</span>. The <em>Thesaurus</em> was a seminal book in music theory. As suggested by its title, the book is an exhaustive collection of melodies which Slonimsky laboriously generated manually and systematically. The purpose of such a volume was to provide a repository of melodies which breaks free of traditional tonal harmonic principles. In other words, it was an attempt to systematically open up possibilities in the Western music system which had not yet been explored (for later similar approaches see e.g., <span class="citation">Johnson (2014)</span>).</p>
<p>Slonimsky’s undertaking can be viewed as a way of codifying and unlocking the potential of melodic possibilities through systematisation. It highlights that by using algorithimic thinking, new possibilities can be unlocked. One basic principle behind Slonimsky’s systematisation was to divide one or more octaves of the twelve-tone system into symmetrical intervals and from there systematically interpolate different numbers of notes between the intervals created by the divisions. Additionally, he used other formulae to generate melodic patterns which had not yet been yielded by his basic scheme. Of <em>The Thesaurus</em>, the Second Viennese School composer Arnold Schoenberg wrote to Slonimsky, <em>“you might [have] in all probability organized every possible succession of tones”</em> and referred to his work as “an admirable feast of mental gymnastics” (from the blurb of the book). Whilst the former is almost certainly not true (unless constrained to a length, the number of possible melodies are infinite), the latter is undoubtedly. However, such a task would now be solved at ease by a script on a modern computer, partly motivating this research project.</p>
<p>The <em>Thesaurus</em> thus represents a significant intersection between theoretical systems and jazz improvisation. Although originally conceived as a classical resource, the text became influential among jazz musicians beyong Coltrane (including Frank Zappa, for instance; <span class="citation">Slonimsky (1988)</span>) seeking to expand their improvisational vocabulary by enabling a systematic approaches to exploring melodic possibilities within the twelve-tone chromatic scale.
The application of these patterns to jazz contexts demonstrates how theoretical systems can be adapted to serve improvisational purposes, expanding the vocabulary available to jazz improvisers while maintaining connections to the oral tradition. Coltrane exemplifies this duality of pushing the boundaries; whilst exploring new, avant-grade melodic language, he continued to play jazz standards live at concerts even late into his career. Similar “boundary pushing” melodic vocabularies in the jazz literature are Yuseff Lateef’s <em>Repository of Scales and Melodic Patterns</em> <span class="citation">(Lateef 2015)</span> and works by Masaya Yamaguchi such as <em>The Complete Thesaurus of Musical Scales</em> <span class="citation">(Yamaguchi 2006)</span> and <em>Lexicon of Geometric Patterns for Jazz Improvisation</em> <span class="citation">(Yamaguchi 2011)</span>.</p>
<p>Note that, Coltrane’s use of Slonimsky’s <em>Thesaurus</em> represents a desire to move from simply “learning the oral jazz tradition” to developing novel melodic ideas. This is an important distinction to be made and represent two kinds of approaches to acquiring melodic representations for improvisational jazz music. The first, is about “learning the tradition” - transcribing important historical elements of jazz language; specific jazz licks etc. Such language acquisition is more pedagogical, using “tried-and-tested” patterns which helps play within idiomatic jazz frameworks (e.g., particular chord changes/jazz standards). I term the latter approach about acquiring novel melodic vocabularies, “<em>aspirational melodic vocabularies</em>” representing that the intention behind their acquisition is about pushing creative boundaries and finding new and exciting melodic combinations. This melodic space is virtually infinite, but exciting to explore for improvisers looking to develop a personal melodic style. There are thus two potential use cases when thinking about the development of a training program. The first for developing idiomatic jazz language will be of interest to beginners and experts alike, but the second, aspirational melodic vocabulary acquisition will generally only be of interest to experts.</p>
</div>
<div id="historical-background-conclusion" class="section level3 hasAnchor" number="3.1.6">
<h3><span class="header-section-number">3.1.6</span> Historical Background: Conclusion<a href="backgrounds.html#historical-background-conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Record players, transcription books, and pattern books have each contributed to jazz ear training across the 20th and 21st centuries. Sociocultural/historical perspectives affirm that while written and technological resources are valuable, they should be embedded in a pedagogy that privileges listening, in accordance with the “jazz tradition”. The most enduring jazz learning strategies would suggest that tools are integrated into a broader aural framework, preserving the tradition of learning music by ear, even in the context of modern jazz education codification.</p>
<p>The historical development of approaches to improving playing by ear in jazz pedagogy reveals a gradual evolution from purely aural learning to increasingly systematised methods. As the revered saxophonist Liebman argues in his discussion of transcription practices, this process involves “a three part learning process: body, mind and spirit-in that order” <span class="citation">(<span>“The <span>Complete Transcription Process</span> <span></span> <span>David Liebman</span>”</span> 2006)</span>. Whether we disgard the mysticism or not, this represents a holistic view often shared in jazz musician circles which recognises that effective ear training integrates physical, intellectual, and intuitive aspects of musical development, reflecting the multifaceted nature of jazz improvisation itself.</p>
<p>The continued evolution of ear training approaches in jazz education reflects broader trends in the field, balancing respect for traditional aural learning with recognition of the benefits offered by more systematised methods and technological tools. This integration of approaches provides contemporary students with multiple pathways for developing the aural skills essential to effective jazz performance. As jazz education continues to evolve, maintaining this balance between aural tradition and systematised instruction remains a central challenge and opportunity for jazz pedagogy.</p>
<p>The adoption of melodic thesaruses, such as the exhaustive algorithmic work of Slonimsky’s illustrates how jazz education has drawn from diverse sources beyond the jazz tradition itself. This connection between Coltrane’s innovative improvisational approach and Slonimsky’s theoretical work illustrates the emerging synthesis between systematised approaches and creative expression in jazz education.</p>
</div>
</div>
<div id="modern_technological_approaches" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Modern Technological Approaches to Ear Training<a href="backgrounds.html#modern_technological_approaches" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<!-- https://chatgpt.com/c/683ad51a-434c-800d-afa4-1b11dac1635f -->
<p>Somewhat narratively separate from the specific jazz pedagogical issues discussed in the previous section, but which is nonetheless relevant to any learner in the 21st centry - including those enlisting in jazz studies - is a discussion of the development of computerised ear training technology, which be discussed below.</p>
<div id="historical-development-of-ear-training-technology" class="section level3 hasAnchor" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Historical Development of Ear-Training Technology<a href="backgrounds.html#historical-development-of-ear-training-technology" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In formal music education, “dictation” (listening to music and writing it down) has been a staple of ear training <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023; Baker 2019)</span>. The first computer-assisted ear training tools appeared in the late 1960s and by the 1970s many university music departments had begun using software for interval, melody, chord and rhythm training <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023; Peters 1992; Stevens 1991)</span>. These early systems predated mainstream personal computers and were often limited in interface and scope, but they signaled that technology could supplement one-on-one tutoring. During the 1980s–90s, as home computers became common, commercial ear-training packages emerged. For instance, desktop programs offered exercises in interval recognition or chord dictation with synthetic examples. Software like <em>EarMaster</em> (first released in the 1990s; <span class="citation"><span>“<span>EarMaster</span> - <span>The App</span> for <span>Ear Training</span>, <span>Sight-Singing</span>, and <span>Rhythm Training</span>”</span> (2025)</span>) began to compile thousands of drills in scales, chords and rhythms. Meanwhile, audio-editing tools introduced the ability to manipulate real recordings: by the 1990s and early 2000’s, software like <em>Transcribe</em><span class="citation">(<span>“Transcribe! - Software to Help Transcribe Recorded Music”</span> 2021)</span> and <em>Amazing Slow Downer</em> <span class="citation">(Roni Music 2025)</span>allowed users to slow down a recording or loop segments without altering pitch, greatly aiding transcription practice. In the 2000s, internet and mobile devices further expanded possibilities with web-based quizzes (e.g. at musictheory.net), smartphone apps (many interval- and chord-drill apps), and online communities for sharing transcriptions all appeared. A recent survey notes that ear-training apps and digital media are now recognized as important in music education, especially after the <em>COVID-19</em> pandemic accelerated remote learning <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023; Biasutti, Antonini Philippe, and Schiavio 2022)</span>.</p>
<p>More recently platforms, particularly YouTube, have become critical resources for jazz ear training. Thousands of free and paid video lessons offer guided transcription walkthroughs, call-and-response singing drills, harmonic analysis, and interval recognition in context. Creators like Adam Neely, Rick Beato, Aimee Nolte, and Jens Larsen provide high-quality instructional content often supplemented by downloadable PDFs containing annotated solos, theoretical explanations, and practice routines. These materials function as hybrid tools: students watch demonstrations, listen to examples repeatedly, and then practice using guided notation. While not interactive like apps, the structured nature of these lessons makes them accessible and effective for visual and auditory learners. Additionally, PDF packages often include backing tracks or isolated stems, making them compatible with tools like <em>Transcribe!</em> or <em>iReal Pro</em> for further ear training integration.</p>
<p>A notable recent example is <em>JazzLessonVideos.com</em>, co-founded by saxophonist Chad Lefkowitz-Brown (Chad LB) and educator Nathan Graybeal. Their platform offers a comprehensive suite of ear training resources tailored for jazz musicians. Their offerings include the Jazz Ear Training Video Course by Dr. Joe Gilman, comprising 23 videos with over 90 minutes of instruction. This course provides step-by-step guidance on identifying chord extensions, comparing chord types, and recognizing individual tones within chords, supplemented by interactive listening challenges. Additionally, their <em>Ear Training Method Book</em> focuses on essential skills such as interval and pitch identification, melodic dictation, chord identification, and chord progression recognition, complete with audio exercises and fill-in worksheets. These resources are designed to enhance aural skills through structured, self-paced learning, making them valuable tools for jazz students seeking to improve their improvisational abilities.</p>
<p>The platform’s approach emphasises the integration of video instruction with downloadable PDF materials, allowing students to engage with content visually, aurally, and kinesthetically. For instance, their “Melodic Cells” PDF package features 64 exercises focusing on non-diatonic, diatonic, and compound melodic cells, providing a structured method for developing improvisational vocabulary. Such resources are designed to be used in conjunction with backing tracks and other practice tools, facilitating a comprehensive ear training experience that bridges theoretical knowledge and practical application.
.
### Commercial Ear-Training and Transcription Tools</p>
<p>There are several main areas of computer assisted tools for helping improve playing by ear and related skills: transcription software, interval and melody training apps, chord/harmony recognition tools and rhythm training tools, which will be summarised below.</p>
<div id="transcription-software" class="section level4 hasAnchor" number="3.2.1.1">
<h4><span class="header-section-number">3.2.1.1</span> Transcription software<a href="backgrounds.html#transcription-software" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Jazz students often begin by transcribing solos and rhythms by ear. In contemporary times, specialised programs can help facilitate this process. <em>Transcribe!</em> <span class="citation">(<span>“Transcribe! - Software to Help Transcribe Recorded Music”</span> 2021)</span> and <em>Amazing Slow Downer</em> <span class="citation">(Roni Music 2025)</span> are two leading commercial tools that let a user loop passages, change tempo, and even shift pitch in real time. This lets learners gradually discern fast or complex lines at a slower pace without distortion. These tools also typically display a spectrogram or note analysis, which can guide accurate pitch identification. Other options include <em>Audacity</em> <span class="citation">(2025a)</span> (free audio editor with tempo/pitch controls) and <em>Sonic Visualiser</em> <span class="citation">(Centre for Digital Music 2025)</span> (research-oriented spectrogram display). Recently, AI-driven transcription has emerged: for example, plugins like <em>Melodyne</em> <span class="citation">(2025b)</span> can extract melody lines into MIDI, and open-source tools like Spotify’s <em>Basic Pitch</em> <span class="citation">(Spotify 2025)</span> (using machine learning) can convert a recording to notes. Such tools can automatically detect pitches and even chords in monophonic lines, though they struggle with dense jazz ensembles. Nonetheless, they offer an assistive first draft for transcribing complex solos or harmonic progressions. Interval and Melody Training Apps. Many apps and websites are designed as drill-and-practice tools for intervals and melodies. Well-known examples include <em>EarMaster</em> <span class="citation">(<span>“<span>EarMaster</span> - <span>The App</span> for <span>Ear Training</span>, <span>Sight-Singing</span>, and <span>Rhythm Training</span>”</span> 2025)</span>, <em>Tenuto</em> (by musictheory.net), <em>Perfect Ear</em> <span class="citation">(Crazy Ootka Software AB 2025)</span>, and <em>TonedEar</em> <span class="citation">(TonedEar 2025)</span>. These let a student train on identifying intervals, scales, and short melodies by ear. For instance, <em>EarMaster</em> <span class="citation">(<span>“<span>EarMaster</span> - <span>The App</span> for <span>Ear Training</span>, <span>Sight-Singing</span>, and <span>Rhythm Training</span>”</span> 2025)</span>offers thousands of exercises in intervals, chord types, cadences, and melodic dictation, while Tenuto’s exercises let one tap out or sing back intervals or scales on a keyboard interface. <em>Functional Ear Trainer</em> (iOS/Android) uses the concept of solfège by establishing a tonal center and having the student name scale-degrees or harmonic functions of incoming notes. Such apps typically provide immediate feedback and can adjust difficulty, which is a strength over traditional one-on-one drills (whose pace is fixed by the teacher). A Chinese study found that structured use of <em>EarMaster</em> significantly improved university students’ pitch, rhythm and timbre recognition compared to traditional instruction <span class="citation">(Lingjie 2025)</span>.</p>
</div>
<div id="chordharmonic-recognition-tools." class="section level4 hasAnchor" number="3.2.1.2">
<h4><span class="header-section-number">3.2.1.2</span> Chord/Harmonic Recognition Tools.<a href="backgrounds.html#chordharmonic-recognition-tools." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Identifying chords and progressions by ear is crucial in jazz. Some ear-training apps include chord identification modules: for example, <em>EarMaster</em> <span class="citation">(<span>“<span>EarMaster</span> - <span>The App</span> for <span>Ear Training</span>, <span>Sight-Singing</span>, and <span>Rhythm Training</span>”</span> 2025)</span> can play triads or seventh-chords of different qualities (major, minor, dominant, etc.) for recognition practice. <em>Tenuto</em> <span class="citation">(musictheory.net 2025)</span> and <em>Perfect Ear</em> <span class="citation">(Crazy Ootka Software AB 2025)</span> also have chord quizzes. Meanwhile, digital accompaniments like <em>iReal Pro</em> <span class="citation">(2025e)</span> indirectly train harmonic ear skills. <em>iReal Pro</em> is a jazz “fake book” app that plays back chord charts in realistic backing-band styles. Students use it to loop ii–V–I progressions, turnarounds, or full standards at varying tempos, and practice improvising over them. Although <em>iReal Pro</em> doesn’t explicitly quiz the ear, it immerses students in hearing chord changes in context. (Notably, <em>iReal Pro</em> is also used pedagogically by many teachers – e.g. forums note that educators share custom chord exercises on its forum irealpro.com.) Other software like <em>Band-in-a-Box</em> <span class="citation">(2025d)</span> or <em>Chordbot</em> <span class="citation">(AB 2025)</span> generates full-band or looped chord sequences. Chord-detection services (e.g. <em>Chordify</em> <span class="citation">(B. V. 2025)</span>) even attempt to automatically transcribe chords from recordings, though their accuracy can falter on jazz’s complex voicings. In summary, these tools help jazz students internalise harmonic progressions, but most pedagogical testing still relies on human evaluation or structured quizzes.</p>
</div>
<div id="rhythm-training-tools." class="section level4 hasAnchor" number="3.2.1.3">
<h4><span class="header-section-number">3.2.1.3</span> Rhythm Training Tools.<a href="backgrounds.html#rhythm-training-tools." class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Jazz rhythm (swing feel, syncopation) can be elusive. Apps such as <em>Rhythm Trainer</em>, <em>Rhythm Trainer Complete</em>, or online rhythm dictation games allow practice identifying and tapping back rhythmic patterns. <em>EarMaster</em> <span class="citation">(<span>“<span>EarMaster</span> - <span>The App</span> for <span>Ear Training</span>, <span>Sight-Singing</span>, and <span>Rhythm Training</span>”</span> 2025)</span> includes clap-back and error-detection rhythm exercises. Some drum-focused VR games (e.g. the <em>Drumhead</em> <span class="citation">(VR 2025)</span> VR app) present rhythms visually. These tools support the move toward an “aural skills” approach even for rhythm. However, authentic jazz swing feel and poly-rhythms are hard to simulate outside an ensemble. Educators often still use live or recorded jazz drum examples (e.g. using <em>GrooveScribe</em> <span class="citation">(TheDrumNinja and Firth 2025)</span> to slow or isolate drum grooves) and encourage students to mimic them by ear. Nonetheless, any metronome with accent settings or rhythm game adds value for fundamental training.</p>
</div>
</div>
<div id="non-commercial-and-research-initiatives" class="section level3 hasAnchor" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Non-Commercial and Research Initiatives<a href="backgrounds.html#non-commercial-and-research-initiatives" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Beyond commercial products, there are academic and open initiatives for ear training. Music education researchers have explored computer-based ear training since the 1970s, and some projects still surface: e.g. Sibelius Ear Training Exercises (built-in to notation software) or <em>ToneGym</em> <span class="citation">(ToneGym 2025)</span> (a freemium web app with interactive ear games) have some educational followings. A particularly novel project is Virtual Reality ear training. For example, <em>Berklee College of Music</em> has developed a free VR <em>Ear Trainer</em> game: players enter a virtual room and tap notes or rhythms to match aural prompts, using immersive spatial audio <span class="citation">(Smith-Muller 2024)</span>. In research, Bournemouth University created a VR interval-recognition system and found users enjoyed it <span class="citation">(Fletcher, Hulusic, and Amelidis 2019)</span>. These VR approaches align with modern pedagogical emphases on engagement and multisensory learning. Additionally, open-source AI tools like Spotify’s <em>Basic Pitch</em> (audio-to-MIDI conversion) <span class="citation">(Spotify 2025)</span> represent an emerging trend: while not classroom tools per se, they hint at future “smart” apps that can listen to a student’s improvisation and provide instant feedback on pitch and harmony. In terms of research on effectiveness, studies confirm that technology can boost ear-training. The Chinese <em>Earmaster</em> study <span class="citation">(Lingjie 2025)</span> is one example (not jazz-specific but broadly applicable), showing structured software practice outperformed traditional drills in improving aural skills. On the other hand, some surveys report that teachers are cautious: French music educators noted a wealth of apps exists but found few that fit their curricula and quality standards <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023)</span>. In practice, most instructors integrate tech pragmatically (e.g. assigning app exercises for homework, using iReal Pro in lab hours) rather than abandoning traditional exercises outright.</p>
</div>
<div id="pedagogical-strategies-and-practical-use" class="section level3 hasAnchor" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Pedagogical Strategies and Practical Use<a href="backgrounds.html#pedagogical-strategies-and-practical-use" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Modern tools offer flexible practice but must be aligned with pedagogical goals. For transcription work, a typical strategy is: (1) listen to a short phrase repeatedly; (2) use software to slow it (e.g. to 60–80% speed) without changing pitch; (3) loop and isolate segments; (4) gradually raise speed as confidence grows. Teachers might recommend <em>Transcribe!</em> <span class="citation">(<span>“Transcribe! - Software to Help Transcribe Recorded Music”</span> 2021)</span> or <em>Amazing Slow Downer</em> <span class="citation">(Roni Music 2025)</span> for this, noting they allow marking sections and adjusting playback easily. Students also often use generic audio editors or <em>DAWs</em> (<em>Logic</em>, <em>Ableton</em>, <em>Audacity</em>) to visually align waveforms or annotate phrases. For interval recognition, instructors may mix app drills with in-class ear tests: e.g. <em>EarMaster</em> sessions can reinforce what students practiced privately on <em>Tenuto</em> <span class="citation">(musictheory.net 2025)</span>. Some educators advocate functional ear training (using scale degrees) especially for jazz, since jazz harmony is often thought of functionally; apps like <em>Functional Ear Trainer</em> <span class="citation">(Benbassat 2025)</span> implement this method. Others prefer interval drills, training students to name or match intervals regardless of key, arguing it transfers to any style. In practice, many adopt a hybrid: using apps for technical skill-building, then embedding those skills in jazz context via transcription and improvisation. Chord and harmonic dictation can be taught by first drilling triad types (through apps or teacher-led quizzing) and gradually moving to seventh chords and modes. Here technology’s pros/cons are clear: an <em>EarMaster</em> chord drill gives clear examples of an isolated chord tone, but hearing chords in real music often involves piano voicings or comping instruments. Some software (e.g. <em>Band-in-a-Box</em>) can generate controlled chord voicings for drill, but a teacher must ensure the student generalizes to actual recordings. Tools like iReal Pro support this by letting students choose different “rhythmic feels” (swing, bossa, etc.) for a given progression, so they hear the chords in musical context. In classes, teachers might assign each student to program a progression into iReal Pro (e.g. a standard tune’s changes) and then transpose and improvise over it. This contrasts with traditional jazz pedagogy, where playing “head a tunes and backings” was often live or from fake books; iReal Pro effectively democratizes a live band rehearsal. Rhythm and groove training via apps must be complemented by ensemble playing. An app can tap or clap back polyrhythms or swing patterns to a click, but internalizing groove usually involves playing with others. Many jazz educators therefore use tech to drill fundamentals (time feel, comping rhythms) but still emphasize jam sessions or drummer-led practice for true syncopation skills. Some programs (e.g. Melodic Perception interactive software) teach reading swing notations, but often jazz theory recommends learning rhythms aurally (listen-and-repeat) above all. Overall, modern ear-training tools align with traditional jazz pedagogy in that they emphasize listening and imitation, but they diverge in method. Traditional methods rely on a teacher or bandleader, whereas apps provide automated feedback and endless repetition. For example, while Lennie Tristano insisted on singing solos note-for-note (which students must check by ear or rely on the teacher’s judgment), an app like EarMaster could instantly verify if a student sang the correct interval. Similarly, instead of a teacher clapping a rhythm for a student to echo, a rhythm app can play random patterns for unsupervised practice. This autonomy can increase practice time and motivation, but some educators warn it may reduce human nuance: a student might become skilled at clicking “correct” on an app but still lack expressive feel.</p>
</div>
<div id="benefits-and-limitations" class="section level3 hasAnchor" number="3.2.4">
<h3><span class="header-section-number">3.2.4</span> Benefits and Limitations<a href="backgrounds.html#benefits-and-limitations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Modern tools allow personalised, flexible practice. Students can drill weak areas at their own pace, track progress quantitatively, and engage in gamified learning. Slowed/audio-transcription tools let learners tackle pieces beyond their current technical level. Mobile apps and cloud platforms enable anywhere-anytime practice, which is especially helpful for busy or distant learners. In higher education, platforms like <em>EarMaster Cloud</em> <span class="citation">(2025c)</span> or <em>MusicFirst</em> integrate with online curricula, giving instructors assignments and reports. Some researchers note that these tools can bridge gaps in large classes where one-on-one ear training is impractical <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023)</span>.</p>
<p>However, technology cannot fully replicate a skilled teacher or ensemble experience. Commercial apps often focus on Western tonal exercises (major/minor systems), which may not cover jazz’s extended/improvised tonalities (e.g. altered dominants or modal jazz). Additionally, software feedback is often binary (right/wrong) and ignores expression. Some students may “beat the drill” by test-taking tactics (memorizing patterns) without deeper musical understanding. Technical issues also arise: automated chord detectors misinterpret complex voicings; time-stretch algorithms can artefact; VR systems may cause fatigue and currently only train simple tasks (intervals, not swing feel) <span class="citation">(Fletcher, Hulusic, and Amelidis 2019)</span>. Teachers report that finding apps that mesh with a course’s philosophy is challenging <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023)</span>; for example, an app that only tests fixed notes may conflict with an improvisation-first curriculum. Cost is another factor: many apps require purchase (though often at modest prices), and institutional adoption sometimes faces budget constraints. Importantly, some purists worry that reliance on “cheat-like” tools can impede ear development e.g., that slow-down software may constitute “cheating” when transcribing, and hearing at full tempo is the real test. However, educators counter that these are training wheels: speed can be reintroduced gradually to build authentic skill. Pedagogically, best practice seems to be using technology as a supplement: begin with slow, guided work, but also include exercises at normal tempo and many “blind” listening tasks.</p>
</div>
<div id="modern-technological-approaches-to-ear-training-conclusion" class="section level3 hasAnchor" number="3.2.5">
<h3><span class="header-section-number">3.2.5</span> Modern Technological Approaches to Ear Training: Conclusion<a href="backgrounds.html#modern-technological-approaches-to-ear-training-conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Modern technology has substantially broadened the toolkit for jazz ear training. From historically modest computer-assisted programs to today’s interactive apps, VR experiences, and AI transcribers, musicians and educators have more resources than ever for developing listening skills. These tools generally align with traditional jazz pedagogy by reinforcing learning-by-ear, but they allow more self-guided, data-driven practice than the old master-apprentice model. Academic research (from empirical studies to qualitative surveys) suggests that, when used thoughtfully, technology can improve outcomes in pitch, rhythm, and harmonic recognition <span class="citation">(Munive Benites, Lalitte, and Eyharabide 2023; Lingjie 2025)</span>.</p>
<p>At the same time, they remind us of the irreplaceable value of human nuance – the swinging rhythm of a live drummer, the phrasing of a soloist, and the inspirational guidance of a mentor. The most effective ear-training approach in jazz likely combines the best of both worlds: students drill fundamentals and tricky passages with software, then validate and refine their skills in real musical contexts (singer circles, jam sessions, or ensemble rehearsals). As technology continues to evolve – with VR, AI, and improved music analysis – jazz education will doubtless adapt, aiming always to train both the intuitive “good ear” and the knowledgeable, expressive improviser.</p>
</div>
</div>
<div id="playing_by_ear_literature_review" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Playing by Ear Research: A Literature Review<a href="backgrounds.html#playing_by_ear_literature_review" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, I provide an overview of the literature on playing by ear and related skills. Research specifically on the topic of “playing by ear” mainly comes from the music education and music performance literatures. I will review this literature first. However, this literature does not have a strong cognitive psychological depth. To build on this literature, therefore, I will turn more to the cognitive psychology literature. Here, “playing by ear” has not been established as a clear topic, though there is much related research. I will therefore synthesise these literatures and contextualise playing by ear specifically with a deeper cognitive psychological basis: that is, I will review the internal mechanisms that might underlie performance. This will prepare the next chapter, where I will propose a theorectical cognitive (and computational) model of playing by ear skills.</p>
<div id="historical-overview" class="section level3 hasAnchor" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Historical Overview<a href="backgrounds.html#historical-overview" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="foundation-or-frill-woody2012" class="section level4 hasAnchor" number="3.3.1.1">
<h4><span class="header-section-number">3.3.1.1</span> Foundation or Frill? <span class="citation">(Woody 2012)</span><a href="backgrounds.html#foundation-or-frill-woody2012" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In music education research, in at least as early as the 1950’s did researchers such as <span class="citation">Mainwaring (1951)</span> begin advancing the importance of playing by ear skills in formal music education. By the late eighties, the music education literature began further lamenting that playing by ear skills were largely overlooked in music education, with the tyranny of visual notation being a main focus of teaching <span class="citation">(G. McPherson and Gabrielsson 2002; Priest 1989)</span>. A key emphasis and conclusion of this emerging literature in music education was that playing by ear skills were grossly overlooked, and actually turned out to be important contributors to musicianship as a whole: even sight reading skills <span class="citation">(G. E. McPherson 2005)</span>.</p>
</div>
<div id="from-sound-to-sight-rather-than-from-sight-to-sound" class="section level4 hasAnchor" number="3.3.1.2">
<h4><span class="header-section-number">3.3.1.2</span> From Sound to Sight rather than from Sight to Sound<a href="backgrounds.html#from-sound-to-sight-rather-than-from-sight-to-sound" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>As such, <span class="citation">G. McPherson and Gabrielsson (2002)</span> convey how musical meaning arises through a dynamic interplay between performer intention, listener interpretation, and cultural context, rather than being fixed in notation. They argued that music should be taught from sound to sign—that is, beginning with auditory and expressive engagement before introducing formal notation. This approach, they contend, better reflects how meaning is constructed in music and supports deeper, more intuitive learning. Their contribution is significant within music education and cognition, challenging notation-first traditions and advocating for a more experiential, communication-oriented model of instruction. Such an approach was later refined by <span class="citation">Haston and McPherson (2022)</span>, who gave specific directives as to when learning visual notation should be (e.g., 6-7 years old, after many years of ear-only training).</p>
</div>
<div id="the-contemporary-situation" class="section level4 hasAnchor" number="3.3.1.3">
<h4><span class="header-section-number">3.3.1.3</span> The Contemporary Situation<a href="backgrounds.html#the-contemporary-situation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Whilst visual notation may ostensibly reign supreme, perhaps in part due to the somewhat polemical literature reviewed that emerged arguing for the importance of playing by ear <span class="citation">(G. McPherson and Gabrielsson 2002; Musco 2010; Priest 1989)</span>, did attitudes and practices change. At the present time of writing, playing by ear seems to now be more widely recognised as a valuable pedagogical tool, with aural skill tests, including singing/playing by ear, being a feature of exam boards, at least in the UK. The development of playing-by-ear skills varies significantly across music examination boards. The <em>ABRSM</em> includes aural tests in which candidates sing back short melodies (Grades 1–3), but it does not assess instrumental playback by ear <span class="citation">(ABRSM 2024)</span>. In contrast, the <em>Trinity College London</em> syllabus features a “musical recall” component that directly tests the ability to play by ear on an instrument <span class="citation">(Trinity College London 2024)</span>. Similarly, <em>Rockschool</em> places strong emphasis on contemporary aural skills, including instrumental playback and improvisation as part of its exams from early grades <span class="citation">(RSL Awards 2024)</span>. These differences reflect broader pedagogical focuses, with ABRSM favoring traditional classical training and Trinity and Rockschool supporting a more holistic or contemporary approach. Perhaps due to these contemporary picture, has there been a relative dearth of new research on playing by ear. In the next section, I will describe findings from the music education and performance literature that help us understand the development of playing by ear skills and its relationship to other factors.</p>
</div>
</div>
<div id="developmental-and-pedagogical-aspects-of-playing-by-ear-skill-acquisition" class="section level3 hasAnchor" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> Developmental and Pedagogical Aspects of Playing By Ear Skill Acquisition<a href="backgrounds.html#developmental-and-pedagogical-aspects-of-playing-by-ear-skill-acquisition" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>How do musicians acquire the ability to play by ear? <span class="citation">Musco (2010)</span>’s review reports that playing by ear skills may develop naturally over time <span class="citation">(Gerber 1993; G. E. McPherson 2005)</span>, through unsupervised practice <span class="citation">(Gary E. McPherson 1995)</span> and practice with instruction [<span class="citation">Bernhard (2004)</span>; <span class="citation">Brown (1990)</span>; <span class="citation">Dickey (1991)</span>. Evidence suggests that the practice of recalling melodies on an instrument can improve playing by ear skills <span class="citation">(Bernhard 2005; Dickey 1991; Wilder 1988)</span>.</p>
<div id="early-development-and-informal-learning" class="section level4 hasAnchor" number="3.3.2.1">
<h4><span class="header-section-number">3.3.2.1</span> Early Development and Informal Learning<a href="backgrounds.html#early-development-and-informal-learning" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Developmental studies indicate that playing by ear can emerge at surprisingly early stages given the right exposure. Many children first experience music informally – singing songs, copying melodies by ear on piano or guitar, improvising little tunes – often well before they read notation. Longitudinal research <span class="citation">(e.g., G. E. McPherson 2005; G. E. McPherson, Bailey, and Sinclair 1997)</span> followed young instrumental students over time and found that those who engaged in activities like singing or picking out tunes by ear showed enhanced musical understanding in the long run <span class="citation">(Varvarigou 2014)</span>. McPherson noted that having beginners “sing before playing” an instrument helps them internalise pitch and rhythm, which later aids in connecting sound to symbols (notation). In essence, early ear-playing experiences allow children to embody music – linking what they hear to what their fingers do – which lays a cognitive foundation for all subsequent musical learning. Another study by <span class="citation">Gerber (1993)</span> suggested that skill in playing by ear often develops naturally through unguided exploration: children who spend time noodling on their instrument, figuring out favorite tunes by ear, tend to improve in that ability through self-discovery. Such findings align with anecdotal observations that many talented ear-players are self-taught or began learning informally (e.g. picking up guitar chords from recordings or learning folk tunes by ear). In popular music contexts, it is common for beginners to start with imitation of recordings, gradually building a repertoire of songs by ear <span class="citation">(Green 2002)</span>. Overall, developmental evidence supports the idea that given exposure and opportunity, learners will cultivate ear-playing competencies even without formal instruction – though formal training can further refine and expand these skills.</p>
</div>
<div id="formal-pedagogy-and-ear-training" class="section level4 hasAnchor" number="3.3.2.2">
<h4><span class="header-section-number">3.3.2.2</span> Formal Pedagogy and Ear-Training<a href="backgrounds.html#formal-pedagogy-and-ear-training" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Despite its evident benefits, playing by ear has not always been systematically incorporated into formal music education. Traditional Western pedagogy, especially in classical music, has heavily focused on notation literacy and technical exercises, with ear-playing sometimes regarded as a lesser skill or even a distraction. Nonetheless, a growing body of pedagogical research advocates for integrating playing by ear into teaching curricula for its positive impact on musicianship. <span class="citation">Baker and Green (2013)</span> conducted a landmark “Ear Playing Project” experiment with 10–14 year-old students in the UK, providing one group of students with regular opportunities to learn melodies by ear from recordings (instead of from notation) while a control group received only traditional instruction. After a period of instruction, all students were given standardised aural tests that required them to play back melodies and rhythms by ear. The results were striking: the ear-playing group surpassed the control group in every criterion (pitch accuracy, rhythmic accuracy, melodic contour, tempo, etc.) on the post-tests. In other words, those who practiced learning music by ear showed significantly greater improvement in aural skills than those who only learned through notation. This evidence strongly suggests that incorporating ear-playing in lessons can enhance students’ aural development. Notably, these gains did not come at the expense of other skills; instead, ear-playing experience appeared to reinforce musical memory and understanding that also benefit reading and performing. Parallel research by <span class="citation">Musco (2010)</span> and <span class="citation">Woody (2012)</span> addressed a common concern among music teachers that spending time on by-ear learning might impede music reading progress <span class="citation">(Varvarigou 2014)</span>. Their findings counter this worry: students can learn to play by ear and to read music in tandem, with each skill informing the other. In fact, <span class="citation">Woody (2012)</span> argued that ear skills make students more sensitive and “musical” when reading notation, since they are not just decoding notes on the page but internally hearing and understanding them <span class="citation">(<span>“Woody’s Research to Appear in <span>Psychology</span> of <span>Music</span>, Upcoming New Book <span></span> <span>Announce</span> <span></span> <span>University</span> of <span>Nebraska-Lincoln</span>”</span> 2018)</span>. Recognising these advantages, educational approaches like Suzuki method (for violin and other instruments) have long emphasised early ear training—students learn tunes by ear first, delaying notation, which purportedly develops strong listening and memory skills <span class="citation">(Hermann 1999)</span>. Similarly, contemporary methods in popular music education (e.g., Lucy Green’s informal learning approach, <span class="citation">Green (2008)</span>) deliberately use playing by ear in group teaching: students might be tasked with figuring out a pop song by listening to a recording together, fostering collaborative ear-learning. Teachers who have tried these approaches often report increased student engagement. For example, <span class="citation">Varvarigou (2014)</span> examined instrumental teachers’ experiences when they introduced “copying by ear” tasks in one-to-one lessons as part of the <em>Ear Playing Project</em>. Teachers adopted various strategies, such as singing or humming phrases to prompt students, asking guiding questions, and giving positive feedback while students learned songs by ear. By the end of the project, the teachers noted that incorporating ear-playing provided “a new and enjoyable way” to work on aural skills and even boosted their own confidence in teaching by ear. They observed that students seemed to enjoy lessons more, showed improved improvisation abilities, and grew more confident on their instruments through these activities. These qualitative outcomes echo formal test results: playing by ear can increase musical enjoyment and creativity, likely because it is a more naturally immersive way to learn music than reading alone.</p>
</div>
<div id="jazz-education-and-professional-development" class="section level4 hasAnchor" number="3.3.2.3">
<h4><span class="header-section-number">3.3.2.3</span> Jazz Education and Professional Development<a href="backgrounds.html#jazz-education-and-professional-development" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To summarise what was discussed in Chapter 3, in jazz music, learning by ear has always been fundamental, and research on jazz pedagogy provides insights into advanced playing by ear skill development. For instance, jazz educators encourage students to transcribe solos by ear (i.e. learn them by listening and reproducing, sometimes writing them down afterward) and to learn tunes from recordings rather than fakebooks. This practice not only ingrains repertoire, but also develops the aural vocabulary needed for improvisation. Ethnographic work, such as Paul Berliner’s <em>Thinking in Jazz</em> <span class="citation">(1994)</span>, documents how jazz legends acquired their craft: virtually all spent countless hours listening to records, imitating phrasing and solos, and jamming informally – all ear-driven learning. Systematic studies reinforce this: for example, a study of collegiate jazz improvisers by <span class="citation">Norgaard (2011)</span> found that expert improvisers rely heavily on musical memory during performance. In interviews, professional jazz musicians described their improvisational thinking as a mix of pre-learned phrases (licks) retrieved from memory, and spontaneous creation guided by ear. They reported that while improvising, they often recall well-learned ideas from memory and insert them, or choose notes based on an internal auditory priority (what they hear as the next phrase) rather than a purely theoretical formula. This again highlights the “primacy of the ear” (also the name given to a popular resource of the same name; <span class="citation">Blake (2010)</span>).</p>
</div>
<div id="improvisation-and-creativity" class="section level4 hasAnchor" number="3.3.2.4">
<h4><span class="header-section-number">3.3.2.4</span> Improvisation and Creativity<a href="backgrounds.html#improvisation-and-creativity" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Improvisation is closely intertwined with playing by ear, as both involve real-time generation of music without reading. Many studies of improvisation emphasise the role of the ear: improvisers are essentially composing with their instrument in real time, and to do so, they must listen – to the accompanying music, to their own ideas as they unfold, and to an internal sense of where the music could go next. Psychological models of improvisation <span class="citation">(e.g., Johnson-Laird 2002; Pressing 1988)</span> propose that improvisers use a repertoire of memorised licks plus generative rules to create new solos. The selection and execution of those licks is guided by auditory feedback: a player might hear a motif in their head and immediately play it, then listen to what they just played and let that spark the next idea. <span class="citation">Norgaard (2011)</span>’s study of expert jazz improvisers illustrated this iterative process of planning, executing, and monitoring during solos. The musicians described constantly evaluating their output (“was that phrase good? should I repeat it or change it?”) and making adjustments on-the-fly. This improvisational thinking requires a well-trained ear to judge one’s musical statements and to hear possibilities before playing them. Because of this, exercises that strengthen playing by ear are often recommended to aspiring improvisers. A vivid demonstration of advanced audiomotor integration is seen in jazz improvisers. <span class="citation">Harris, van Kranenburg, and de Jong (2016)</span> compared improvising pianists with classical score-dependent pianists in their ability to reproduce unfamiliar melodies by ear. They found that the improvising (ear-trained) musicians had a “superior ability […] to replicate both the pitch and rhythm of aurally perceived music at the keyboard, not only in the original key, but also in other tonalities”. In other words, those accustomed to playing by ear could accurately pick up a tune and immediately play it and even transpose it, far outperforming the note-bound players. The same study linked this behavioral skill to neural differences: an <em>fMRI</em> comparison revealed that improvising musicians showed enhanced activation in a right dorsal fronto-parietal network during audiation tasks, suggesting more efficient neural pathways for audiomotor transformations. These brain regions (including posterior parietal and premotor cortices) are thought to support mapping auditory inputs to motor responses. Likewise, <span class="citation">Limb and Braun (2008)</span>’s <em>fMRI</em> study of jazz improvisation found that spontaneous musical creation involves distinct neural dynamics (including heightened activity in motor-planning areas and the suppression of self-monitoring regions), illustrating the brain’s adaptation to real-time ear-to-hand performance. Collectively, research underscores that playing by ear is a whole-brain activity: it recruits auditory perception circuits, memory and planning areas, and motor execution networks in a tightly coordinated loop. With training, this loop becomes highly optimised – as seen in professionals who can hear a melody once and immediately play it. Sensorimotor integration is thus at the core of playing by ear, enabling the immediate translation of heard musical ideas into played music.</p>
</div>
<div id="learning-strategies-for-playing-by-ear" class="section level4 hasAnchor" number="3.3.2.5">
<h4><span class="header-section-number">3.3.2.5</span> Learning Strategies for Playing by Ear<a href="backgrounds.html#learning-strategies-for-playing-by-ear" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>There is limited research on the practice of learning by ear, especially among popular musicians <span class="citation">(Lilliestam 1996)</span>, with previous studies of learning by ear usually focusing on students or novices, often limited to short melodies <span class="citation">(<strong>Lahav2005:1?</strong>; Varvarigou and Green 2015)</span>. Despite this, there have been a few studies on experienced musicians, who use music theory and advanced strategies <span class="citation">(<strong>Johansson2004:1?</strong>; <strong>WoodyLehmann2010:1?</strong>)</span>. Musicians often learn by ear from recordings, using informal methods <span class="citation">(Bennett 1980; Groce 1989)</span> and recordings have been central to learning, even before digital tools <span class="citation">(Bennett 1983; Campbell 1995)</span>. It has been suggested that recordings serve as “notation” for popular musicians
Learning is typically a private, self-taught process <span class="citation">(Bennett 1983; Campbell 1995)</span>. Contemporarily, tools like Transcribe! and Amazing Slow Downer help slow and loop recordings, but their usage remains under-researched <span class="citation">(Driedger and Müller 2016; Johansson 2004)</span>. It has also been suggested that modelling i.e., call and response is an effective method to teach playing by ear skills <span class="citation">(<strong>dickey1988comparison?</strong>; Haston and McPherson 2022; Haston 2010)</span>. Additionally, providing “opportunities for self-initiated learning and non-evaluated practice” – where students explore without immediate external correction – has been suggested as crucial for developing confidence in ear-playing <span class="citation">(Varvarigou 2014)</span>. Such unguided exploration allows individuals to discover what strategies work best for them, whether it’s trial-and-error, visualising the music, or relying on muscle memory.</p>
<p>An important theme in playing by ear research is the contrast between formally trained musicians and those from informal backgrounds (such as self-taught popular musicians). Studies consistently show differences in how these groups learn and approach ear-playing. <span class="citation">Woody and Lehmann (2010a)</span> found that college music students with vernacular (informal) experiences needed significantly fewer trials to learn melodies by ear than their strictly classically trained peers. The formally trained musicians often struggled initially because their habits were tied to written cues and deliberate practice of technique; they tended to focus on “physically producing the melodies” (e.g. thinking about finger positions) instead of listening to the melody as a whole. In contrast, the informal-trained students had automated much of the motor execution, allowing them to focus attention on the sound itself. This finding echoes many anecdotal observations in music teaching: students coming from church bands, garage bands, or other informal environments often have a natural ease with picking up songs by ear and playing with others, whereas conservatory-trained students might excel at reading and technique but initially feel “lost” without sheet music. Of course, these differences are not immutable – formal training can incorporate ear skills, and informal musicians can learn theory and reading. The point is that early experiences shape one’s musical orientation. Individual differences in auditory memory, motivation, and even personality (e.g. willingness to take risks) can also affect playing by ear ability. Some individuals seem to have a proclivity for learning by ear; researchers like <span class="citation">Mishra (2016)</span> have speculated about auditory working memory capacity or auditory imagery vividness as factors that might make one person a stronger ear-learner than another. However, the overarching message from the literature is that playing by ear is trainable. Even those who do not consider themselves naturally good at it can improve with practice and the right strategies. For instance, a case study by <span class="citation">Creech et al. (2008)</span> showed that adult classical musicians, when encouraged to learn simple tunes by ear as part of a workshop, made substantial progress and reported it positively impacted their listening skills. As one educator summarised, “ear playing is learned by playing by ear” <span class="citation">(Johansson 2004)</span> – meaning the best way to get better is simply to do it, genre by genre, song by song, gradually building the mental library and reflexes that enable ever more fluent playing by ear.</p>
<p>Recent research has noted how YouTube has been used in various fields for observing real-world behaviors, including learning by ear <span class="citation">(Anthony, Kim, and Findlater 2013; Mauriello, Avrahami, and Mankoff 2018)</span>. YouTube offers access to real-world examples of musicians learning in their natural environments. <span class="citation">Liscio and Brown (2024)</span> conducted a hypothesis-generating study to explore how experienced popular musicians learn music by ear, using 18 YouTube videos as data. Their goal was to identify patterns of human-recording interaction that could inform the design of future music learning technologies. From their observations, they derived six key hypotheses grounded in empirical evidence. First, they found that the scope of learning influences musicians’ interaction with recordings. While some musicians attempted to learn entire songs, most focused on fragments such as riffs or solos, which may reflect both genre conventions (e.g., repetition in popular music) and the limited affordances of their tools. Second, notation and transcription played a surprisingly limited role. While a few musicians created sheet music or tablature during their learning process, these artifacts seemed to function more as memory aids than as tools directly supporting ear-based learning. Notably, most musicians did not consult notation while playing, suggesting that transcription and ear learning may operate as parallel, rather than integrated, activities. Third, purpose-built technologies—such as software designed to slow or loop audio—were seldom used. Most musicians relied on general-purpose media players like YouTube or Spotify and demonstrated little use of features like tempo or pitch adjustment. This underutilisation raises questions about the accessibility, awareness, or necessity of such tools among skilled learners. Fourth, the authors highlighted the importance of working memory in by-ear learning. Musicians frequently sang or hummed notes after pausing playback, indicating that vocal rehearsal may serve as a bridge between perception and performance. The ability to mentally retain short musical phrases and reproduce them on an instrument was a common strategy among participants. Fifth, familiarity with recordings prior to learning appeared to enhance the effectiveness of ear-based learning. Some musicians listened to tracks repeatedly before attempting to play them, or demonstrated genre-specific knowledge that allowed them to anticipate musical patterns. This suggests that pre-exposure and stylistic fluency may scaffold the by-ear learning process. Finally, the study found that theoretical knowledge, particularly regarding harmony and key, aided musicians in identifying chords and notes more efficiently. Those who could name chords or apply scale structures progressed more rapidly than those relying purely on trial-and-error methods. However, the authors caution that this efficiency may stem as much from instrumental fluency as from abstract theoretical understanding. Overall, this study contributes important insights into informal, in-the-wild musical learning practices and calls for future research to refine technological tools that align with the actual strategies musicians use. It also underscores the need for more inclusive datasets and broader participant demographics in future work. In Table xx, I reproduce the hypotheses generated by their study.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="backgrounds.html#cb1-1" tabindex="-1"></a><span class="co"># Create the data frame</span></span>
<span id="cb1-2"><a href="backgrounds.html#cb1-2" tabindex="-1"></a>table_data <span class="ot">&lt;-</span> tibble<span class="sc">::</span><span class="fu">tibble</span>(</span>
<span id="cb1-3"><a href="backgrounds.html#cb1-3" tabindex="-1"></a>  <span class="at">Hypothesis =</span> <span class="fu">c</span>(</span>
<span id="cb1-4"><a href="backgrounds.html#cb1-4" tabindex="-1"></a>    <span class="st">&quot;Desiderata recording interactions change depending on learning scope&quot;</span>,</span>
<span id="cb1-5"><a href="backgrounds.html#cb1-5" tabindex="-1"></a>    <span class="st">&quot;Transcription serves no role in the by-ear learning task&quot;</span>,</span>
<span id="cb1-6"><a href="backgrounds.html#cb1-6" tabindex="-1"></a>    <span class="st">&quot;Experienced musicians rarely engage with purpose-built tools&quot;</span>,</span>
<span id="cb1-7"><a href="backgrounds.html#cb1-7" tabindex="-1"></a>    <span class="st">&quot;A musician’s working memory will dictate their ability to copy notes&quot;</span>,</span>
<span id="cb1-8"><a href="backgrounds.html#cb1-8" tabindex="-1"></a>    <span class="st">&quot;Intentional recording familiarization improves by-ear learning&quot;</span>,</span>
<span id="cb1-9"><a href="backgrounds.html#cb1-9" tabindex="-1"></a>    <span class="st">&quot;Knowledge of theory helps make note and chord identification more efficient&quot;</span></span>
<span id="cb1-10"><a href="backgrounds.html#cb1-10" tabindex="-1"></a>  )</span>
<span id="cb1-11"><a href="backgrounds.html#cb1-11" tabindex="-1"></a>  )</span>
<span id="cb1-12"><a href="backgrounds.html#cb1-12" tabindex="-1"></a></span>
<span id="cb1-13"><a href="backgrounds.html#cb1-13" tabindex="-1"></a><span class="co"># Display the table</span></span>
<span id="cb1-14"><a href="backgrounds.html#cb1-14" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(table_data, </span>
<span id="cb1-15"><a href="backgrounds.html#cb1-15" tabindex="-1"></a>              <span class="at">caption =</span> <span class="st">&quot;Hypotheses about playing by ear strategies generated by Liscio and Brown (2014)&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-12">Table 3.1: </span>Hypotheses about playing by ear strategies generated by Liscio and Brown (2014)</caption>
<colgroup>
<col width="100%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Hypothesis</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Desiderata recording interactions change depending on learning scope</td>
</tr>
<tr class="even">
<td align="left">Transcription serves no role in the by-ear learning task</td>
</tr>
<tr class="odd">
<td align="left">Experienced musicians rarely engage with purpose-built tools</td>
</tr>
<tr class="even">
<td align="left">A musician’s working memory will dictate their ability to copy notes</td>
</tr>
<tr class="odd">
<td align="left">Intentional recording familiarization improves by-ear learning</td>
</tr>
<tr class="even">
<td align="left">Knowledge of theory helps make note and chord identification more efficient</td>
</tr>
</tbody>
</table>
</div>
<div id="playing-by-ear-abilities-and-its-relationship-to-other-factors" class="section level4 hasAnchor" number="3.3.2.6">
<h4><span class="header-section-number">3.3.2.6</span> Playing By Ear Abilities and its Relationship to Other Factors<a href="backgrounds.html#playing-by-ear-abilities-and-its-relationship-to-other-factors" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="citation">Musco (2010)</span> how playing by ear skills are related to sight-reading <span class="citation">(Luce 1965; Gary E. McPherson 1995; G. E. McPherson 2005)</span>.</p>
<p><span class="citation">Haston and McPherson (2022)</span> argue that singing should be a frequent and integral component of early music instruction. To advance beyond singing alone, a connection between vocalisation and the corresponding instrumental fingerings should be established - in lieu of visual notation. Musicians who both sing and play during the modeling or echo-teaching process strengthen the connection between their ears and fingers, promoting multimodal learning <span class="citation">(Haston and McPherson 2022)</span>. The process of mentally and physically rehearsing a piece “by ear”—through simultaneous singing and fingering - would cultivate a child’s capacity to perceive sound through kinesthetic engagement, thereby promoting the integration of bodily movement with cognitive processes <span class="citation">(Galvão and Kemp 1999; Haston and McPherson 2022)</span>. They further argue that application of solfège could further facilitate this transition by reinforcing the progression from rote memorisation (e.g., singing on a neutral syllable such as “la”) to conceptual understanding (e.g., employing sol-fa syllables and correlating them with instrumental fingerings).</p>
</div>
<div id="interim-summary" class="section level4 hasAnchor" number="3.3.2.7">
<h4><span class="header-section-number">3.3.2.7</span> Interim Summary<a href="backgrounds.html#interim-summary" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In summary, research in music education converges on the idea that integrating ear-playing experiences – whether through informal learning projects, ear-training exercises, or improvisational activities – significantly enriches musical development. It produces musicians who are more well-rounded, confident, creative, and able to adapt to new musical situations (a crucial trait for professionals). Ear-playing is no longer seen as mere talent or trick; it is increasingly recognised as a pedagogical tool and an objective of instruction in its own right.</p>
</div>
</div>
<div id="mcphersons-integrated-model-of-musical-skill-development" class="section level3 hasAnchor" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> McPherson’s Integrated Model of Musical Skill Development<a href="backgrounds.html#mcphersons-integrated-model-of-musical-skill-development" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To situate playing by ear and its development among other skills in an integrative fashion, <span class="citation">Gary E. McPherson (1993)</span> proposed and tested a theoretical model that examines the development of key musical performance skills among student instrumentalists. Drawing on both literature and empirical data—student performance outcomes and interviews, McPherson’s model offers a nuanced view of how various learning experiences and individual practices contribute to musicianship. The model, later supported by further analysis <span class="citation">(G. McPherson and Gabrielsson 2002)</span>, reveals both direct and indirect pathways between factors such as early musical experiences, quality and length of study, and the development of skills like sight-reading, improvisation, and playing by ear.</p>
<p>One of the central findings of McPherson’s model is the pivotal role of playing by ear. This skill was shown to be the strongest predictor of a student’s ability to improvise, suggesting that aural engagement is foundational to more creative aspects of musical performance. Playing by ear was also shown to have a meaningful, though more complex, relationship with sight-reading ability—supporting earlier findings that ear-training may play a more critical role in developing musical fluency than traditionally emphasised <span class="citation">(Luce 1965; Priest 1989)</span>. If also found that early musical experiences positively influenced students’ capacity to play by ear, though they had little impact on sight-reading. Similarly, engaging in enriching activities—such as improvising or playing by ear during practice—had a strong impact on the development of ear-playing skills, but again, less so on sight-reading. Interestingly, the quality of formal study had only a weak influence on both ear-playing and sight-reading, while the length of study had a moderate and consistent effect across multiple performance domains, including rehearsed performance, sight-reading, and playing by ear.</p>
<p>Through qualitative analysis of student interviews, McPherson also identified clear differences in cognitive strategy between less and more skilled performers. Less proficient players often relied on abstract, notation-based thinking, such as trying to identify note names while listening. In contrast, more capable musicians demonstrated a more integrated aural-kinesthetic approach, mentally translating what they heard directly into instrumental actions.</p>
<p>Overall, McPherson’s model offers an argument for the centrality of ear-playing in music education, as further iterated in <span class="citation">(Haston and McPherson 2022)</span>. It suggests that developing the ability to play by ear not only supports improvisational skill but also facilitates the integration of aural, visual, and motor domains essential to fluent musicianship. These findings carry significant pedagogical implications, potentially challenging traditional hierarchies in music training and highlighting the potential value of emphasising aural-based learning strategies in instrumental instruction.</p>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-13"></span>
<embed src="../img/McPherson_Chapter 8 Figure 3.pdf" title="Path analysis of the McPherson (1993) theoretical model. Thicker lines represent stronger relationships and thinner lines weaker relationships from one variable to the next, as shown by the directed arrows. Reproduced with the permission of Gary McPherson." type="application/pdf" />
<p class="caption">
Figure 3.1: Path analysis of the McPherson (1993) theoretical model. Thicker lines represent stronger relationships and thinner lines weaker relationships from one variable to the next, as shown by the directed arrows. Reproduced with the permission of Gary McPherson.
</p>
</div>
</div>
<div id="cognitive-mechanisms-underlying-playing-by-ear" class="section level3 hasAnchor" number="3.3.4">
<h3><span class="header-section-number">3.3.4</span> Cognitive Mechanisms Underlying Playing by Ear<a href="backgrounds.html#cognitive-mechanisms-underlying-playing-by-ear" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the next section, I now move towards describing playing by ear at a more detailed cognitive level. As far as I am aware, no comprehensive cognitive model of playing by ear yet exists. However, several models come very close to describing this phenomenon, and I thus review and later synthesise them here.</p>
<p>In general, music performance relies on three key cognitive skills: goal imaging (imagining the sound), motor production (executing movements), and self-monitoring (hearing and assessing one’s performance) <span class="citation">(Lehmann and Davidson 2002; Woody 2003)</span>. Similarly, <span class="citation">Haston and McPherson (2022)</span> describe playing by ear as requiring “aural discrimination skills and the alignment of concomitant motor skills: goal imaging, motor production, and self-monitoring. Linking that goal image to motor production is key.”.</p>
<p>Fluency in playing an instrument and by-ear playing involves creating strong connections between imagined sounds and physical actions—developing ear–hand coordination. Ideally, even reading music should trigger mental sounds that are already linked to specific instrumental actions.</p>
<p>In terms of cognition, I will review the various levels of processes required to play by ear, starting with “low-level” processes and moving up to high-level cognition.</p>
</div>
<div id="auditory-perception" class="section level3 hasAnchor" number="3.3.5">
<h3><span class="header-section-number">3.3.5</span> Auditory Perception<a href="backgrounds.html#auditory-perception" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Auditory perception represents a complex cognitive process through which the human brain transforms acoustic vibrations into meaningful sound experiences, involving multiple interconnected neural pathways and processing stages. The process begins with sound wave transduction in the cochlea, where mechanical vibrations are converted into electrical signals that travel through the vestibulocochlear nerve to various brainstem nuclei before reaching the medial geniculate body of the thalamus, which acts as a critical information processing hub that actively shapes auditory representations rather than serving as a simple relay <span class="citation">(Bartlett 2013)</span>. From the thalamus, processed auditory information reaches the primary auditory cortex in the temporal lobe, where sophisticated computational processes enable the brain to perform what <span class="citation">Bregman (1990)</span> termed “auditory scene analysis” - the fundamental ability to segregate, integrate, and organise complex mixtures of simultaneous sounds into distinct perceptual objects <span class="citation">(Sussman 2017)</span>. This cognitive process involves both automatic, stimulus-driven mechanisms that operate without conscious attention, as well as top-down attentional processes that allow selective focus on specific sound sources in noisy environments, such as following a conversation at a cocktail party <span class="citation">(Sussman 2017)</span>. The auditory system’s remarkable capacity for sound localization, pitch perception, and timbre recognition emerges from the integration of multiple acoustic cues processed across parallel neural pathways, with attention serving as a limited but flexible resource that can enhance processing of attended sounds while maintaining access to unattended auditory information in neural memory <span class="citation">(Carlini, Bordeau, and Ambard 2024; Sussman 2017)</span>.</p>
</div>
<div id="working-memory" class="section level3 hasAnchor" number="3.3.6">
<h3><span class="header-section-number">3.3.6</span> Working Memory<a href="backgrounds.html#working-memory" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>With attention applied to the auditory stimulus, tonal information is parsed and generally enters an acoustic store. This acoustic store is encapsulated in a memory system known as <em>working memory</em> <span class="citation">(A. D. Baddeley and Hitch 1974; A. Baddeley 2000)</span>, a form short term memory system. Cognitive psychology distinguishes between short-term memory and long-term memory in terms of both capacity and duration. Short-term memory (often equated with working memory) is a limited storage that holds information for mere seconds if not actively rehearsed <span class="citation">(Cascella and Al Khalili 2025)</span>. In contrast, long-term memory can retain information for days, years, or even a lifetime. These two memory systems differ not only in duration but also in function and mechanism. Working memory acts as a mental “scratchpad” for immediate information processing (such as remembering a phone number long enough to dial it), whereas long-term memory stores more durable knowledge such as facts, personal experiences, and skills. The classic <span class="citation">(<strong>atkinsonHumanMemoryProposed1968?</strong>)</span> conceptualised memory as a flow from transient sensory memory, to short-term memory, and eventually to long-term storage. While modern research has refined this modal model, the basic distinction remains useful: short-term memory is fleeting unless information is deliberately maintained or encoded into long-term memory.</p>
<p>The construct of working memory is now well-developed in psychology, with the most popular model being Baddeley and Hitch (1974)’s multi-component model, subsequently updated in Baddeley (2000). Working memory refers to the ability to transform and manipulate information in short-term memory. In general, it is thought to comprise components for manipulating phonic and visual stimuli separately. Music scholars have long recognised the important role of working memory in musical behaviours, particularly those involving aural skills (Chenette, 2021; Cornelius &amp; Brown, 2020; Gates, 2021; Karpinski, 2000). Indeed, those with formal music training have widely been documented to have better geneal working memory capacities (Talamini, Altoè, Carretti, &amp; Grassi, 2017; Talamini, Carretti, &amp; Grassi, 2016), but note, it is not clear that musical training causally influences general working memory (Silas et al., 2022).</p>
<p>It has been argued that <span class="citation">(<strong>baddeleyWorkingMemory1983model?</strong>)</span>’s standard general working memory model does not sufficiently explain the manipulation of musical stimuli (e.g., see <span class="citation">Berz (1995)</span>). Instead, it is proposed that there are other working memory components that represent a different class of working memory called <em>long-term working memory</em> <span class="citation">(Ericsson and Kintsch 1995)</span>, which particularly relies on experience-driven and domain- specific training in specialised domains, such as formal music training and chess, cultivates domain-specific forms of working memory, whereby (musical) abilities are subserved by relatively specialised systems, quite distinct from general working memory.</p>
<p>In our own research, we have found that a music-specific working memory system can be statistically dissociated from a general working system <span class="citation">Silas et al. (2022)</span>. Musical training appears related to musical working memory, which in turn is related to general working memory, but general working memory and musical training and not directly related. One could conceive that general working memory encapsulates musical working memory, which relies more on training and music-specific knowledge. In this way, general working memory probably constrains the development of musical working memory. We documented the possible scenarios which might explain the links between domain-general and domain-specific (music) working memory faculties: they may be relatively (statistically) disparate, but nonetheless, rely on each other, potentially bidirectionally. The implications of this are that, perhaps by definition, musical abilities are subserved by both domain-general (potentially to do more with inherited characteristics) and domain-specific (potentially more to do with training) faculties. In other words, someone with a very good general working memory might be able to demonstrate a similar level of musical (e.g., sung recall) performance to someone who has had more musical training. The former’s general faculties may help them monitor their performance as well as someone who has carved out music-specific templates to aid the same task. The underlying processes may be different, but the observable phenotype similar. Framed in terms of our study: if music conforms to a style that people in the general population are familiar with, do musical features (often better remembered by expert musicians) tend to matter? With relatively simplistic, familiar musical styles, is performance really mainly mediated by music-specific processes, or could it be more domain-general processes which turn out to be important? If melodies are long enough to require multiple attempts to sing in full, are musical features beyond length clearly important, compared to the length of a melody alone?</p>
<p>In <span class="citation">Silas and Müllensiefen (2023)</span>, we further explored this potential difference musical vs. non musical nature of sung recall further. We found that, the handling of relatively stylically simplistic (i.e, pop) melodies, can almost be thought more of a general working memory, rather than musical working memory, task. This is because, if melodic material is simplistic enough enough to handle, such that the general population will have had much exposure to their contents, then the importance of musical training in memory way not be as pronounced, and sung recall may then become more about general constraints on human memory (Christiansen &amp; Chater, 2016; Cowan, 2010; Miller, 1956; Oberauer &amp; Cowan, 2007). In this way, we found that not all all variance in melodic recall behaviour may be explained in musicological terms, suggesting that domain-general memory mechanisms should not be overlooked in explaining the representation of musical stimuli, at least when they are stylistically simplistic. This suggested the potential application of models and ideas from already well-established theories of produced mental representations in non-musical domains (non-musical serial recall; <span class="citation">Anderson (1972)</span>). We concluded that concepts related to general working memory constraints (e.g., non-musical serial recall, item length) are important in explaining melodic recall, potentially more so than any other musicological considerations (e.g., interval representations, tonality) at least when the length of the melodies certainly requires multiple attempts to sing back all the notes (e.g., length 15-48), or with pop melodies which are relatively simple to sing. In other words: the “melodic recall” of relatively simple pop melodies appears to be closely related to “recall” in other memory domains. In summary, the handling of musical stimuli in working memory depends ultimately on general working memory, but the more stylistically advanced the features become, the more musical training is required in developing domain-specific expertise (in Western music listeners, familiarity with simplsitic pop music does not constinute expertise, but a norm).</p>
<p>In the non-musical literature on verbal recall exists some relevant non-musical analogues to the observations that Sloboda and Parker (1985) made, that the attempt length increases across attempts (e.g., from the <em>Adaptive Control of Thought-Rational</em>, <em>ACT-R</em> literature Anderson, 1972, 1972; Chikhaoui et al., 2009). The so-called list length effect is the finding that recognition performance is superior for items that are part of a short list than for items that were part of a long list (Kinnell &amp; Dennis, 2012). Usually, the literature on verbal memory has used lists of unrelated words as stimuli and asks the participant to recall as many items as they can from memory. Over multiple attempts, Murdock Jr. (1960) specifically found that the shape of the learning curve across attempts can be described as an exponential curve with an asymptote equal to the number of items in a target list. However, word lists have different properties to melodies, which presuppose serial recall (i.e., a note order) and embody important structural features within interval and rhythmic patterns. It is not clear if the unique properties of musical stimuli mean that melodic recall processes are underpinned by fundamentally different processes to their non-musical analogues. Next, we discuss previous approaches to studying melodic memory.</p>
<div id="auditory-imagery-and-mental-representation" class="section level4 hasAnchor" number="3.3.6.1">
<h4><span class="header-section-number">3.3.6.1</span> Auditory Imagery and Mental Representation<a href="backgrounds.html#auditory-imagery-and-mental-representation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A central cognitive component of playing by ear is <em>auditory imagery</em>: the ability to internally hear or imagine music without external sound <span class="citation">(<strong>geldingEfficientAdaptiveTest2021?</strong>)</span>. Skilled by-ear players exhibit strong auditory imagery capacities, which enable them to anticipate and mentally “hear” pitches and phrases before playing them.</p>
<p>A fundamental skill for playing by ear is precise pitch perception – the ability to identify and reproduce notes and intervals. Many ear players develop acute relative pitch skills, allowing them to recognise scale degrees or chord tones by ear and map them to their instrument. Some research has examined the role of absolute pitch in ear-playing as well. While absolute pitch (the ability to identify pitches without a reference) can aid certain tasks, it appears to be somewhat rare, even in musician populations (&lt; 30% with absolute pitch; <span class="citation">Gregersen et al. (1999)</span>; <span class="citation">Leite, Mota-Rolim, and Queiroz (2016)</span>). Instead, most musicians seem to rely on well-honed relative pitch and tonal schema to play by ear in real musical contexts. For instance, learning a song by ear often involves detecting its tonal center and scale, recognizing common chord progressions (e.g. the 12-bar blues or II–V–I progression in jazz), and using those frameworks to guide note choices. <span class="citation">Johansson (2004)</span>, in a study of rock musicians, observed that ear players often identify familiar “clichés, harmonic formulas and other stylistic traits” of the genre to decode songs on the fly. In other words, they listen for characteristic chord patterns or melodic motifs, which helps them predict upcoming pitches. This genre-dependent pattern recognition underscores that ear-playing proficiency is partly a product of genre-specific listening experience. Musicians essentially build a library of musical phrases and progressions in memory by extensive listening; when a new piece is heard, they match it to known patterns. Over time, this process can become quite automatic. In summary, cognitive mechanisms of pitch processing in playing by ear involve both fine-grained perception (discriminating pitches and intervals) and higher-order schema (tonal and stylistic expectations), all coordinated through the musician’s auditory imagery and memory systems.</p>
<p>Playing by ear, sight-reading, and interacting musically help build an internal “aural database,” expanding musicians’ capacity to memorize more music <span class="citation">(Fine et al. 2006; Haston and McPherson 2022; Odam 1995)</span></p>
<p>Aural imagery allows musicians to develop and store mental representations of melodic and harmonic patterns, which supports more efficient future learning <span class="citation">(Freymuth 1999)</span></p>
<p>Memorising music relies on integrating aural, visual, and kinesthetic codes, making learning more robust and multidimensional <span class="citation">(Hallam 1998)</span></p>
<p>Playing by ear strengthens aural and kinesthetic memory - and possibly visual memory - as musicians often mentally visualise notation or musical structure <span class="citation">(Woody and Lehmann 2010b; Woody 2019)</span></p>
</div>
<div id="pitch-processing-and-audiation" class="section level4 hasAnchor" number="3.3.6.2">
<h4><span class="header-section-number">3.3.6.2</span> Pitch Processing and Audiation<a href="backgrounds.html#pitch-processing-and-audiation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>playing by ear promotes “inner hearing” <span class="citation">(Haston and McPherson 2022; Woody 2012)</span> - allows musicians to form a mental model of the sound they are going to play.</p>
<p>developing inner hearing allows performers to “listen with expectation” <span class="citation">(Haston and McPherson 2022)</span></p>
</div>
<div id="sensorimotor-integration-and-neural-basis" class="section level4 hasAnchor" number="3.3.6.3">
<h4><span class="header-section-number">3.3.6.3</span> Sensorimotor Integration and Neural Basis<a href="backgrounds.html#sensorimotor-integration-and-neural-basis" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Behavioural evidence suggests that the auditory imagery generated (in working memory) can guide performance by activating sensorimotor representations <span class="citation">(<strong>novembreConceptualReviewActionperception2014a?</strong>; Keller, Dalla Bella, and Koch 2010; Keller and Koch 2006; Pfordresher 2005; Pfordresher and Palmer 2006)</span>. Imagining sounds that correspond to specific instrumental actions can trigger the motor programs for those actions. In other words, when an experienced musician internally hears a melody, that imagery is closely coupled with the fingerings or movements needed to produce it. This aligns with the concept of <em>audiation</em> in music education <span class="citation">(E. E. Gordon 2001; E. Gordon 2007)</span>, whereby musicians “hear” music in their mind as a precursor to performing it. Neuroimaging evidence further supports this auditory–motor linkage. For example, studies show that simply imagining musical sequences engages regions of the brain’s motor planning network in trained musicians <span class="citation">(Bangert et al. 2006; D’Ausilio et al. 2006; Haueisen and Knösche 2001; <strong>novembreConceptualReviewActionperception2014a?</strong>)</span>. <span class="citation">Keller (2012)</span> noted that mental imagery in music performance serves important functions such as planning upcoming notes and monitoring intonation.</p>
<p>Neuroimaging studies have shown that similar brain activity occurs when music is heard and when it is imagined, suggesting that musicians can internally “hear” accurate pitches and “feel” the appropriate muscular movements during mental practice <span class="citation">(Alluri et al. 2017; C. L. Gordon, Cobb, and Balasubramaniam 2018; Haston and McPherson 2022)</span>. This integration of auditory imagery with the sensation of performance highlights the constant cross-modal processing involved in instrumental playing <span class="citation">(Ross 1985; Woody 2012)</span>. Additional research indicates that mental practice away from the instrument can be as effective as physical practice <span class="citation">(Miksza 2023)</span>.</p>
<p>Perhaps the most striking aspect of playing by ear is the seamless integration of heard sound with motor action. This audiomotor integration means that when an experienced musician hears a melody (externally or internally), their brain quickly maps those sounds to the required finger movements or vocal actions. Neuroscientific research has shed light on the brain networks that enable this feat. In skilled musicians, auditory and motor regions of the brain form strong bidirectional connections due to training. <span class="citation">(<strong>novembreConceptualReviewActionperception2014a?</strong>)</span> review evidence that musical training “couples” perception and action systems, such that perceiving a musical phrase can automatically activate the motor program to play it. This reflects the brain’s general action–perception coupling mechanism, where anticipated effects (like a heard note) can trigger the motor command associated with producing that effect. In the context of ear-playing, this means a violinist might hear a phrase in their mind and feel the impulse to execute the fingerings and bowings, or a pianist hearing a chord might internally rehearse the hand shape required.</p>
</div>
</div>
</div>
<div id="interim-summary-1" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Interim Summary<a href="backgrounds.html#interim-summary-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To summarise the cognitive psychological literature reviewed and relate it back to the music education literature: playing music by ear also engages working memory and long-term memory in unique ways. Musicians must temporarily hold incoming auditory information (i.e., the sounds just heard) while simultaneously planning and executing motor responses on their instrument. This places demands on the phonological loop (for retaining pitch sequences) as well as domain-specific long term working memory for melodies, as well as the integration of auditory and motor memory. Studies have explored how working memory for musical material might differ between those who rely on ear-playing and those who rely on notation. <span class="citation">Nichols, Wöllner, and Halpern (2018)</span> compared jazz and classically trained musicians on auditory working memory tasks and found notable differences. Jazz players – who typically emphasise learning by ear – outperformed classical players in remembering and reproducing heard melodies, especially when they had to play back the melodies on an instrument. In this study, musicians were asked to recall the final notes of sequences after a distraction, either by writing/singing or by playing them on a piano. Jazz musicians showed superior recall for aurally presented melodies when responding instrumentally (playing by ear), and their scores positively correlated with years of jazz experience. The authors concluded that jazz training (i.e., involving extensive ear-playing and improvisation experience) might enhance a domain-specific working memory capacity which allows the better handling of musical information in real time, especially relevant to improvised music contexts. Furthermore, ear-trained musicians often develop efficient cognitive chunking strategies. Instead of processing every note in isolation, they rely on familiar patterns and harmonic sequences stored in long-term memory. When reproducing a melody by ear, skilled musicians may anticipate likely chord progressions or melodic resolutions based on their internalised “musical grammar”. This predictive listening reduces memory load by allowing the musician to generate expectations. In this way, <span class="citation">Woody and Lehmann (2010b)</span> found that musicians with extensive vernacular (informal) music experience could learn melodies by ear with fewer repetitions than classically trained musicians, thanks in part to better anticipation of melodic/harmonic patterns. <span class="citation">Woody and Lehmann (2010a)</span> studied how well college music majors could learn melodies by ear. They compared students with “vernacular” music backgrounds (e.g., jazz, rock) to those trained mainly through formal instruction. The vernacular musicians outperformed the formal ones, needing fewer attempts to accurately sing or play back melodies. On average, vernacular students required 3 attempts to sing and 3.8 to play melodies, compared to 6.4 and 10.6 for formal students, suggesting that vernacular training places emphasis on both melodic memory (goal imaging) and the ability to reproduce melodies on instruments (motor production). The ear-trained players applied a “more sophisticated knowledge base to generate accurate expectations” about how a melody would unfold. In contrast, formally trained players without strong ear-playing backgrounds used less efficient, more surface-level strategies for encoding melodies. This implies that cognitive schemas and pattern knowledge (acquired largely through listening and imitating) free up working memory resources during playing by ear by providing ready-made chunks and expectations.</p>
<!--

-->
<p>Expert playing by ear musicians form rich mental representations of pieces, often encoding not just the melodic contour but also harmonic and structural features. Musicians highly skilled in ear-playing use “harmonically oriented integrated cognitive strategies,” whereas less experienced ear-players rely on more fragmentary, note-by-note approaches <span class="citation">(Woody 2020)</span>. In Woody’s study, university music students who were guided to focus on a melody’s underlying chord progression developed a more substantive “goal image” of the tune, which in turn improved their ability to learn it by ear. This indicates that adding harmonic context to one’s auditory imagery (for instance, knowing the chord changes) leads to more robust mental representations and facilitates ear-playing. Thus, proficient playing by ear involves vivid auditory imagery and schema-like memory for musical patterns, especially harmonic frameworks.</p>
</div>
<div id="pfordreshers-cognitive-model-of-singing-accuracy-and-h-pac-models" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> Pfordresher’s Cognitive Model of Singing Accuracy and H-PAC Models<a href="backgrounds.html#pfordreshers-cognitive-model-of-singing-accuracy-and-h-pac-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><span class="citation">Pfordresher et al. (2015)</span> provided a foundational overview of theoretical approaches to singing accuracy, emphasising the complexity of the cognitive and sensorimotor processes involved in vocal production. They highlight that accurate singing depends on more than just pitch perception or motor ability—it arises from the interaction between perceptual and motor systems, including how auditory targets are represented and transformed into vocal output.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="backgrounds.html#cb2-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">&#39;../img/pfordresher_singing_model.jpg&#39;</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-14"></span>
<img src="../img/pfordresher_singing_model.jpg" alt="Pfordresher et al.'s (2015) cognitive model of singing accuracy. Reproduced with the permission of Peter Pfordresher."  />
<p class="caption">
Figure 3.2: Pfordresher et al.’s (2015) cognitive model of singing accuracy. Reproduced with the permission of Peter Pfordresher.
</p>
</div>
<p>This perspective sets the stage for the <em>H-PAC</em> (Hierarchical Perception-Action Coupling) model later proposed by <span class="citation">(<strong>pfordresherSoundActionMusic2019?</strong>)</span>, which formalises these ideas into a mechanistic account of how singing behaviour emerges from hierarchical layers of processing. According to the <em>H-PAC</em> model, musical performance involves the dynamic coupling of auditory perception with motor planning and execution, structured across multiple levels—from abstract representations such as melodic contour, down to specific articulatory commands that activate the vocal apparatus. These commands refer to the fine-grained motor instructions sent to the muscles involved in vocal production (e.g., the larynx, tongue, lips), translating high-level musical goals into physical sound.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="backgrounds.html#cb3-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">include_graphics</span>(<span class="st">&#39;../img/pfordresher_hpac_model.png&#39;</span>)</span></code></pre></div>
<div class="figure"><span style="display:block;" id="fig:unnamed-chunk-15"></span>
<img src="../img/pfordresher_hpac_model.png" alt="Pfordresher et al.'s (2019) H-PAC model. Reproduced with the permission of Peter Pfordresher."  />
<p class="caption">
Figure 3.3: Pfordresher et al.’s (2019) H-PAC model. Reproduced with the permission of Peter Pfordresher.
</p>
</div>
<p>A central feature of both the <span class="citation">(2015)</span> and <span class="citation">(<strong>pfordresherSoundActionMusic2019?</strong>)</span> accounts is the notion that poor-pitch singing often reflects a disruption in the mapping between auditory targets and motor output, rather than a deficit in either domain alone. This helps explain why some individuals with intact pitch perception still struggle to produce accurate vocal pitches. Within the <em>H-PAC framework</em>, such difficulties are attributed to failures in either feedforward mechanisms - which plan motor actions based on internally generated auditory representations - or feedback mechanisms, which compare ongoing output with auditory goals and make real-time corrections.</p>
<p>At the low level, this cognitive system includes an auditory feedback loop, wherein external sound is encoded as perceptual representations of pitch, timbre, duration, and loudness. These low-level representations are used to guide sensorimotor planning through a translation mechanism, which maps perceptual information onto physical actions. In singing, this mapping guides processes like respiration, phonation, and articulation. In instrumental performance, however, these actions are instrument-specific: finger coordination for piano, violin, or clarinet; embouchure control for brass and woodwinds; or arm and wrist movements for percussion.</p>
<p>Beyond low-level mapping, higher-level cognitive processes support the categorisation and structuring of auditory input. Drawing on long-term memory <span class="citation">(<strong>baddeleyMemory2009?</strong>; Ericsson and Kintsch 1995)</span>, listeners use mental templates to extract musical features such as tonality, melodic contour, and phrasing. These abstract representations provide top-down input to inform sensorimotor planning, while also being shaped by real-time auditory feedback. The result is a bidirectional architecture, in which perception and action are constantly influencing one another.</p>
<p>Crucially, this same system can be extended to playing by ear—the reproduction of music on an instrument without notation. In such contexts, an auditory stimulus is perceived, mentally represented, and mapped onto the motor system of a particular instrument. The perceptual and cognitive processes involved in encoding, segmenting, and categorising the input remain largely the same as in singing; it is primarily the motor modality that differs. Whether reproducing a melody vocally or on a violin, successful performance depends on the strength of the mapping between internal sound representations and the corresponding motor output. One difference between singing and instrumental playing is the different kinds of kinaesthetic perceptual traces and memories that may reinforce learning <span class="citation">(Galvão and Kemp 1999)</span>.</p>
<p>Thus, both <span class="citation">Pfordresher et al. (2015)</span> and the <span class="citation">(<strong>pfordresherSoundActionMusic2019?</strong>)</span> <em>H-PAC</em> model offer a unified theoretical framework for understanding musical reproduction across domains. By situating performance within a hierarchically organised, interactive system that links perception, cognition, and motor control, this approach provides a compelling account of how individuals produce music—either through singing or playing by ear. It also offers explanatory power for understanding individual differences in performance ability, the nature of imitation deficits, and potential strategies for remediation or training.</p>
</div>
<div id="bakers-computational-model-of-melodic-dictation" class="section level2 hasAnchor" number="3.6">
<h2><span class="header-section-number">3.6</span> Baker’s Computational Model of Melodic Dictation<a href="backgrounds.html#bakers-computational-model-of-melodic-dictation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><span class="citation">Baker (2019)</span>’s computational model of melodic dictation presents a stage-based framework that simulates how listeners perceive, process, retain, and ultimately transcribe melodies into symbolic notation. Whilst melodic dictation - the reproductive act of transcribing a melody into visual notation on paper - is different to melodic recall/playing by ear, this model has some useful features to add depth to the other frameworks discussed above.</p>
<p>The model begins with a perception stage, during which the dictation object — typically a short monophonic melody — is encoded into a set of low-level melodic features. For simplicity, the author follows <span class="citation">(<strong>pearceConstructionEvaluationStatistical2005?</strong>)</span>’s representation of both pitch (note and scale degree) and timing (rhythm and interonset interval). Whilst Baker only uses these features for convenience, it is likely that other higher order melodic features are relevant to this task as well as playing by ear. An important part of this model is the notion that as a melody unfolds serially (note-by-note), each new note added to the working memory buffer for the target melody adds a new degree of information content. The information content is computed based on a users stylistic knowledge of Western tonal music that has in turn been created through enculturation (i.e., many years of listening; <span class="citation">(<strong>pearceConstructionEvaluationStatistical2005?</strong>)</span>). The more training a musician has undertaken, the larger their library of “learned” musical chunks that they can rely on. Each transcriber has their own working memory capacity for such information, which when reached should lead to a deterioration in memory. After hearing and representing the melody, a search for representations of that melody in ones “prior knowledge”. If a match is found for a representation that has been explicitly learned, then the melody or segment can enter the transcription module and be transcribed. If there is a gap between prior knowledge and the target melody, on patches will be transcribed, based on any matches that could be found for melodic subsets (i.e., N-grams).</p>
<p><span class="citation">Baker (2019)</span>’s conception of <em>cumulatative information content</em> is useful and highly relevant to playing by ear. In playing by ear, this cumulative information content would be implicated in both the heard melody and the recalled melody. The idea of segmenting and only being able to recall N-gram subsets of melodies avaialble in prior knowledge is also a useful notion.</p>
</div>
<div id="models-of-sung-recall" class="section level2 hasAnchor" number="3.7">
<h2><span class="header-section-number">3.7</span> Models of Sung Recall<a href="backgrounds.html#models-of-sung-recall" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Lastly, I synthesise models from my own research regarding sung melodic recall. My <span class="citation">Silas, Müllensiefen, and Kopiez (2023)</span> study investigated sung recall by examining its relationship with other related skills and participant attributes. Demographically, better sung recall ability ability was associated with more musical training, a younger age, and being female, though the latter two effects were small. The findings suggest that while musical training can enhance singing ability, inherent skills might also predispose individuals to seek musical training. Moreover, there was a relatively large difference between the marginal and conditional R^2 values, which suggests that there is a sizeable proportion of individual differences in the sample of participants tested which explains SAA performance which shows that individual differences should explain performance on a task in which one can develop high levels of domain-specific expertise.</p>
<p>We found there that melodic discrimination, pitch imagery abilities, and mistuning perception appear to be fundamental skills contributing to melodic sung recall. The sung recall score we devised moderately correlated with self-reported singing ability and musical training. However, it shows no significant correlation with visuospatial working memory or pitch discrimination, aligning with previous research and suggesting that singing ability is not closely linked to low-level perceptual processes. This suggests that, whilst</p>
<p>The study also shows that melodic features which indicate melodic complexity (including melody length) are relevant predictors of sung recall performance. These predictors represented melody length, as well as features related to contour, tonality, statistical occurrence of N-grams in the melody, and durational complexity. Rhythmic trials were generally found to be more difficult and we found that it was appropriate to create separate models for arhythmic and rhythmic.</p>
<p>In another of my papers, <span class="citation">(Silas and Müllensiefen 2023)</span>, we investigated how individuals learn and recall melodies using a computational approach that emphasizes similarity metrics rather than traditional accuracy-based methods. The research involved 31 participants who sang back 28 melodies presented either as piano sounds or vocal audio excerpts from pop songs, with each melody repeated up to six times. The similarity between the target melody and the participants’ sung recalls was measured using advanced algorithmic techniques. The primary goal was to understand how melodic recall improves over successive attempts and what factors most significantly influence recall accuracy.</p>
<p>One of the key findings of the study is that the length of sung recall attempts consistently increases across multiple attempts, and this increase significantly correlates with the overall similarity to the target melody. This observation challenges the traditional view that musical features such as interval patterns or tonality are the primary factors influencing melodic recall. Instead, the study suggests that the sheer length of the melody plays a more critical role, indicating that general memory constraints may be more influential than music-specific features. This insight aligns with theories of working memory, suggesting that melodic recall shares characteristics with other types of serial recall rather than being purely domain-specific to music.</p>
<p>A significant finding (presented there in Figure 8), examines how similarity changes as a function of attempt and the specific section of the melody (beginning, middle, end). The results show that similarity performance increases more rapidly for the beginning of the melody compared to the middle and end across successive attempts. This indicates that participants tend to stabilise their recall of the initial melodic segments earlier than the middle or end sections. The end sections, in particular, show a slower rate of improvement, suggesting that the latter parts of a melody are more challenging to accurately recall perhaps due to the higher working memory load as a result of having to remember more notes, the later you are in a position, or that generally people engaging in sung recall prioritise getting the earlier parts melody correct first. This finding supports the theory that memory encoding is stronger for the beginning of sequences, a phenomenon consistent with the primacy effect observed in other types of serial recall tasks. It also highlights that recall accuracy is not uniformly distributed across a melody, with the initial segments being more robustly learned compared to later ones.</p>
<p>The study also found that musical training did not significantly enhance recall performance when similarity metrics were used as the primary assessment method, as shown in another key result. This challenges the conventional belief that formal musical training substantially improves melodic recall ability. Instead, the data suggests that domain-general memory skills may be just as important, pointing to a more integrative understanding of how musical and non-musical cognitive processes interact.</p>
<p>Moreover, the results highlight that similarity scores increase with each successive attempt, but the rate of improvement diminishes after the third or fourth attempt. This pattern suggests that the most substantial gains in melodic recall occur early in the learning process, followed by incremental refinements in pitch and rhythm accuracy. Additionally, melodies presented as vocal audio excerpts resulted in higher recall accuracy compared to piano sound presentations, indicating that the human voice might provide additional mnemonic cues that aid in memory encoding.</p>
<p>Overall, the study’s use of similarity-based metrics, particularly the “opti3” metric that integrates pitch intervals, harmonic progression, and rhythmic similarity, offers a more nuanced and accurate assessment of how melodies are learned and recalled. By focusing on the gradual increase in recall length and the differential improvement across melodic segments, the study sheds light on the underlying cognitive processes involved in melodic memory, emphasizing the role of general memory mechanisms and the relatively limited impact of formal musical training.</p>
<div id="playing-by-ear-research-conclusion" class="section level3 hasAnchor" number="3.7.1">
<h3><span class="header-section-number">3.7.1</span> Playing by Ear Research: Conclusion<a href="backgrounds.html#playing-by-ear-research-conclusion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The phenomenon of playing by ear sits at the intersection of cognitive skill, pedagogical practice, and musical creativity. From a cognitive standpoint, playing by ear engages complex mental processes: vivid auditory imagery, specialised working memory, pattern recognition, and a tight coupling of perception and action. Neuroscience suggests that extensive ear-playing experience can even shape the brain, leading to more efficient audiomotor networks (as seen in improvising musicians). Developmentally, learning to play by ear can begin early and flourish in environments that encourage informal exploration. Incorporating ear-playing into formal instruction – as research in music education has shown – yields benefits for aural skills, musical understanding, and student motivation. In jazz and other professional domains, playing by ear is not only a skill to acquire but a mode of musical existence: it underpins the ability to improvise and to connect with music on a deeply intuitive level. Individual differences certainly influence how people approach playing by ear, yet studies underline that with the right strategies and experiences, virtually any musician can improve their ear-playing ability. This rich body of literature refutes the old notion that playing by ear is a mysterious gift; instead, it is a multifaceted skill set that can be analysed, taught, and learned. As <span class="citation"><span>“Woody’s Research to Appear in <span>Psychology</span> of <span>Music</span>, Upcoming New Book <span></span> <span>Announce</span> <span></span> <span>University</span> of <span>Nebraska-Lincoln</span>”</span> (2018)</span> observed, developing ear-based musicianship imbues music making with a certain “humanness”
– it reconnects performers with the fundamentally aural nature of music. In practical terms, musicians who play by ear often learn new material faster, memorise more effectively, and perform with greater expressivity and flexibility. For educators, the implication is clear: fostering playing by ear alongside other skills produces more well-rounded and versatile musicians. For researchers, playing by ear remains a fertile topic, raising questions about auditory cognition, expert memory, and even cross-cultural musical learning. The literature so far, grounded in cognitive psychology, music psychology, and systematic musicology, provides a compelling case that playing by ear is both an essential subject of study and an invaluable aspect of musical praxis – from the novice learner picking out a tune, to the jazz virtuoso crafting a solo, guided all the while by the inner ear.</p>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="a-comprehensive-theorectical-model-of-playing-by-ear.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
  "sharing": {
    "github": false,
    "facebook": true,
    "twitter": true,
    "linkedin": false,
    "weibo": false,
    "instapaper": false,
    "vk": false,
    "whatsapp": false,
    "all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
  },
  "fontsettings": {
    "theme": "white",
    "family": "sans",
    "size": 2
  },
  "edit": {
    "link": null,
    "text": null
  },
  "history": {
    "link": null,
    "text": null
  },
  "view": {
    "link": null,
    "text": null
  },
  "download": null,
  "search": {
    "engine": "fuse",
    "options": null
  },
  "toc": {
    "collapse": "subsection"
  }
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
