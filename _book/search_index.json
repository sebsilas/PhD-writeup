[["table-of-contents.html", "1 Table of Contents", " 1 Table of Contents Introduction {#introduction} Further Research/To Do Motivations Generalising beyond jazz Computational modelling What is playing by ear? Learning to play by ear Research questions Music and combinatorics library(musiccombinatoricsr) The Coltrane-Slonimsky Problem Background Historical approaches to improving playing by ear Melody as Cognitive Psychology Playing By Ear: A Theoretical Model {#theoretical-model} Pfordresher’s H-PAC model Pfordresher’s cognitive model of singing accuracy Baker’s computational model of melodic dictation Models of sung recall Non-musical models of serial recall WM bits Bringing it together Moving from Theoretical to Computational Inputs Sequential Construction Function Application Mathematical Representation Algorithm Flow Final Equation Strategies Learning, forgetting The Melodic Mind As Item Bank Predictions: Melodic corpora as networks {#melodic_networks} musicassessr Similarity Simulation Model A computational ecosystem {#computational-ecosystem} pyin: Psychologically meaningful musical item banks: itembankr itembankr Datasets WJD Berkowitz Slonimsky Other useful functions Assessing musical behaviours: musicassessr Conclusion Ability Tests {#ability_tests} SAA PBET SAA() PBET() Calibration studies {#calibration_studies} Development of a melodic similarity algorithm for short recalled melodies {#melsim_development} Model of melodic difficulty {#pbet_online_study} Item curation {#item_curation} Heterogenity and item bank sampling {#heterogeneity_and_item_bank_sampling} via item response theory (IRT) (difficulty) via similarity via difficulty/similarity hybrid Approaches to similarity for large scale corpora {#item_banks_and_similarity} Problem: WJD_no_items &lt;- nrow(WJD::WJD(‘phrases’)) factorial(WJD_no_items) Approach #1: similarity of features as proxy for melodic similarity Approach #2: Generative similarity Approach #3: on breaking up items into ngrams, store representations/similarity. Reviewing and spaced repetition {#reviewing_and_spaced_repetition} identify correct vs incorrect ngrams in a recall: add incorrect ngrams to beginning of session buffer Reviewing and spaced repetition {#visual_vs_auditory_learning_pbe} identify correct vs incorrect ngrams "],["introduction.html", "2 Introduction 2.1 Further Research/To Do", " 2 Introduction Jazz musician spiel In 1947, the Russian-American composer Nicolas Slonimsky who was “obsessed with twelve-tone rows” (https://books.google.de/books?id=r9S--ESUuxEC&amp;pg=PR151&amp;lpg=PR151&amp;dq=schoenberg+feat+of+mental+gymnastics&amp;source=bl&amp;ots=V4wLBZKQPn&amp;sig=ACfU3U2mfVWZ-_DJgE8OEHtNN-SCCS5HJA&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwjooqOFtcTtAhV75-AKHQqaA9EQ6AEwBHoECAYQAg#v=onepage&amp;q&amp;f=false) produced a seminal book in music theory: the Thesaurus of Scales and Melodic Patterns (from here referred to as the Slonimsky’s Thesaurus; Slonimsky, 1947). As suggested by its title, the book is an exhaustive collection of musical melodies which Slonimsky laboriously generated manually and systematically. The purpose of such a volume was to provide a repository of musical melodies which breaks free of traditional tonal harmonic principles. In other words, it was an attempt to systematically open up possibilities in the Western Music system which had not yet been explored. Slonimsky’s undertaking can be viewed as a way of codifying and unlocking the potential of music through systematization; it highlights that by algorithimic thinking, new possibilities can be unleashed. As such, Slonimsky’s volume fascinated.. Coltrane … Zappa. One basic principle behind Slonimsky’s systematization was to divide one or more octaves of the twelve-tone system into symmetrical intervals and, from there, systematically interpolate different numbers of notes between the intervals created by the divisions. Additionally, he used other formulae to generate melodic patterns which had not yet been yield by his basic scheme. Of The Thesaurus, Schoenberg wrote to Slonimsky, “you might [have] in all probability organized every possible succession of tones” and referred to his work as “an admirable feast of mental gymnastics”. Whilst the former is almost certainly not true (unless constrained to a length, the possibilities of melodies are infinite), the latter is undoubtedly. However, such a task would now be solved at ease by a script on a modern computer. The present author was fascinated by the possibilities of the work, wishing to uptake the melodies on his saxophone in a systematic way. However, the book has at least 1,400 discrete items and some of the patterns are terrifically long and complicated. Additionally, nearly all of the melodies are presented from a single note, C, and could be transposed to start on the other 11 chromatic tones. This means there are at least 16,800 (12 * 1400) items to be learned. The author’s saxophone tutor, who was a virtuoso, once said, “Oh, don’t bother trying to learn [Slonimsky’s Thesaurus of Scales and Melodic Patterns] systematically”. This was a wise comment since, as there is so much information, it is almost impossible for a human to comprehend and track their learning of it systematically. However, with advances in computation, this is a relatively easy challenge to solve once the data is in digital form. The author entered the Slonimsky’s Thesaurus corpus into his computer to provide a digital representation. This corpus will remain the test case for description in this document later on. In more recent times, other repositieies of melodies have emerged which are not usually as concerned with twelve-tone possibilities, but are more constrained to a pedagogically focused item banks. Such volumes can be viewed as melodic etudes, which are usually geared towards jazz improvisation and acquiring inner melodic representations. In the music theory and music education literatures, particularly with respect to jazz improvisation, there are many books which contain itemised melodic patterns to stimulate compositional ideas or so that training musicians can practise acquiring cognitive representations of new melodic material (Lateef, 2015; Weiskopf, 2015; Slonimsky, 1947; Ricker, 1999). Such books are essentially corpuses (of which they will from here be referred to) of melodic grammar and possibilities. As well as improving one’s melodic “vocabulary”, such books can be used to develop technical prowess, by challenging the player to acquire new action patterns to perform the items. However, often these volumes are just repositories of melodies and lack a systematic structure, or if they do, the structure is not built upon rigid principles which advance the objective of efficient learning. This is also a technological issue: books are not able to break down items into smaller pieces and consider the relationship between items. Instead, the meaning as to be discovered post hoc by the book’s user. Therefore, by not bring structured in a way that makes them optimised for memorisation such books are limited. Typically, contents will be structured into discrete items where each item represents a particular melodic sequence. However, each of these items can be broken into smaller contiguous subsets known as n-grams (Damashek, 1995), here called “chunks”. Such componentisation makes items more readily memorable since sequence length is a major predictor of how memorable an item is (Cowan, 2010; Miller, 1956). The implication is that, by first learning smaller chunks and then increasing the size of chunks, one can optimise the learning process (Lehmann &amp; Kopiez, 2011). To undertake such a task manually is more or less impossible as it would require an individual to comprehend a combinatorial explosion of relationships between the items in a given corpus (intra-corpus). Moreover, different corpuses will also share identical and similar chunks, so learning one chunk may support learning other chunks inter-corpuses. It would be redundant to treat these as separate chunks (except to count chunks by frequency, another potential indicator of its usefulness) and would instead be more efficient to have a centralised system which can consider information inter-corpus. The present paper details a new set of scripts which allow a user to process a corpus programmatically to solve some of the problems above. Consequentially, it is able to: a) provide useful insights into that particular corpus b) process the corpus into more readily memorable structures c) facilitate the ability to relate items to one another intra-corpus and inter-corpus . In doing so, the application should be able to improve the amount of time a user requires to learn melodic information from repositories of patterns. 2.1 Further Research/To Do https://books.google.de/books/about/Perfect_Pitch.html?id=V1cIAQAAMAAJ&amp;redir_esc=y https://wiki.killuglyradio.com/wiki/Nicolas_Slonimsky "],["motivations.html", "3 Motivations", " 3 Motivations The main problems this thesis attempts to solve is: A Computational Model of Playing By Ear Abilities: Given an aurally presented melody as input and a reproduction of that melody by a performer as output, what are the cognitive processes underlying performance? This problem is one of developing a cognitive model of playing by ear skills. I will specifically seek to develop a computational model of playing by ear skills. A Computational Model of Playing By Ear Learning and Skill Acquisition: Extending such a model, how do people learn to play by ear? How can people learn to play by ear effectively? item generation curation item selection: that of selecting new melodic material to learn to improve playing by ear skills. "],["generalising-beyond-jazz.html", "4 Generalising beyond jazz", " 4 Generalising beyond jazz Whilst I motivate this problem historically and pedagogically in terms of those learning jazz materials, I note, that I expect many of the outcomes to be relevant to playing by ear to very similar - if not virtually identical - for other types of music too, and at least very similar for singing by ear too which is far more ubiqutuous. Since virtually everyone can sing (CITE) but far fewer people have access to an instrument beyond the voice (CITE), I will often discuss singing by ear too and borrow from this literature. In general, much of the cognitive processes behind singing and playing by ear should be very similar. I thus suggest that, the outcomes of this dissertation are not only relevant to jazz musicians, but have a much larger impact, for musicians and musics of all kinds - at least in principle. In practice, model specifics may need adapting for utmost relevance to other domains. There are two (related) principal problems that this thesis aims to tackle. First, since, as of yet, there exists no comprehensive computational model of playing by ear skills (in terms of both acquisition and utilisation), I intend to first propose a theoretical model based on a synthesis of related literature. Once described, I seek to investigate and validate parts of this proposed model in light of empirical data. The second principal problem is to, given such a computational model, design a computer application which helps playing by ear learners more efficiently improve their skills. This part of the thesis has a practical deliverable component that is intended to be used in real-life learning situations, whilst being situated in a scientific framework - both theoretical and statistical. Such an application would be proposed in an open source framework that can be extended by future developers to add new features and improve existing components of the application. The main problem the application intends to solve is one of item selection i.e., finding “optimum” playing by ear items to learn for a given learner, at a given timepoint. "],["computational-modelling.html", "5 Computational modelling", " 5 Computational modelling "],["what-is-playing-by-ear.html", "6 What is playing by ear? 6.1 Learning to play by ear 6.2 Research questions", " 6 What is playing by ear? In this dissertation, I define playing by ear as the ability to reproduce an aurally presented melody on and instrument (including the voice). To play well by ear means to reproduce the musical properties of the heard melody accurately across relevant domains, such as pitch, interval and rhythmic structures. I note, that, precisely what these important musical structures to assess accuracy by are consist of is non-trivial, and something partly explored on this thesis. I thus leave the definition relatively general at this point. To play badly by ear means to struggle to reproduce the musical structures contained in the melody. Note, that my definition separates playing by ear from “improvisation”, which is about spontaneously generating (new) ideas, not a faithful replication of that heard before. 6.1 Learning to play by ear I separate the general process of “playing by ear” from “learning to play by ear”, even though the two are intrinsically linked. “Playing by ear” presumes that the melody is sufficiently “prelearned” to be recalled almost perfectly. Conversely, learning to play by ear is a separate process, whereby the melody to be recalled is not yet stable enough in memory to be reproduced faithfully. It will take specifically at least more than one attempt to be recalled accurately - potentially “revised” - or may not be recallable in a given session. Thus, learning requires multiple attempts. Learning also requires that improvements are made over attempts, in the relative short term [@silasLearningRecallingMelodies2023], but also over longer time periods. 6.2 Research questions PRQ1: How can one effectively learn to play by ear? The thesis aims to answer this question in psychological, musicological, computational, and pedagogical terms. SRQ1: What makes PBE difficult? (psychological, musicological) SRQ2: Can a computer app (with computational item selection) help learn more quickly? (computational) SRQ3: What does such a computational model need to take into account? (DASH?) (computational, psychological) SRQ4: Does presentation mode (visual vs. auditory) make a difference to learning? (pedagogical) SRQ5: Does singing a melody first help? (pedagogical) SRQ6: to what degree is playing by ear based on absolute vs. relative pitch? SRQ7: to what degree is playing by ear based on general working memory vs. acquired training? PRQ2: Intervention: Does a program which implements these effectively work? (psychological, musicological, computational, pedagogical) "],["music-and-combinatorics.html", "7 Music and combinatorics", " 7 Music and combinatorics # library(musiccombinatoricsr) 7.0.1 The Coltrane-Slonimsky Problem Solve the “Coltrane-Slonimsky Problem” Given a wealth of melodic possibilities to learn from, to select something to learn which is sufficiently challenging and interesting to the ear. Two key deliverables: front-facing apps: Slonimsky.app Songbird.training "],["background.html", "8 Background 8.1 Historical approaches to improving playing by ear", " 8 Background 8.1 Historical approaches to improving playing by ear record player transcription books pattern books "],["melody-as-cognitive-psychology.html", "9 Melody as Cognitive Psychology", " 9 Melody as Cognitive Psychology [@herbornFeaturesPerceptionConstruction2022] "],["theoretical-model.html", "10 Playing By Ear: A Theoretical Model", " 10 Playing By Ear: A Theoretical Model As far as the author is aware, no computational model of playing by ear has been described in the music psychology, or related, literature(s). Thus, a first step in this thesis is to propose a theoretical model, which can then later be formulated more precisely as a computational model, then tested, partly with data collected throughout this thesis. However, related computational models have been described, for instance in the domain of aural skill acquisition [@bakerModelingMelodicDictation2019] and sung melodic recall by the author [@silasLearningRecallingMelodies2023; @silasSingingAbilityAssessment2023]. Theoretical cognitive models have also been described in the domain of singing accuracy [@pfordresherTheoreticalPerspectivesSinging2015]. Therefore, in this section, I will attempt to synthesise this literature to propose a corresponding model specifically for playing by ear skills. I distinguish between two basic playing by ear processes: a) playing by ear skill acquisition (learning) and b) playing by ear skill execution (recall). "],["pfordreshers-h-pac-model.html", "11 Pfordresher’s H-PAC model", " 11 Pfordresher’s H-PAC model "],["pfordreshers-cognitive-model-of-singing-accuracy.html", "12 Pfordresher’s cognitive model of singing accuracy 12.1 Baker’s computational model of melodic dictation", " 12 Pfordresher’s cognitive model of singing accuracy I start first by using @pfordresherTheoreticalPerspectivesSinging2015’s cognitive (but non-computational) model of singing accuracy, which is the most broad of the models I will review. At the low level, this model comprises an auditory feedback loop. In this loop, first, external auditory input is processed as low-level perceptual representations of sound (pitch, duration, timbre, loudness). Such low-level representations are used as input to a translation model, which relates auditory input to sensorimotor action that is relevant to singing. Hence, this enables the guidance of a singer’s sensorimotor plans to adjust their singing (e.g., to be in tune), in response to auditory feedback. Such changes in sensorimotor actions comprise physical processes like respiration, phonation, and articulation. Abstracting the sensorimotor part to the domain of playing by ear, such physical processes would be somewhat instrument-specific. For many instruments, the physical part will involve finger coordination (e.g., clarinet, violin), but for some, coordination will be more at the level of the arm (e.g., percussion, drums). Many processes will be instrument-specific processes. For example, for brass and woodwind instruments, requiring to coordinate an embouchure to produce a sound. We do not exhaust these instrument-specific processes, but only state that such physical processes are part of the model, with instrument-specific attributes. The lower-level auditory representations are also used as input to higher levels of cognition, which hold mental templates about music (e.g., its features, such as its tonality), stored in long- term memory (Baddeley et al., 2009). These templates allow auditory content to be categorized, forming more sophisticated representations of it, taking on musical domains such as representations of (melodic) features like tonality and contour, as well as segmenting melodies into coherent perceptual chunks. These formed higher-level representations can in turn be used as input back to the lower-level auditory feedback loop and further inform sensorimotor planning. Hence, the overall architecture of Pfordresher et al. (2015)’s cognitive model is bidirectional: both “top down” and “bottom up”. Altogether, this system enables a singer - to fulfill objectives related to sung recall (i.e., hearing stimuli, representing its musical features mentally, responding through singing, and adjusting behavior to fulfill the goal sufficiently). This can readily be abstracted to playing by ear too: the only difference being in the motor plan aspects, which, as mentioned, are instrument-specific. Our focus in the current manuscript is on the higher-level aspects of this model: memory for melodic representations. Caption for the image 12.1 Baker’s computational model of melodic dictation "],["models-of-sung-recall.html", "13 Models of sung recall", " 13 Models of sung recall Lastly, I synthesise models from my own research regarding sung melodic recall. My @silasSingingAbilityAssessment2023 study investigated sung recall by examining its relationship with other related skills and participant attributes. Demographically, better sung recall ability ability was associated with more musical training (𝛽 = 0.07), a younger age (𝛽 = -0.05), and being female (𝛽 = -0.03), though the latter two effects were small. The findings suggest that while musical training can enhance singing ability, inherent skills might also predispose individuals to seek musical training. Moreover, there was a relatively large difference between the marginal and conditional R^2 values, which suggests that there is a sizeable proportion of individual differences in the sample of participants tested which explains SAA performance which shows that individual differences should explain performance on a task in which one can develop high levels of domain-specific expertise. We found there that melodic discrimination, pitch imagery abilities, and mistuning perception appear to be fundamental skills contributing to melodic sung recall. The sung recall score we devised moderately correlated with self-reported singing ability (r = .46) and musical training (r = ?). However, it shows no significant correlation with visuospatial working memory or pitch discrimination, aligning with previous research and suggesting that singing ability is not closely linked to low-level perceptual processes. This suggests that, whilst The study also shows that melodic features which indicate melodic complexity (including melody length) are relevant predictors of sung recall performance. These predictors represented melody length, as well as features related to contour, tonality, statistical occurrence of N-grams in the melody, and durational complexity. Rhythmic trials were generally found to be more difficult (B = -0.15, p &lt; .001) and we found that it was appropriate to create separate models for arhythmic and rhythmic. In another of my papers, [@silasLearningRecallingMelodies2023], we investigated how individuals learn and recall melodies using a computational approach that emphasizes similarity metrics rather than traditional accuracy-based methods. The research involved 31 participants who sang back 28 melodies presented either as piano sounds or vocal audio excerpts from pop songs, with each melody repeated up to six times. The similarity between the target melody and the participants’ sung recalls was measured using advanced algorithmic techniques. The primary goal was to understand how melodic recall improves over successive attempts and what factors most significantly influence recall accuracy. One of the key findings of the study is that the length of sung recall attempts consistently increases across multiple attempts, and this increase significantly correlates with the overall similarity to the target melody. This observation challenges the traditional view that musical features such as interval patterns or tonality are the primary factors influencing melodic recall. Instead, the study suggests that the sheer length of the melody plays a more critical role, indicating that general memory constraints may be more influential than music-specific features. This insight aligns with theories of working memory, suggesting that melodic recall shares characteristics with other types of serial recall rather than being purely domain-specific to music. A significant finding (presented there in Figure 8), examines how similarity changes as a function of attempt and the specific section of the melody (beginning, middle, end). The results show that similarity performance increases more rapidly for the beginning of the melody compared to the middle and end across successive attempts. This indicates that participants tend to stabilise their recall of the initial melodic segments earlier than the middle or end sections. The end sections, in particular, show a slower rate of improvement, suggesting that the latter parts of a melody are more challenging to accurately recall perhaps due to the higher working memory load as a result of having to remember more notes, the later you are in a position, or that generally people engaging in sung recall prioritise getting the earlier parts melody correct first. This finding supports the theory that memory encoding is stronger for the beginning of sequences, a phenomenon consistent with the primacy effect observed in other types of serial recall tasks. It also highlights that recall accuracy is not uniformly distributed across a melody, with the initial segments being more robustly learned compared to later ones. The study also found that musical training did not significantly enhance recall performance when similarity metrics were used as the primary assessment method, as shown in another key result. This challenges the conventional belief that formal musical training substantially improves melodic recall ability. Instead, the data suggests that domain-general memory skills may be just as important, pointing to a more integrative understanding of how musical and non-musical cognitive processes interact. Moreover, the results highlight that similarity scores increase with each successive attempt, but the rate of improvement diminishes after the third or fourth attempt. This pattern suggests that the most substantial gains in melodic recall occur early in the learning process, followed by incremental refinements in pitch and rhythm accuracy. Additionally, melodies presented as vocal audio excerpts resulted in higher recall accuracy compared to piano sound presentations, indicating that the human voice might provide additional mnemonic cues that aid in memory encoding. Overall, the study’s use of similarity-based metrics, particularly the “opti3” metric that integrates pitch intervals, harmonic progression, and rhythmic similarity, offers a more nuanced and accurate assessment of how melodies are learned and recalled. By focusing on the gradual increase in recall length and the differential improvement across melodic segments, the study sheds light on the underlying cognitive processes involved in melodic memory, emphasizing the role of general memory mechanisms and the relatively limited impact of formal musical training. "],["non-musical-models-of-serial-recall.html", "14 Non-musical models of serial recall", " 14 Non-musical models of serial recall (look at Silas &amp; Müllensiefen paper) ACT-R "],["wm-bits.html", "15 WM bits", " 15 WM bits Baddeley and hitch Berz (1995) LTWM (erricsson) @silasAssociationsMusicTraining2022 discussion around MWM and GWM "],["bringing-it-together.html", "16 Bringing it together 16.1 Moving from Theoretical to Computational 16.2 Mathematical Representation 16.3 Algorithm Flow 16.4 Final Equation", " 16 Bringing it together In sum, then, 16.1 Moving from Theoretical to Computational “When we develop a psychological theory that is sufficiently precise to be implemented as a computer program, we call it a computational model. The process of developing such theories, and implementing their corresponding computer programs, is then called computational modelling.” [@harrisonMusicScience2025]. At this point, I already suggest a more specific feature to the model: that for playing by ear tasks, there exists a mental melodic “similarity” algorithm, housed in working memory. The input to this module is the target melody and the evolving real-time assessment of the melody being produced in the moment. The performer must hear the target melody, store this in short term memory as a reference, and then continuously update the target melody which each new note that is produced. I speculate that the mind recomputes the similarity between the presently number of recalled notes and the target melody iteratively, each time a new note is added. In other words, a check for the accuracy is made every time a note is recalled, and the presence of an error and its nature, will inform whether or not the performer stops to start again or continues to proceed recalling the melody, at least in the stage of learning. Formally: 16.1.1 Inputs \\(T = [t_1, t_2, \\dots, t_n]\\): TargetMelody of fixed length \\(n\\). \\(R = [r_1, r_2, \\dots, r_k]\\): RecalledMelody of length \\(k\\), unknown a priori. 16.1.2 Sequential Construction \\(T\\) is fixed and built one note at a time. \\(R\\) is sequentially constructed one note at a time. 16.1.3 Function Application At each step \\(i\\) (current length of \\(R\\)), the function MelSim is applied to TargetMelody and the current length of RecalledMelody. 16.2 Mathematical Representation Let: - \\(T_i\\) be the prefix of the TargetMelody up to length \\(i\\), i.e., \\(T_i = [t_1, t_2, \\dots, t_i]\\). - \\(R_i\\) be the current state of the RecalledMelody of length \\(i\\), i.e., \\(R_i = [r_1, r_2, \\dots, r_i]\\). - \\(\\text{MelSim}(T_i, R_i)\\) be the similarity function between the two melodies at length \\(i\\). The MelSim function can be formulated as: \\[ \\text{MelSim}(T_i, R_i) = f(T_i, R_i) \\] Where: - \\(f\\) is a similarity measure (e.g., distance function, alignment score). - \\(i\\) iterates from 1 to \\(n\\), where \\(n\\) is the fixed length of the target melody. 16.3 Algorithm Flow Start with an empty recalled melody \\(R\\). For each new note \\(r_i\\) added to \\(R\\): Compute the similarity: \\(\\text{MelSim}(T_i, R_i)\\) if \\(i = n\\). Repeat until the entire recalled melody is constructed. 16.4 Final Equation The similarity calculation is performed only when the length of the RecalledMelody equals the fixed length of the TargetMelody. Therefore, the final equation is expressed as: \\[ \\text{MelSim}(T, R_n) = f(T, R_n) \\] I note that the MelSim algorithm is itself modular and of discussion in and of itself (cite M&amp;F). For the purpose of this paper, "],["strategies.html", "17 Strategies", " 17 Strategies Beyond scope of this dissertation to investigate in detail. Pop strategies hypotheses: [@liscioWatchingPopularMusicians2024] Also, we have our own text data, for later. "],["learning-forgetting.html", "18 Learning, forgetting", " 18 Learning, forgetting Ebbinghaus, learning curves Unit of sleep "],["the-melodic-mind-as-item-bank.html", "19 The Melodic Mind As Item Bank", " 19 The Melodic Mind As Item Bank Big concept "],["predictions.html", "20 Predictions:", " 20 Predictions: Simpler melodies will rely more on general working memory than musical working memory. In the short term (&lt; 30 mins), melodies learned by sight will be less better retained than those "],["melodic_networks.html", "21 Melodic corpora as networks", " 21 Melodic corpora as networks 21.0.1 musicassessr "],["similarity-simulation-model.html", "22 Similarity Simulation Model", " 22 Similarity Simulation Model "],["computational-ecosystem.html", "23 A computational ecosystem 23.1 pyin:", " 23 A computational ecosystem To investigate computational questions related to playing by ear, an appropriate computational architecture is required. Whilst many musicological and psychological tools exist, as far as I am aware, there is no open source academic framework that provides an end-to-end solution for recording produced musical data, transcribing audio into useful symbolic representations, and assessing these representations within a scientific statistical modelling framework - all in real-time. However, it would be far beyond the scope of any individual to produce all the required components, themselves requiring considerable research. Indeed, we stand on the shoulders of giants. In that respect, my work here has mainly been to find ways to combine the already existing tools into a framework - to get them to interact with one another - and create useful data structures to store relevant information and make it readily usable in web applications. To not detract from the theoretical questions in this manuscript, I will only give a brief tour of this architecture here. However, please see the documentation for a more thorough treatment. I will start with the low-level packages and work my way up to the higher level ones. 23.1 pyin: To be able to assess music production data, it is first necessary to melsim "],["psychologically-meaningful-musical-item-banks-itembankr.html", "24 Psychologically meaningful musical item banks: itembankr 24.1 Datasets 24.2 Other useful functions 24.3 Conclusion", " 24 Psychologically meaningful musical item banks: itembankr 24.0.1 itembankr library(itembankr) library(WJD) library(Berkowitz) #library(Slonimsky) 24.1 Datasets 24.1.1 WJD The command used to create the item bank was: WJD &lt;- corpus_to_item_bank(corpus_name = &quot;WJD&quot;, corpus_df = phrases_dbs2, output_type = &quot;ngram&quot;, phrases_db = phrases_dbs2, launch_app = FALSE) The properties of the item bank are: WJD::WJD itembankr::hist_item_bank(WJD::WJD) 24.1.2 Berkowitz head(Berkowitz::Berkowitz) itembankr::hist_item_bank(Berkowitz::Berkowitz) 24.1.3 Slonimsky head(Slonimsky::Slonimsky) itembankr::hist_item_bank(Slonimsky::Slonimsky) 24.2 Other useful functions itembankr::subset_item_bank() itembankexplorer::item_bank_explorer(Berkowitz::Berkowitz) Much of the architecture is grouped under the musicassessr package and ecosystem [@silasMusicassessrEcosystemRecord2023]. musicassessr is, in essence, a giant wrapper, bringing already developed psychological and musicological into the same software environment, backed by a statistical modelling framework in R [@rcoreteamLanguageEnvironmentStatistical2020]. 24.2.1 Assessing musical behaviours: musicassessr library(musicassessr) library(htmltools) htmltools::tagList( lapply(musicassessr::musicassessr_js(visual_notation = TRUE), function(x) { if(base::startsWith(x, &quot;http&quot;)) { htmltools::tags$script(src = x) } else { htmltools::includeScript(x) } }) ) musicassessr::present_stimuli( stimuli = c(60, 62, 64, 65), stimuli_type = &quot;midi_notes&quot;, display_modality = &quot;visual&quot; ) 24.3 Conclusion Thus, a primary outcome of this dissertation was the development of a computational ecosystem to record and assess music production data in real-time. "],["ability_tests.html", "25 Ability Tests", " 25 Ability Tests 25.0.1 SAA 25.0.2 PBET # SAA() # PBET() Experimental/technically feasible: SST() SRT() "],["calibration_studies.html", "26 Calibration studies", " 26 Calibration studies 11 participants.. BDS tasks represent a classic measure of WM (Case &amp; Globerson, 1974). Participants must remember an ordered sequence of digits, mentally reverse it, and enter the reversed sequence by clicking the numbers on a key- pad. We reimplemented the version used by Vock and Holling (2008), which consisted of 12 trials of increas- ing difficulty using sequences of four to seven digits length. Since all stimuli were presented in the visual domain and responding involved clicking digits on a visually displayed keypad that spatially organized the digits, we consider this a visuospatial BDS task. Previous item response theory (IRT) models for this task could not be used as they were constructed based on their inclusion in another battery of tasks (as explained above). We computed IRT scores for each participant by fitting a Rasch psychometric model to the collected data. A Pearson’s product-moment correlation of the sum scores with the IRT scores yielded a very strong correlation (r 1⁄4 .99, p &lt; .01), indicating a high level of consistency between the classical test theory and IRT scoring methods. "],["melsim_development.html", "27 Development of a melodic similarity algorithm for short recalled melodies", " 27 Development of a melodic similarity algorithm for short recalled melodies "],["pbet_online_study.html", "28 Model of melodic difficulty", " 28 Model of melodic difficulty "],["item_curation.html", "29 Item curation", " 29 Item curation "],["heterogeneity_and_item_bank_sampling.html", "30 Heterogenity and item bank sampling 30.1 via item response theory (IRT) (difficulty) 30.2 via similarity 30.3 via difficulty/similarity hybrid", " 30 Heterogenity and item bank sampling #TODO demo PBET etc. sampling functions PBET::item_characteristics_sampler_pbet() ## 2025-04-17 11:41:29.229868 INFO::Creating PBET block with 10 items: 10 auditory and 0 visual ## # A tibble: 10 × 3 ## trial_no key_difficulty display_modality ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 easy auditory ## 2 2 hard auditory ## 3 3 easy auditory ## 4 4 hard auditory ## 5 5 easy auditory ## 6 6 easy auditory ## 7 7 hard auditory ## 8 8 hard auditory ## 9 9 easy auditory ## 10 10 hard auditory 30.1 via item response theory (IRT) (difficulty) 30.2 via similarity 30.3 via difficulty/similarity hybrid "],["item_banks_and_similarity.html", "31 Approaches to similarity for large scale corpora 31.1 Problem: 31.2 Approach #1: similarity of features as proxy for melodic similarity 31.3 Approach #2: Generative similarity 31.4 Approach #3: on breaking up items into ngrams, store representations/similarity.", " 31 Approaches to similarity for large scale corpora opti3 etc. 31.1 Problem: # WJD_no_items &lt;- nrow(WJD::WJD(&#39;phrases&#39;)) # factorial(WJD_no_items) 31.2 Approach #1: similarity of features as proxy for melodic similarity Conclusion: similarity of features =! melodic (opti3/[perceptual?!]) similarity - this is important, because similar features will produce similar difficulty scores (need to test this formally though).. which shows that similarity as a separate item selector to difficulty is warranted/important (potentially) 31.3 Approach #2: Generative similarity bringing in desimilarize et al. app 31.4 Approach #3: on breaking up items into ngrams, store representations/similarity. by definition ngrams will be similarity to the overall melody they come from "],["reviewing_and_spaced_repetition.html", "32 Reviewing and spaced repetition", " 32 Reviewing and spaced repetition "],["identify-correct-vs-incorrect-ngrams-in-a-recall-add-incorrect-ngrams-to-beginning-of-session-buffer.html", "33 identify correct vs incorrect ngrams in a recall: add incorrect ngrams to beginning of session buffer", " 33 identify correct vs incorrect ngrams in a recall: add incorrect ngrams to beginning of session buffer prioritise those with temporal order prioritise those which are easier or, just incrementally test until each ngram is obtained from the beginning. e.g, if the target is, 60:65, first the participant must at least get 60:61; once this is got, 60:63 etc.. the program adds a note each time (or if the participant adds an additional extra note, the program could skip an n-gram) "],["visual_vs_auditory_learning_pbe.html", "34 Reviewing and spaced repetition", " 34 Reviewing and spaced repetition "],["identify-correct-vs-incorrect-ngrams.html", "35 identify correct vs incorrect ngrams", " 35 identify correct vs incorrect ngrams append incorrect ngrams to top of buffer priorotise earlier ngrams "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
